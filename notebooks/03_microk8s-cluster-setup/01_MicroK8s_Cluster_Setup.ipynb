{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f166f6d5",
   "metadata": {},
   "source": [
    "# MicroK8s Cluster Setup: CPU Controller + DGX Spark Nodes\n",
    "\n",
    "This tutorial walks through setting up a MicroK8s Kubernetes cluster with:\n",
    "\n",
    "| Node | Role | IP Address | Description |\n",
    "|------|------|------------|-------------|\n",
    "| controller | Control Plane | 192.168.1.75 | CPU-only node running K8s control plane |\n",
    "| spark-01 | Worker | 192.168.1.76 | DGX Spark with GPU |\n",
    "| spark-02 | Worker | 192.168.1.77 | DGX Spark with GPU |\n",
    "\n",
    "All nodes are connected via WiFi and have the `nvidia` user configured.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Ubuntu 22.04 or later on all nodes\n",
    "- SSH access from your workstation to all nodes\n",
    "- `nvidia` user with sudo privileges on all nodes\n",
    "- Network connectivity between all nodes (WiFi in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaceaaa8",
   "metadata": {},
   "source": [
    "## Step 1: Define Cluster Variables\n",
    "\n",
    "Store node information in environment variables for use throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0c767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controller: nvidia@192.168.1.75\n",
      "Spark-01:   nvidia@192.168.1.76\n",
      "Spark-02:   nvidia@192.168.1.77\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Cluster configuration\n",
    "CONTROLLER_IP = \"192.168.1.75\"\n",
    "SPARK01_IP = \"192.168.1.76\"\n",
    "SPARK02_IP = \"192.168.1.77\"\n",
    "SSH_USER = \"nvidia\"\n",
    "\n",
    "# Store as environment variables for shell commands\n",
    "os.environ[\"CONTROLLER_IP\"] = CONTROLLER_IP\n",
    "os.environ[\"SPARK01_IP\"] = SPARK01_IP\n",
    "os.environ[\"SPARK02_IP\"] = SPARK02_IP\n",
    "os.environ[\"SSH_USER\"] = SSH_USER\n",
    "\n",
    "print(f\"Controller: {SSH_USER}@{CONTROLLER_IP}\")\n",
    "print(f\"Spark-01:   {SSH_USER}@{SPARK01_IP}\")\n",
    "print(f\"Spark-02:   {SSH_USER}@{SPARK02_IP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f6674",
   "metadata": {},
   "source": [
    "### Fix: Initialize SSH Agent in Kernel\n",
    "\n",
    "The Jupyter kernel runs in a separate process without access to your terminal's SSH agent. Run this cell once to start the agent and load your key within the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc4a4506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSH_AUTH_SOCK=/var/folders/lv/0641bl7j7cj9wls4nqrctypm0000gp/T//ssh-9pEoO3Jo7nYI/agent.51358\n",
      "SSH_AGENT_PID=51359\n",
      "Identity added: /Users/elizabeththomas/.ssh/id_ed25519 (email2eliza@gmail.com)\n",
      "\n",
      "\n",
      "SSH agent environment saved to /tmp/ssh_agent_env.sh\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Start SSH agent and capture its output\n",
    "result = subprocess.run(\n",
    "    ['ssh-agent', '-s'],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Parse and set environment variables\n",
    "for line in result.stdout.split('\\n'):\n",
    "    if 'SSH_AUTH_SOCK' in line:\n",
    "        sock = line.split(';')[0].split('=')[1]\n",
    "        os.environ['SSH_AUTH_SOCK'] = sock\n",
    "        print(f\"SSH_AUTH_SOCK={sock}\")\n",
    "    elif 'SSH_AGENT_PID' in line:\n",
    "        pid = line.split(';')[0].split('=')[1]\n",
    "        os.environ['SSH_AGENT_PID'] = pid\n",
    "        print(f\"SSH_AGENT_PID={pid}\")\n",
    "\n",
    "# Add the SSH key\n",
    "add_result = subprocess.run(\n",
    "    ['ssh-add', os.path.expanduser('~/.ssh/id_ed25519')],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "print(add_result.stdout or add_result.stderr)\n",
    "\n",
    "# Write environment to a file that bash cells can source\n",
    "with open('/tmp/ssh_agent_env.sh', 'w') as f:\n",
    "    f.write(f'export SSH_AUTH_SOCK={os.environ[\"SSH_AUTH_SOCK\"]}\\n')\n",
    "    f.write(f'export SSH_AGENT_PID={os.environ[\"SSH_AGENT_PID\"]}\\n')\n",
    "print(\"\\nSSH agent environment saved to /tmp/ssh_agent_env.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d88ab",
   "metadata": {},
   "source": [
    "## Step 2: Test SSH Connectivity\n",
    "\n",
    "Verify SSH access to all nodes. Each command should return the hostname without prompting for a password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31836783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SSH to Controller (192.168.1.75)...\n",
      "controller\n",
      "\n",
      "Testing SSH to Spark-01 (192.168.1.76)...\n",
      "spark-01\n",
      "\n",
      "Testing SSH to Spark-02 (192.168.1.77)...\n",
      "spark-02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "nodes = [\n",
    "    (\"Controller\", \"192.168.1.75\"),\n",
    "    (\"Spark-01\", \"192.168.1.76\"),\n",
    "    (\"Spark-02\", \"192.168.1.77\")\n",
    "]\n",
    "\n",
    "ssh_opts = [\"-o\", \"ConnectTimeout=5\", \"-o\", \"StrictHostKeyChecking=accept-new\"]\n",
    "\n",
    "for name, ip in nodes:\n",
    "    print(f\"Testing SSH to {name} ({ip})...\")\n",
    "    result = subprocess.run(\n",
    "        [\"ssh\"] + ssh_opts + [f\"nvidia@{ip}\", \"hostname\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(result.stdout.strip())\n",
    "    else:\n",
    "        print(f\"FAILED: Cannot connect to {name.lower()}\")\n",
    "        if result.stderr:\n",
    "            print(f\"Error: {result.stderr.strip()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47333179",
   "metadata": {},
   "source": [
    "### Diagnosing SSH Environment\n",
    "\n",
    "The notebook kernel may run in a different environment than your terminal. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94173c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SSH Environment Check ===\n",
      "\n",
      "Running as user: elizabeththomas\n",
      "Home directory: /Users/elizabeththomas\n",
      "\n",
      "SSH keys available:\n",
      "-rw-------@ 1 elizabeththomas  staff   411 Nov  4 12:57 /Users/elizabeththomas/.ssh/id_ed25519\n",
      "-rw-r--r--@ 1 elizabeththomas  staff   103 Nov  4 12:57 /Users/elizabeththomas/.ssh/id_ed25519.pub\n",
      "-rw-------@ 1 elizabeththomas  staff  3434 Oct 11  2024 /Users/elizabeththomas/.ssh/id_rsa\n",
      "-rw-r--r--@ 1 elizabeththomas  staff   747 Oct 11  2024 /Users/elizabeththomas/.ssh/id_rsa.pub\n",
      "\n",
      "SSH agent status:\n",
      "SSH_AUTH_SOCK: /var/folders/lv/0641bl7j7cj9wls4nqrctypm0000gp/T//ssh-9pEoO3Jo7nYI/agent.51358\n",
      "256 SHA256:na0tGgsozbGtZ2nM52FTdk7No5zpLE5r4iaZE0U2zyQ email2eliza@gmail.com (ED25519)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"=== SSH Environment Check ===\"\n",
    "echo \"\"\n",
    "echo \"Running as user: $(whoami)\"\n",
    "echo \"Home directory: $HOME\"\n",
    "echo \"\"\n",
    "echo \"SSH keys available:\"\n",
    "ls -la ~/.ssh/id_* 2>/dev/null || echo \"No SSH keys found in ~/.ssh/\"\n",
    "echo \"\"\n",
    "echo \"SSH agent status:\"\n",
    "echo \"SSH_AUTH_SOCK: ${SSH_AUTH_SOCK:-NOT SET}\"\n",
    "ssh-add -l 2>&1 || echo \"No agent running or no keys loaded\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5e071",
   "metadata": {},
   "source": [
    "### Fix: Set Up SSH Key-Based Authentication\n",
    "\n",
    "If SSH fails, you need to set up passwordless SSH. First, check if you have an SSH key:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad71f8f",
   "metadata": {},
   "source": [
    "**If no key exists**, run this cell to generate one (skip if you already have a key):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f86491",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Generate SSH key (only run if you don't have one)\n",
    "ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 -N \"\" -C \"microk8s-cluster\"\n",
    "echo \"Key generated:\"\n",
    "cat ~/.ssh/id_ed25519.pub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c277b4e",
   "metadata": {},
   "source": [
    "### Copy SSH Key to All Nodes\n",
    "\n",
    "Run `ssh-copy-id` for each node. This will prompt for the password once per node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe8e3f",
   "metadata": {},
   "source": [
    "**Run these commands in a terminal** (they require interactive password input):\n",
    "\n",
    "```bash\n",
    "# Copy to controller\n",
    "ssh-copy-id nvidia@192.168.1.75\n",
    "\n",
    "# Copy to spark-01\n",
    "ssh-copy-id nvidia@192.168.1.76\n",
    "\n",
    "# Copy to spark-02\n",
    "ssh-copy-id nvidia@192.168.1.77\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc1f93",
   "metadata": {},
   "source": [
    "## Step 3: Install MicroK8s on All Nodes\n",
    "\n",
    "MicroK8s is a lightweight Kubernetes distribution from Canonical. We'll install it on all three nodes, then join the Spark nodes to the controller.\n",
    "\n",
    "**Architecture:**\n",
    "- Controller (192.168.1.75): Runs the Kubernetes control plane only\n",
    "- Spark-01 (192.168.1.76): Worker node with GPU\n",
    "- Spark-02 (192.168.1.77): Worker node with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa73344",
   "metadata": {},
   "source": [
    "### 3.1 Install MicroK8s on the Controller\n",
    "\n",
    "The controller runs the control plane (API server, scheduler, etcd). No GPU needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "743963b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Installing MicroK8s on Controller (192.168.1.75) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pseudo-terminal will not be allocated because stdin is not a terminal.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Ubuntu 24.04.3 LTS (GNU/Linux 6.8.0-90-generic x86_64)\n",
      "\n",
      " * Documentation:  https://help.ubuntu.com\n",
      " * Management:     https://landscape.canonical.com\n",
      " * Support:        https://ubuntu.com/pro\n",
      "\n",
      " System information as of Sun Feb  1 04:51:15 AM UTC 2026\n",
      "\n",
      "  System load:             0.0\n",
      "  Usage of /:              1.6% of 835.58GB\n",
      "  Memory usage:            3%\n",
      "  Swap usage:              0%\n",
      "  Temperature:             39.9 C\n",
      "  Processes:               320\n",
      "  Users logged in:         1\n",
      "  IPv4 address for wlp2s0: 192.168.1.75\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:dba1:cc44:2510:46a6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:36b9:c4a0:a7e9:31ed\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:9d6d:19f6:90da:d7f6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:ef2d:9464:3557:9dec\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:7a8d:97c:e56c:fe96\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10::48\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:22:bc19:d505:ab6a\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:5152:63e:7ef:88e3\n",
      "\n",
      " * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s\n",
      "   just raised the bar for easy, resilient and secure K8s cluster deployment.\n",
      "\n",
      "   https://ubuntu.com/engage/secure-kubernetes-at-the-edge\n",
      "\n",
      "Expanded Security Maintenance for Applications is not enabled.\n",
      "\n",
      "68 updates can be applied immediately.\n",
      "To see these additional updates run: apt list --upgradable\n",
      "\n",
      "Enable ESM Apps to receive additional future security updates.\n",
      "See https://ubuntu.com/esm or run: sudo pro status\n",
      "\n",
      "\n",
      "Installing MicroK8s...\n",
      "microk8s (1.31/stable) v1.31.14 from Canonical** installed\n",
      "microk8s is running\n",
      "high-availability: no\n",
      "  datastore master nodes: 127.0.0.1:19001\n",
      "  datastore standby nodes: none\n",
      "addons:\n",
      "  enabled:\n",
      "    dns                  # (core) CoreDNS\n",
      "    ha-cluster           # (core) Configure high availability on the current node\n",
      "    helm                 # (core) Helm - the package manager for Kubernetes\n",
      "    helm3                # (core) Helm 3 - the package manager for Kubernetes\n",
      "  disabled:\n",
      "    cert-manager         # (core) Cloud native certificate management\n",
      "    cis-hardening        # (core) Apply CIS K8s hardening\n",
      "    community            # (core) The community addons repository\n",
      "    dashboard            # (core) The Kubernetes dashboard\n",
      "    gpu                  # (core) Alias to nvidia add-on\n",
      "    host-access          # (core) Allow Pods connecting to Host services smoothly\n",
      "    hostpath-storage     # (core) Storage class; allocates storage from host directory\n",
      "    ingress              # (core) Ingress controller for external access\n",
      "    kube-ovn             # (core) An advanced network fabric for Kubernetes\n",
      "    mayastor             # (core) OpenEBS MayaStor\n",
      "    metallb              # (core) Loadbalancer for your Kubernetes cluster\n",
      "    metrics-server       # (core) K8s Metrics Server for API access to service metrics\n",
      "    minio                # (core) MinIO object storage\n",
      "    nvidia               # (core) NVIDIA hardware (GPU and network) support\n",
      "    observability        # (core) A lightweight observability stack for logs, traces and metrics\n",
      "    prometheus           # (core) Prometheus operator for monitoring and logging\n",
      "    rbac                 # (core) Role-Based Access Control for authorisation\n",
      "    registry             # (core) Private image registry exposed on localhost:32000\n",
      "    rook-ceph            # (core) Distributed Ceph storage using Rook\n",
      "    storage              # (core) Alias to hostpath-storage add-on, deprecated\n",
      "\n",
      "MicroK8s version:\n",
      "Client Version: v1.31.14\n",
      "Kustomize Version: v5.4.2\n",
      "Server Version: v1.31.14\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Installing MicroK8s on Controller (192.168.1.75) ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.75 << 'EOF'\n",
    "    # Check if MicroK8s is already installed\n",
    "    if snap list microk8s &>/dev/null; then\n",
    "        echo \"MicroK8s is already installed. Skipping installation.\"\n",
    "        microk8s version\n",
    "    else\n",
    "        echo \"Installing MicroK8s...\"\n",
    "        sudo snap install microk8s --classic --channel=1.31/stable\n",
    "        # Add user to microk8s group (only needed on first install)\n",
    "        sudo usermod -a -G microk8s $USER\n",
    "        newgrp microk8s\n",
    "    fi\n",
    "    \n",
    "    # Ensure .kube directory exists\n",
    "    mkdir -p ~/.kube\n",
    "    \n",
    "    # Wait for MicroK8s to be ready (use microk8s directly, not sudo)\n",
    "    microk8s status --wait-ready\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"MicroK8s version:\"\n",
    "    microk8s kubectl version --short 2>/dev/null || microk8s kubectl version\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92165e6d",
   "metadata": {},
   "source": [
    "### 3.2 Install MicroK8s on Spark-01\n",
    "\n",
    "Worker node with GPU. Same installation, will join the cluster later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3004a29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Installing MicroK8s on Spark-01 (192.168.1.76) ===\n",
      "MicroK8s not found or broken. Installing fresh...\n",
      "Installing MicroK8s...\n",
      "microk8s (1.31/stable) v1.31.14 from Canonical** installed\n",
      "NOTE: Group membership updated. Running remaining commands with sudo.\n",
      "microk8s is running\n",
      "high-availability: no\n",
      "  datastore master nodes: 127.0.0.1:19001\n",
      "  datastore standby nodes: none\n",
      "addons:\n",
      "  enabled:\n",
      "    dns                  # (core) CoreDNS\n",
      "    ha-cluster           # (core) Configure high availability on the current node\n",
      "    helm                 # (core) Helm - the package manager for Kubernetes\n",
      "    helm3                # (core) Helm 3 - the package manager for Kubernetes\n",
      "  disabled:\n",
      "    cert-manager         # (core) Cloud native certificate management\n",
      "    cis-hardening        # (core) Apply CIS K8s hardening\n",
      "    community            # (core) The community addons repository\n",
      "    dashboard            # (core) The Kubernetes dashboard\n",
      "    host-access          # (core) Allow Pods connecting to Host services smoothly\n",
      "    hostpath-storage     # (core) Storage class; allocates storage from host directory\n",
      "    ingress              # (core) Ingress controller for external access\n",
      "    kube-ovn             # (core) An advanced network fabric for Kubernetes\n",
      "    mayastor             # (core) OpenEBS MayaStor\n",
      "    metallb              # (core) Loadbalancer for your Kubernetes cluster\n",
      "    metrics-server       # (core) K8s Metrics Server for API access to service metrics\n",
      "    minio                # (core) MinIO object storage\n",
      "    observability        # (core) A lightweight observability stack for logs, traces and metrics\n",
      "    prometheus           # (core) Prometheus operator for monitoring and logging\n",
      "    rbac                 # (core) Role-Based Access Control for authorisation\n",
      "    registry             # (core) Private image registry exposed on localhost:32000\n",
      "    rook-ceph            # (core) Distributed Ceph storage using Rook\n",
      "    storage              # (core) Alias to hostpath-storage add-on, deprecated\n",
      "\n",
      "MicroK8s version:\n",
      "Client Version: v1.31.14\n",
      "Kustomize Version: v5.4.2\n",
      "Server Version: v1.31.14\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Installing MicroK8s on Spark-01 (192.168.1.76) ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.76 'bash -s' << 'EOF'\n",
    "    # Check if MicroK8s snap is installed and microk8s command works\n",
    "    if snap list microk8s &>/dev/null && /snap/bin/microk8s version &>/dev/null; then\n",
    "        echo \"MicroK8s is already installed and working. Skipping installation.\"\n",
    "        /snap/bin/microk8s version\n",
    "    else\n",
    "        echo \"MicroK8s not found or broken. Installing fresh...\"\n",
    "        # Remove any broken installation first\n",
    "        sudo snap remove microk8s --purge 2>/dev/null || true\n",
    "        \n",
    "        echo \"Installing MicroK8s...\"\n",
    "        sudo snap install microk8s --classic --channel=1.31/stable\n",
    "        \n",
    "        # Add user to microk8s group\n",
    "        sudo usermod -a -G microk8s $USER\n",
    "        \n",
    "        echo \"NOTE: Group membership updated. Running remaining commands with sudo.\"\n",
    "    fi\n",
    "    \n",
    "    # Ensure .kube directory exists\n",
    "    mkdir -p ~/.kube\n",
    "    \n",
    "    # Wait for MicroK8s to be ready\n",
    "    sudo /snap/bin/microk8s status --wait-ready\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"MicroK8s version:\"\n",
    "    sudo /snap/bin/microk8s kubectl version --short 2>/dev/null || sudo /snap/bin/microk8s kubectl version\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2b210f",
   "metadata": {},
   "source": [
    "### 3.3 Install MicroK8s on Spark-02\n",
    "\n",
    "Second GPU worker node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b693d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Installing MicroK8s on Spark-02 (192.168.1.77) ===\n",
      "MicroK8s not found or broken. Installing fresh...\n",
      "Installing MicroK8s...\n",
      "microk8s (1.31/stable) v1.31.14 from Canonical** installed\n",
      "NOTE: Group membership updated. Running remaining commands with sudo.\n",
      "microk8s is running\n",
      "high-availability: no\n",
      "  datastore master nodes: 127.0.0.1:19001\n",
      "  datastore standby nodes: none\n",
      "addons:\n",
      "  enabled:\n",
      "    dns                  # (core) CoreDNS\n",
      "    ha-cluster           # (core) Configure high availability on the current node\n",
      "    helm                 # (core) Helm - the package manager for Kubernetes\n",
      "    helm3                # (core) Helm 3 - the package manager for Kubernetes\n",
      "  disabled:\n",
      "    cert-manager         # (core) Cloud native certificate management\n",
      "    cis-hardening        # (core) Apply CIS K8s hardening\n",
      "    community            # (core) The community addons repository\n",
      "    dashboard            # (core) The Kubernetes dashboard\n",
      "    host-access          # (core) Allow Pods connecting to Host services smoothly\n",
      "    hostpath-storage     # (core) Storage class; allocates storage from host directory\n",
      "    ingress              # (core) Ingress controller for external access\n",
      "    kube-ovn             # (core) An advanced network fabric for Kubernetes\n",
      "    mayastor             # (core) OpenEBS MayaStor\n",
      "    metallb              # (core) Loadbalancer for your Kubernetes cluster\n",
      "    metrics-server       # (core) K8s Metrics Server for API access to service metrics\n",
      "    minio                # (core) MinIO object storage\n",
      "    observability        # (core) A lightweight observability stack for logs, traces and metrics\n",
      "    prometheus           # (core) Prometheus operator for monitoring and logging\n",
      "    rbac                 # (core) Role-Based Access Control for authorisation\n",
      "    registry             # (core) Private image registry exposed on localhost:32000\n",
      "    rook-ceph            # (core) Distributed Ceph storage using Rook\n",
      "    storage              # (core) Alias to hostpath-storage add-on, deprecated\n",
      "\n",
      "MicroK8s version:\n",
      "Client Version: v1.31.14\n",
      "Kustomize Version: v5.4.2\n",
      "Server Version: v1.31.14\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Installing MicroK8s on Spark-02 (192.168.1.77) ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.77 'bash -s' << 'EOF'\n",
    "    # Check if MicroK8s snap is installed and microk8s command works\n",
    "    if snap list microk8s &>/dev/null && /snap/bin/microk8s version &>/dev/null; then\n",
    "        echo \"MicroK8s is already installed and working. Skipping installation.\"\n",
    "        /snap/bin/microk8s version\n",
    "    else\n",
    "        echo \"MicroK8s not found or broken. Installing fresh...\"\n",
    "        # Remove any broken installation first\n",
    "        sudo snap remove microk8s --purge 2>/dev/null || true\n",
    "        \n",
    "        echo \"Installing MicroK8s...\"\n",
    "        sudo snap install microk8s --classic --channel=1.31/stable\n",
    "        \n",
    "        # Add user to microk8s group\n",
    "        sudo usermod -a -G microk8s $USER\n",
    "        \n",
    "        echo \"NOTE: Group membership updated. Running remaining commands with sudo.\"\n",
    "    fi\n",
    "    \n",
    "    # Ensure .kube directory exists\n",
    "    mkdir -p ~/.kube\n",
    "    \n",
    "    # Wait for MicroK8s to be ready\n",
    "    sudo /snap/bin/microk8s status --wait-ready\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"MicroK8s version:\"\n",
    "    sudo /snap/bin/microk8s kubectl version --short 2>/dev/null || sudo /snap/bin/microk8s kubectl version\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd24ef",
   "metadata": {},
   "source": [
    "## Step 4: Form the Kubernetes Cluster\n",
    "\n",
    "Now that MicroK8s is installed on all nodes, we need to join the worker nodes to the controller.\n",
    "\n",
    "The process:\n",
    "1. Generate a join token on the controller\n",
    "2. Use that token on each worker node\n",
    "3. Verify all nodes are connected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894581a5",
   "metadata": {},
   "source": [
    "### 4.1 Generate Join Token on Controller\n",
    "\n",
    "This command generates a one-time token that workers will use to join the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4cf18c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating Join Token on Controller ===\n",
      "From the node you wish to join to this cluster, run the following:\n",
      "microk8s join 192.168.1.75:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae\n",
      "\n",
      "Use the '--worker' flag to join a node as a worker not running the control plane, eg:\n",
      "microk8s join 192.168.1.75:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae --worker\n",
      "\n",
      "If the node you are adding is not reachable through the default interface you can use one of the following:\n",
      "microk8s join 192.168.1.75:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:dba1:cc44:2510:46a6:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:36b9:c4a0:a7e9:31ed:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:9d6d:19f6:90da:d7f6:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:ef2d:9464:3557:9dec:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:7a8d:97c:e56c:fe96:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10::48:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:22:bc19:d505:ab6a:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:5152:63e:7ef:88e3:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Generating Join Token on Controller ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.75 'microk8s add-node' | tee /tmp/join_token.txt\n",
    "\n",
    "echo \"Token generated. Extract the join command for workers.\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338ba50",
   "metadata": {},
   "source": [
    "### 4.2 Extract Join Command\n",
    "\n",
    "Parse the join token output to get the actual command. The token expires after some time, so complete the join process promptly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "439efac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join command for workers:\n",
      "microk8s join 192.168.1.75:25000/49058fcd49010d1ddcbebfee1a209411/eee097e0a8ae --worker\n",
      "\n",
      "Saving to /tmp/join_cmd.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Extract the join command with --worker flag\n",
    "JOIN_CMD=$(grep \"microk8s join\" /tmp/join_token.txt | head -1 | sed 's/^[[:space:]]*//')\n",
    "\n",
    "if [ -z \"$JOIN_CMD\" ]; then\n",
    "    echo \"ERROR: Could not extract join command\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"Join command for workers:\"\n",
    "echo \"$JOIN_CMD --worker\"\n",
    "echo \"\"\n",
    "echo \"Saving to /tmp/join_cmd.txt\"\n",
    "echo \"$JOIN_CMD --worker\" > /tmp/join_cmd.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc2428",
   "metadata": {},
   "source": [
    "### 4.3 Join Spark-01 to Cluster\n",
    "\n",
    "Execute the join command on spark-01. The `--worker` flag ensures it only runs workloads, not control plane components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51552c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Joining Spark-01 (192.168.1.76) to Cluster ===\n",
      "Contacting cluster at 192.168.1.75\n",
      "\n",
      "The node has joined the cluster and will appear in the nodes list in a few seconds.\n",
      "\n",
      "This worker node gets automatically configured with the API server endpoints.\n",
      "If the API servers are behind a loadbalancer please set the '--refresh-interval' to '0s' in:\n",
      "    /var/snap/microk8s/current/args/apiserver-proxy\n",
      "and replace the API server endpoints with the one provided by the loadbalancer in:\n",
      "    /var/snap/microk8s/current/args/traefik/provider.yaml\n",
      "\n",
      "Successfully joined the cluster.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Joining Spark-01 (192.168.1.76) to Cluster ===\"\n",
    "\n",
    "JOIN_CMD=$(cat /tmp/join_cmd.txt)\n",
    "ssh $SSH_OPTS nvidia@192.168.1.76 \"sudo $JOIN_CMD\"\n",
    "\n",
    "echo \"\"\n",
    "sleep 30\n",
    "echo \"Spark-01 join initiated. Wait 30 seconds for node to appear...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa09c682",
   "metadata": {},
   "source": [
    "### 4.4 Join Spark-02 to Cluster\n",
    "\n",
    "Join the second GPU worker node. Each worker needs its own join command (tokens are consumed after use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb8bf1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating new token for Spark-02 ===\n",
      "From the node you wish to join to this cluster, run the following:\n",
      "microk8s join 192.168.1.75:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae\n",
      "\n",
      "Use the '--worker' flag to join a node as a worker not running the control plane, eg:\n",
      "microk8s join 192.168.1.75:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae --worker\n",
      "\n",
      "If the node you are adding is not reachable through the default interface you can use one of the following:\n",
      "microk8s join 192.168.1.75:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:dba1:cc44:2510:46a6:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:36b9:c4a0:a7e9:31ed:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:9d6d:19f6:90da:d7f6:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:ef2d:9464:3557:9dec:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:7a8d:97c:e56c:fe96:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10::48:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:22:bc19:d505:ab6a:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae\n",
      "microk8s join 2600:1702:56e5:4e10:5152:63e:7ef:88e3:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae\n",
      "\n",
      "\n",
      "Extracted: microk8s join 192.168.1.75:25000/5e98a07149da21fdcf0fcb1c2a5dcba0/eee097e0a8ae\n",
      "\n",
      "=== Joining Spark-02 (192.168.1.77) to Cluster ===\n",
      "Contacting cluster at 192.168.1.75\n",
      "\n",
      "The node has joined the cluster and will appear in the nodes list in a few seconds.\n",
      "\n",
      "This worker node gets automatically configured with the API server endpoints.\n",
      "If the API servers are behind a loadbalancer please set the '--refresh-interval' to '0s' in:\n",
      "    /var/snap/microk8s/current/args/apiserver-proxy\n",
      "and replace the API server endpoints with the one provided by the loadbalancer in:\n",
      "    /var/snap/microk8s/current/args/traefik/provider.yaml\n",
      "\n",
      "Successfully joined the cluster.\n",
      "\n",
      "\n",
      "Spark-02 join initiated. Waiting 30 seconds...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Load SSH agent environment\n",
    "with open('/tmp/ssh_agent_env.sh') as f:\n",
    "    for line in f:\n",
    "        if '=' in line and line.startswith('export'):\n",
    "            key, val = line.replace('export ', '').strip().split('=', 1)\n",
    "            os.environ[key] = val\n",
    "\n",
    "SSH_OPTS = ['-o', 'StrictHostKeyChecking=accept-new']\n",
    "\n",
    "print(\"=== Generating new token for Spark-02 ===\")\n",
    "result = subprocess.run(\n",
    "    ['ssh'] + SSH_OPTS + ['nvidia@192.168.1.75', 'microk8s add-node'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"STDERR:\", result.stderr)\n",
    "\n",
    "# Extract join command\n",
    "join_cmd = None\n",
    "for line in result.stdout.split('\\n'):\n",
    "    if 'microk8s join' in line and '192.168.1.75:25000' in line:\n",
    "        join_cmd = line.strip()\n",
    "        break\n",
    "\n",
    "if not join_cmd:\n",
    "    print(\"ERROR: Could not extract join command\")\n",
    "else:\n",
    "    print(f\"\\nExtracted: {join_cmd}\")\n",
    "    \n",
    "    print(\"\\n=== Joining Spark-02 (192.168.1.77) to Cluster ===\")\n",
    "    join_result = subprocess.run(\n",
    "        ['ssh'] + SSH_OPTS + ['nvidia@192.168.1.77', f'sudo {join_cmd} --worker'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    print(join_result.stdout)\n",
    "    if join_result.stderr:\n",
    "        print(\"STDERR:\", join_result.stderr)\n",
    "    \n",
    "    print(\"\\nSpark-02 join initiated. Waiting 30 seconds...\")\n",
    "    time.sleep(30)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee94adf",
   "metadata": {},
   "source": [
    "### 4.5 Verify Cluster Nodes\n",
    "\n",
    "Check that all three nodes are visible and in Ready status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa49fd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cluster Node Status ===\n",
      "NAME         STATUS   ROLES    AGE     VERSION    INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME\n",
      "controller   Ready    <none>   9m31s   v1.31.14   192.168.1.75   <none>        Ubuntu 24.04.3 LTS   6.8.0-90-generic     containerd://1.6.28\n",
      "spark-01     Ready    <none>   94s     v1.31.14   192.168.1.76   <none>        Ubuntu 24.04.3 LTS   6.11.0-1016-nvidia   containerd://1.6.28\n",
      "spark-02     Ready    <none>   49s     v1.31.14   192.168.1.77   <none>        Ubuntu 24.04.3 LTS   6.14.0-1015-nvidia   containerd://1.6.28\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "echo \"=== Cluster Node Status ===\"\n",
    "ssh nvidia@192.168.1.75 'sudo microk8s kubectl get nodes -o wide'\n",
    "\n",
    "echo \"\"\n",
    "echo \"Expected: 3 nodes (controller, spark-01, spark-02) all in Ready status\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ce3ba",
   "metadata": {},
   "source": [
    "## Step 5: Install NVIDIA GPU Operator\n",
    "\n",
    "The GPU Operator automates the deployment of all NVIDIA software components needed for GPU support in Kubernetes:\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| NVIDIA Driver | GPU device driver (if not already installed) |\n",
    "| NVIDIA Container Toolkit | Enables GPU access in containers |\n",
    "| NVIDIA Device Plugin | Exposes GPUs as schedulable resources |\n",
    "| DCGM Exporter | Metrics for monitoring GPU utilization |\n",
    "| GPU Feature Discovery | Labels nodes with GPU properties |\n",
    "\n",
    "This is production-grade GPU support, not just a basic device plugin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c3e12",
   "metadata": {},
   "source": [
    "### 5.1 Add Helm and NVIDIA Helm Repository\n",
    "\n",
    "The GPU Operator is distributed via Helm chart. First, enable Helm in MicroK8s and add the NVIDIA repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56c37f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Enabling Helm in MicroK8s ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pseudo-terminal will not be allocated because stdin is not a terminal.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Ubuntu 24.04.3 LTS (GNU/Linux 6.8.0-90-generic x86_64)\n",
      "\n",
      " * Documentation:  https://help.ubuntu.com\n",
      " * Management:     https://landscape.canonical.com\n",
      " * Support:        https://ubuntu.com/pro\n",
      "\n",
      " System information as of Sun Feb  1 05:01:18 AM UTC 2026\n",
      "\n",
      "  System load:             0.13\n",
      "  Usage of /:              1.7% of 835.58GB\n",
      "  Memory usage:            4%\n",
      "  Swap usage:              0%\n",
      "  Temperature:             41.1 C\n",
      "  Processes:               357\n",
      "  Users logged in:         1\n",
      "  IPv4 address for wlp2s0: 192.168.1.75\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:dba1:cc44:2510:46a6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:36b9:c4a0:a7e9:31ed\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:9d6d:19f6:90da:d7f6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:ef2d:9464:3557:9dec\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:7a8d:97c:e56c:fe96\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10::48\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:22:bc19:d505:ab6a\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:5152:63e:7ef:88e3\n",
      "\n",
      " * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s\n",
      "   just raised the bar for easy, resilient and secure K8s cluster deployment.\n",
      "\n",
      "   https://ubuntu.com/engage/secure-kubernetes-at-the-edge\n",
      "\n",
      "Expanded Security Maintenance for Applications is not enabled.\n",
      "\n",
      "68 updates can be applied immediately.\n",
      "To see these additional updates run: apt list --upgradable\n",
      "\n",
      "Enable ESM Apps to receive additional future security updates.\n",
      "See https://ubuntu.com/esm or run: sudo pro status\n",
      "\n",
      "\n",
      "Addon core/helm3 is already enabled\n",
      "namespace/gpu-operator created\n",
      "\n",
      "Adding NVIDIA Helm repository...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer repository core for addon helm3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"nvidia\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"nvidia\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n",
      "\n",
      "Helm and NVIDIA repo configured.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"=== Enabling Helm in MicroK8s ===\"\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "    sudo microk8s enable helm3\n",
    "    sudo microk8s kubectl create namespace gpu-operator || true\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"Adding NVIDIA Helm repository...\"\n",
    "    sudo microk8s helm3 repo add nvidia https://helm.ngc.nvidia.com/nvidia\n",
    "    sudo microk8s helm3 repo update\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"Helm and NVIDIA repo configured.\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e8ead",
   "metadata": {},
   "source": [
    "### 5.2 Install GPU Operator\n",
    "\n",
    "Deploy the GPU Operator with driver pre-installed mode.\n",
    "\n",
    "**Why `driver.enabled=false`?**\n",
    "\n",
    "DGX Spark nodes ship with NVIDIA drivers pre-installed on the host OS. You can verify this by running `nvidia-smi` directly on the nodes. The GPU Operator supports two driver deployment modes:\n",
    "\n",
    "1. **Containerized drivers** (`driver.enabled=true`): Operator deploys drivers as privileged pods. Use when nodes don't have drivers pre-installed.\n",
    "\n",
    "2. **Pre-installed drivers** (`driver.enabled=false`): Operator uses existing host drivers. Use when drivers are already installed (our case).\n",
    "\n",
    "Setting `driver.enabled=true` on nodes with existing drivers causes conflicts:\n",
    "```\n",
    "modprobe: ERROR: could not insert 'nvidia': File exists\n",
    "```\n",
    "\n",
    "Even with `driver.enabled=false`, the operator still installs:\n",
    "- NVIDIA Container Toolkit (maps GPUs into containers)\n",
    "- Device Plugin (exposes `nvidia.com/gpu` to Kubernetes)\n",
    "- DCGM Exporter (GPU metrics for Prometheus)\n",
    "- GPU Feature Discovery (automatic node labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "324aa1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Installing NVIDIA GPU Operator ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pseudo-terminal will not be allocated because stdin is not a terminal.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Ubuntu 24.04.3 LTS (GNU/Linux 6.8.0-90-generic x86_64)\n",
      "\n",
      " * Documentation:  https://help.ubuntu.com\n",
      " * Management:     https://landscape.canonical.com\n",
      " * Support:        https://ubuntu.com/pro\n",
      "\n",
      " System information as of Sun Feb  1 05:03:00 AM UTC 2026\n",
      "\n",
      "  System load:             0.09\n",
      "  Usage of /:              1.7% of 835.58GB\n",
      "  Memory usage:            4%\n",
      "  Swap usage:              0%\n",
      "  Temperature:             41.0 C\n",
      "  Processes:               358\n",
      "  Users logged in:         1\n",
      "  IPv4 address for wlp2s0: 192.168.1.75\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:dba1:cc44:2510:46a6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:36b9:c4a0:a7e9:31ed\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:9d6d:19f6:90da:d7f6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:ef2d:9464:3557:9dec\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:7a8d:97c:e56c:fe96\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10::48\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:22:bc19:d505:ab6a\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:5152:63e:7ef:88e3\n",
      "\n",
      " * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s\n",
      "   just raised the bar for easy, resilient and secure K8s cluster deployment.\n",
      "\n",
      "   https://ubuntu.com/engage/secure-kubernetes-at-the-edge\n",
      "\n",
      "Expanded Security Maintenance for Applications is not enabled.\n",
      "\n",
      "68 updates can be applied immediately.\n",
      "To see these additional updates run: apt list --upgradable\n",
      "\n",
      "Enable ESM Apps to receive additional future security updates.\n",
      "See https://ubuntu.com/esm or run: sudo pro status\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0201 05:03:04.503665 1366432 warnings.go:70] spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: node-role.kubernetes.io/master is use \"node-role.kubernetes.io/control-plane\" instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: gpu-operator\n",
      "LAST DEPLOYED: Sun Feb  1 05:03:04 2026\n",
      "NAMESPACE: gpu-operator\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "\n",
      "GPU Operator installed. Waiting for pods to be ready...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"=== Installing NVIDIA GPU Operator ===\"\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "    sudo microk8s helm3 install gpu-operator nvidia/gpu-operator \\\n",
    "        --namespace gpu-operator \\\n",
    "        --set driver.enabled=false \\\n",
    "        --set toolkit.enabled=true \\\n",
    "        --wait \\\n",
    "        --timeout 10m\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"GPU Operator installed. Waiting for pods to be ready...\"\n",
    "    sleep 30\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722cdef0",
   "metadata": {},
   "source": [
    "### 5.3 Verify GPU Operator Pods\n",
    "\n",
    "Check that all GPU Operator components are running on the GPU nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ee3bdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU Operator Pods ===\n",
      "NAME                                                          READY   STATUS     RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES\n",
      "gpu-feature-discovery-g7nz6                                   0/1     Init:0/1   0          14m   <none>         spark-02     <none>           <none>\n",
      "gpu-feature-discovery-xz7hm                                   0/1     Init:0/1   0          14m   <none>         spark-01     <none>           <none>\n",
      "gpu-operator-767fdbb8d5-rczrr                                 1/1     Running    0          14m   10.1.168.194   spark-01     <none>           <none>\n",
      "gpu-operator-node-feature-discovery-gc-645d95b6c-r9kpq        1/1     Running    0          14m   10.1.199.129   spark-02     <none>           <none>\n",
      "gpu-operator-node-feature-discovery-master-66995587d9-dxqfc   1/1     Running    0          14m   10.1.199.131   spark-02     <none>           <none>\n",
      "gpu-operator-node-feature-discovery-worker-bshlc              1/1     Running    0          14m   10.1.49.3      controller   <none>           <none>\n",
      "gpu-operator-node-feature-discovery-worker-rkwtx              1/1     Running    0          14m   10.1.199.130   spark-02     <none>           <none>\n",
      "gpu-operator-node-feature-discovery-worker-vnmmz              1/1     Running    0          14m   10.1.168.193   spark-01     <none>           <none>\n",
      "nvidia-container-toolkit-daemonset-vlj6t                      1/1     Running    0          14m   10.1.168.195   spark-01     <none>           <none>\n",
      "nvidia-container-toolkit-daemonset-xw928                      1/1     Running    0          14m   10.1.199.132   spark-02     <none>           <none>\n",
      "nvidia-dcgm-exporter-88q4k                                    0/1     Init:0/1   0          14m   <none>         spark-01     <none>           <none>\n",
      "nvidia-dcgm-exporter-8jlvv                                    0/1     Init:0/1   0          14m   <none>         spark-02     <none>           <none>\n",
      "nvidia-device-plugin-daemonset-7fbqc                          0/1     Init:0/1   0          14m   <none>         spark-02     <none>           <none>\n",
      "nvidia-device-plugin-daemonset-swtvh                          0/1     Init:0/1   0          14m   <none>         spark-01     <none>           <none>\n",
      "nvidia-operator-validator-5bqhs                               0/1     Init:0/4   0          14m   <none>         spark-02     <none>           <none>\n",
      "nvidia-operator-validator-l9c4s                               0/1     Init:0/4   0          14m   <none>         spark-01     <none>           <none>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"=== GPU Operator Pods ===\"\n",
    "ssh nvidia@192.168.1.75 'sudo microk8s kubectl get pods -n gpu-operator -o wide'\n",
    "\n",
    "echo \"\"\n",
    "echo \"Expected: device-plugin, dcgm-exporter, and other operator pods running on spark-01 and spark-02\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6694ae3f",
   "metadata": {},
   "source": [
    "#### Troubleshooting: Pods Stuck in Init Phase\n",
    "\n",
    "If GPU Operator pods remain in `Init:0/1` or `Init:0/4` status for more than 5 minutes, the init containers are waiting for driver validation or GPU availability. Check the logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2a3ebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Configuring NVIDIA Runtime in Containerd ===\n",
      "\n",
      "=== spark-01 ===\n",
      "NVIDIA runtime already configured in containerd\n",
      "Restarting MicroK8s...\n",
      "Restarted.\n",
      "Verifying nvidia-container-runtime is available...\n",
      "/usr/bin/nvidia-container-runtime\n",
      "\n",
      "\n",
      "=== spark-02 ===\n",
      "NVIDIA runtime already configured in containerd\n",
      "Restarting MicroK8s...\n",
      "Restarted.\n",
      "Verifying nvidia-container-runtime is available...\n",
      "/usr/bin/nvidia-container-runtime\n",
      "\n",
      "\n",
      "=== Waiting 30 seconds for pods to reinitialize ===\n",
      "\n",
      "=== Checking GPU Operator pods ===\n",
      "NAME                                                          READY   STATUS     RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES\n",
      "gpu-feature-discovery-g7nz6                                   0/1     Init:0/1   0          35m   <none>         spark-02     <none>           <none>\n",
      "gpu-feature-discovery-xz7hm                                   0/1     Init:0/1   0          35m   <none>         spark-01     <none>           <none>\n",
      "gpu-operator-767fdbb8d5-rczrr                                 1/1     Running    0          35m   10.1.168.194   spark-01     <none>           <none>\n",
      "gpu-operator-node-feature-discovery-gc-645d95b6c-r9kpq        1/1     Running    0          35m   10.1.199.129   spark-02     <none>           <none>\n",
      "gpu-operator-node-feature-discovery-master-66995587d9-dxqfc   1/1     Running    0          35m   10.1.199.131   spark-02     <none>           <none>\n",
      "gpu-operator-node-feature-discovery-worker-bshlc              1/1     Running    0          35m   10.1.49.3      controller   <none>           <none>\n",
      "gpu-operator-node-feature-discovery-worker-rkwtx              1/1     Running    0          35m   10.1.199.130   spark-02     <none>           <none>\n",
      "gpu-operator-node-feature-discovery-worker-vnmmz              1/1     Running    0          35m   10.1.168.193   spark-01     <none>           <none>\n",
      "nvidia-container-toolkit-daemonset-vlj6t                      1/1     Running    0          35m   10.1.168.195   spark-01     <none>           <none>\n",
      "nvidia-container-toolkit-daemonset-xw928                      1/1     Running    0          35m   10.1.199.132   spark-02     <none>           <none>\n",
      "nvidia-dcgm-exporter-88q4k                                    0/1     Init:0/1   0          35m   <none>         spark-01     <none>           <none>\n",
      "nvidia-dcgm-exporter-8jlvv                                    0/1     Init:0/1   0          35m   <none>         spark-02     <none>           <none>\n",
      "nvidia-device-plugin-daemonset-7fbqc                          0/1     Init:0/1   0          35m   <none>         spark-02     <none>           <none>\n",
      "nvidia-device-plugin-daemonset-swtvh                          0/1     Init:0/1   0          35m   <none>         spark-01     <none>           <none>\n",
      "nvidia-operator-validator-5bqhs                               0/1     Init:0/4   0          35m   <none>         spark-02     <none>           <none>\n",
      "nvidia-operator-validator-l9c4s                               0/1     Init:0/4   0          35m   <none>         spark-01     <none>           <none>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Load SSH environment\n",
    "with open('/tmp/ssh_agent_env.sh') as f:\n",
    "    for line in f:\n",
    "        if '=' in line and line.startswith('export'):\n",
    "            key, val = line.replace('export ', '').strip().split('=', 1)\n",
    "            os.environ[key] = val\n",
    "\n",
    "ssh_opts = ['-o', 'StrictHostKeyChecking=accept-new']\n",
    "\n",
    "print(\"=== Configuring NVIDIA Runtime in Containerd ===\")\n",
    "\n",
    "for node_ip, node_name in [(\"192.168.1.76\", \"spark-01\"), (\"192.168.1.77\", \"spark-02\")]:\n",
    "    print(f\"\\n=== {node_name} ===\")\n",
    "    \n",
    "    # Configure containerd for nvidia runtime\n",
    "    config_script = \"\"\"\n",
    "    # Backup existing config\n",
    "    sudo cp /var/snap/microk8s/current/args/containerd-template.toml /var/snap/microk8s/current/args/containerd-template.toml.backup || true\n",
    "    \n",
    "    # Check if nvidia runtime is already configured\n",
    "    if grep -q \"nvidia\" /var/snap/microk8s/current/args/containerd-template.toml 2>/dev/null; then\n",
    "        echo \"NVIDIA runtime already configured in containerd\"\n",
    "    else\n",
    "        echo \"Adding NVIDIA runtime configuration to containerd...\"\n",
    "        \n",
    "        # Add nvidia runtime configuration\n",
    "        sudo tee -a /var/snap/microk8s/current/args/containerd-template.toml > /dev/null <<'EOF'\n",
    "\n",
    "[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia]\n",
    "  runtime_type = \"io.containerd.runc.v2\"\n",
    "  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia.options]\n",
    "    BinaryName = \"/usr/bin/nvidia-container-runtime\"\n",
    "EOF\n",
    "        \n",
    "        echo \"NVIDIA runtime configuration added\"\n",
    "    fi\n",
    "    \n",
    "    # Restart containerd\n",
    "    echo \"Restarting MicroK8s...\"\n",
    "    sudo snap restart microk8s.daemon-containerd\n",
    "    sleep 10\n",
    "    \n",
    "    echo \"Verifying nvidia-container-runtime is available...\"\n",
    "    which nvidia-container-runtime || echo \"nvidia-container-runtime not found in PATH\"\n",
    "    \"\"\"\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        ['ssh'] + ssh_opts + [f'nvidia@{node_ip}', 'bash -s'],\n",
    "        input=config_script,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(f\"STDERR: {result.stderr}\")\n",
    "\n",
    "print(\"\\n=== Waiting 30 seconds for pods to reinitialize ===\")\n",
    "import time\n",
    "time.sleep(30)\n",
    "\n",
    "print(\"\\n=== Checking GPU Operator pods ===\")\n",
    "result = subprocess.run(\n",
    "    ['ssh'] + ssh_opts + ['nvidia@192.168.1.75', \n",
    "     'sudo microk8s kubectl get pods -n gpu-operator -o wide'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e68f55b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking Device Plugin Init Container ===\n",
      "Pod: nvidia-device-plugin-daemonset-7fbqc\n",
      "\n",
      "=== Init Container Logs ===\n",
      "Error from server (BadRequest): container \"toolkit-validation\" in pod \"nvidia-device-plugin-daemonset-7fbqc\" is waiting to start: PodInitializing\n",
      "No logs available\n",
      "\n",
      "=== Pod Description (Events) ===\n",
      "    Type:          HostPath (bare host directory volume)\n",
      "    Path:          /var/run/cdi\n",
      "    HostPathType:  DirectoryOrCreate\n",
      "  mps-root:\n",
      "    Type:          HostPath (bare host directory volume)\n",
      "    Path:          /run/nvidia/mps\n",
      "    HostPathType:  DirectoryOrCreate\n",
      "  mps-shm:\n",
      "    Type:          HostPath (bare host directory volume)\n",
      "    Path:          /run/nvidia/mps/shm\n",
      "    HostPathType:  \n",
      "  kube-api-access-nxpk6:\n",
      "    Type:                    Projected (a volume that contains injected data from multiple sources)\n",
      "    TokenExpirationSeconds:  3607\n",
      "    ConfigMapName:           kube-root-ca.crt\n",
      "    ConfigMapOptional:       <nil>\n",
      "    DownwardAPI:             true\n",
      "QoS Class:                   BestEffort\n",
      "Node-Selectors:              nvidia.com/gpu.deploy.device-plugin=true\n",
      "Tolerations:                 node.kubernetes.io/disk-pressure:NoSchedule op=Exists\n",
      "                             node.kubernetes.io/memory-pressure:NoSchedule op=Exists\n",
      "                             node.kubernetes.io/not-ready:NoExecute op=Exists\n",
      "                             node.kubernetes.io/pid-pressure:NoSchedule op=Exists\n",
      "                             node.kubernetes.io/unreachable:NoExecute op=Exists\n",
      "                             node.kubernetes.io/unschedulable:NoSchedule op=Exists\n",
      "                             nvidia.com/gpu:NoSchedule op=Exists\n",
      "Events:\n",
      "  Type     Reason                  Age                  From     Message\n",
      "  ----     ------                  ----                 ----     -------\n",
      "  Warning  FailedCreatePodSandBox  52s (x164 over 35m)  kubelet  Failed to create pod sandbox: rpc error: code = Unknown desc = failed to get sandbox runtime: no runtime for \"nvidia\" is configured\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Load SSH environment\n",
    "with open('/tmp/ssh_agent_env.sh') as f:\n",
    "    for line in f:\n",
    "        if '=' in line and line.startswith('export'):\n",
    "            key, val = line.replace('export ', '').strip().split('=', 1)\n",
    "            os.environ[key] = val\n",
    "\n",
    "ssh_opts = ['-o', 'StrictHostKeyChecking=accept-new']\n",
    "\n",
    "print(\"=== Checking Device Plugin Init Container ===\")\n",
    "result = subprocess.run(\n",
    "    ['ssh'] + ssh_opts + ['nvidia@192.168.1.75', \"\"\"\n",
    "        POD=$(sudo microk8s kubectl get pods -n gpu-operator -l app=nvidia-device-plugin-daemonset -o jsonpath='{.items[0].metadata.name}')\n",
    "        echo \"Pod: $POD\"\n",
    "        echo \"\"\n",
    "        echo \"=== Init Container Logs ===\"\n",
    "        sudo microk8s kubectl logs -n gpu-operator $POD -c toolkit-validation --tail=100 2>&1 || echo \"No logs available\"\n",
    "        echo \"\"\n",
    "        echo \"=== Pod Description (Events) ===\"\n",
    "        sudo microk8s kubectl describe pod -n gpu-operator $POD | tail -30\n",
    "    \"\"\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"STDERR:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb3d06e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pseudo-terminal will not be allocated because stdin is not a terminal.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Ubuntu 24.04.3 LTS (GNU/Linux 6.8.0-90-generic x86_64)\n",
      "\n",
      " * Documentation:  https://help.ubuntu.com\n",
      " * Management:     https://landscape.canonical.com\n",
      " * Support:        https://ubuntu.com/pro\n",
      "\n",
      " System information as of Sun Feb  1 05:38:55 AM UTC 2026\n",
      "\n",
      "  System load:             0.03\n",
      "  Usage of /:              1.8% of 835.58GB\n",
      "  Memory usage:            5%\n",
      "  Swap usage:              0%\n",
      "  Temperature:             45.0 C\n",
      "  Processes:               352\n",
      "  Users logged in:         1\n",
      "  IPv4 address for wlp2s0: 192.168.1.75\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:dba1:cc44:2510:46a6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:36b9:c4a0:a7e9:31ed\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:9d6d:19f6:90da:d7f6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:ef2d:9464:3557:9dec\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:7a8d:97c:e56c:fe96\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10::48\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:22:bc19:d505:ab6a\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:5152:63e:7ef:88e3\n",
      "\n",
      " * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s\n",
      "   just raised the bar for easy, resilient and secure K8s cluster deployment.\n",
      "\n",
      "   https://ubuntu.com/engage/secure-kubernetes-at-the-edge\n",
      "\n",
      "Expanded Security Maintenance for Applications is not enabled.\n",
      "\n",
      "68 updates can be applied immediately.\n",
      "To see these additional updates run: apt list --upgradable\n",
      "\n",
      "Enable ESM Apps to receive additional future security updates.\n",
      "See https://ubuntu.com/esm or run: sudo pro status\n",
      "\n",
      "\n",
      "=== Checking Init Container Logs ===\n",
      "Checking pod: nvidia-device-plugin-daemonset-7fbqc\n",
      "\n",
      "=== Init Container Logs ===\n",
      "Error from server (BadRequest): container \"toolkit-validation\" in pod \"nvidia-device-plugin-daemonset-7fbqc\" is waiting to start: PodInitializing\n",
      "No logs yet or container not started\n",
      "\n",
      "=== Pod Events ===\n",
      "Events:\n",
      "  Type     Reason                  Age                  From     Message\n",
      "  ----     ------                  ----                 ----     -------\n",
      "  Warning  FailedCreatePodSandBox  64s (x164 over 36m)  kubelet  Failed to create pod sandbox: rpc error: code = Unknown desc = failed to get sandbox runtime: no runtime for \"nvidia\" is configured\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"=== Checking Init Container Logs ===\"\n",
    "\n",
    "# Get one stuck device-plugin pod\n",
    "POD=$(sudo microk8s kubectl get pods -n gpu-operator -l app=nvidia-device-plugin-daemonset -o jsonpath='{.items[0].metadata.name}')\n",
    "\n",
    "if [ -n \"$POD\" ]; then\n",
    "    echo \"Checking pod: $POD\"\n",
    "    echo \"\"\n",
    "    echo \"=== Init Container Logs ===\"\n",
    "    sudo microk8s kubectl logs -n gpu-operator $POD -c toolkit-validation --tail=50 2>&1 || echo \"No logs yet or container not started\"\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"=== Pod Events ===\"\n",
    "    sudo microk8s kubectl describe pod -n gpu-operator $POD | grep -A 10 \"Events:\"\n",
    "else\n",
    "    echo \"No device-plugin pods found\"\n",
    "fi\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd2959",
   "metadata": {},
   "source": [
    "**Common causes and fixes:**\n",
    "\n",
    "1. **Container runtime not configured**: MicroK8s may need containerd restart after toolkit installation\n",
    "2. **Driver paths not accessible**: Container toolkit can't find `/dev/nvidia*` devices\n",
    "3. **AppArmor/SELinux blocking**: Security policies preventing GPU device access\n",
    "\n",
    "Try these fixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f166abce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fix 1: Restart containerd on GPU nodes ===\n",
      "\n",
      "Restarting containerd on spark-01...\n",
      "✗ spark-01 failed: Job for containerd.service failed because the control process exited with error code.\n",
      "See \"systemctl status containerd.service\" and \"journalctl -xeu containerd.service\" for details.\n",
      "\n",
      "\n",
      "Restarting containerd on spark-02...\n",
      "✗ spark-02 failed: Job for containerd.service failed because the control process exited with error code.\n",
      "See \"systemctl status containerd.service\" and \"journalctl -xeu containerd.service\" for details.\n",
      "\n",
      "\n",
      "=== Waiting 30 seconds for pods to reinitialize ===\n",
      "\n",
      "=== Checking pod status ===\n",
      "NAME                                                          READY   STATUS     RESTARTS   AGE\n",
      "gpu-feature-discovery-g7nz6                                   0/1     Init:0/1   0          40m\n",
      "gpu-feature-discovery-xz7hm                                   0/1     Init:0/1   0          40m\n",
      "gpu-operator-767fdbb8d5-rczrr                                 1/1     Running    0          40m\n",
      "gpu-operator-node-feature-discovery-gc-645d95b6c-r9kpq        1/1     Running    0          40m\n",
      "gpu-operator-node-feature-discovery-master-66995587d9-dxqfc   1/1     Running    0          40m\n",
      "gpu-operator-node-feature-discovery-worker-bshlc              1/1     Running    0          40m\n",
      "gpu-operator-node-feature-discovery-worker-rkwtx              1/1     Running    0          40m\n",
      "gpu-operator-node-feature-discovery-worker-vnmmz              1/1     Running    0          40m\n",
      "nvidia-container-toolkit-daemonset-vlj6t                      1/1     Running    0          40m\n",
      "nvidia-container-toolkit-daemonset-xw928                      1/1     Running    0          40m\n",
      "nvidia-dcgm-exporter-88q4k                                    0/1     Init:0/1   0          40m\n",
      "nvidia-dcgm-exporter-8jlvv                                    0/1     Init:0/1   0          40m\n",
      "nvidia-device-plugin-daemonset-7fbqc                          0/1     Init:0/1   0          40m\n",
      "nvidia-device-plugin-daemonset-swtvh                          0/1     Init:0/1   0          40m\n",
      "nvidia-operator-validator-5bqhs                               0/1     Init:0/4   0          40m\n",
      "nvidia-operator-validator-l9c4s                               0/1     Init:0/4   0          40m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Load SSH environment\n",
    "with open('/tmp/ssh_agent_env.sh') as f:\n",
    "    for line in f:\n",
    "        if '=' in line and line.startswith('export'):\n",
    "            key, val = line.replace('export ', '').strip().split('=', 1)\n",
    "            os.environ[key] = val\n",
    "\n",
    "ssh_opts = ['-o', 'StrictHostKeyChecking=accept-new']\n",
    "\n",
    "print(\"=== Fix 1: Restart containerd on GPU nodes ===\")\n",
    "for node_ip, node_name in [(\"192.168.1.76\", \"spark-01\"), (\"192.168.1.77\", \"spark-02\")]:\n",
    "    print(f\"\\nRestarting containerd on {node_name}...\")\n",
    "    result = subprocess.run(\n",
    "        ['ssh'] + ssh_opts + [f'nvidia@{node_ip}', 'sudo systemctl restart containerd'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✓ {node_name} containerd restarted\")\n",
    "    else:\n",
    "        print(f\"✗ {node_name} failed: {result.stderr}\")\n",
    "\n",
    "print(\"\\n=== Waiting 30 seconds for pods to reinitialize ===\")\n",
    "import time\n",
    "time.sleep(30)\n",
    "\n",
    "print(\"\\n=== Checking pod status ===\")\n",
    "result = subprocess.run(\n",
    "    ['ssh'] + ssh_opts + ['nvidia@192.168.1.75', \n",
    "     'sudo microk8s kubectl get pods -n gpu-operator'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f4ff4",
   "metadata": {},
   "source": [
    "#### Fix: Configure NVIDIA Runtime in Containerd\n",
    "\n",
    "If pods fail with `no runtime for \"nvidia\" is configured`, containerd needs explicit configuration for the NVIDIA runtime. The GPU Operator installs the toolkit, but MicroK8s containerd may need manual configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ac6f4",
   "metadata": {},
   "source": [
    "#### Deep Diagnostics: Check What Init Containers Are Waiting For\n",
    "\n",
    "Let's examine exactly what's blocking the init containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e27e8778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPREHENSIVE GPU OPERATOR DIAGNOSTICS ===\n",
      "\n",
      "1. CHECKING INIT CONTAINER ERROR MESSAGES\n",
      "============================================================\n",
      "Checking pod: nvidia-device-plugin-daemonset-7fbqc\n",
      "\n",
      "Init container logs (toolkit-validation):\n",
      "waiting for nvidia container stack to be setup\n",
      "\n",
      "\n",
      "2. CHECKING SPARK-01 CONFIGURATION\n",
      "============================================================\n",
      "A. nvidia-container-runtime installation:\n",
      "  NOT INSTALLED via dpkg\n",
      "/usr/bin/nvidia-container-runtime\n",
      "-rwxr-xr-x 1 root root 5505192 May 30  2025 /usr/bin/nvidia-container-runtime\n",
      "\n",
      "B. MicroK8s containerd active config (not template):\n",
      "    [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia-container-runtime]\n",
      "      # runtime_type is the runtime type to use in containerd e.g. io.containerd.runtime.v1.linux\n",
      "      runtime_type = \"${RUNTIME_TYPE}\"\n",
      "\n",
      "      [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia-container-runtime.options]\n",
      "        BinaryName = \"nvidia-container-runtime\"\n",
      "\n",
      "   [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.kata]\n",
      "--\n",
      "[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia]\n",
      "  runtime_type = \"io.containerd.runc.v2\"\n",
      "  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia.options]\n",
      "    BinaryName = \"/usr/bin/nvidia-container-runtime\"\n",
      "\n",
      "C. Can containerd see nvidia runtime?\n",
      "  No nvidia plugin visible to containerd\n",
      "\n",
      "D. GPU devices accessible?\n",
      "crw-rw-rw- 1 root root 195, 254 Jan 30 11:29 /dev/nvidia-modeset\n",
      "crw-rw-rw- 1 root root 500,   0 Jan 30 11:29 /dev/nvidia-uvm\n",
      "crw-rw-rw- 1 root root 500,   1 Jan 30 11:29 /dev/nvidia-uvm-tools\n",
      "crw-rw-rw- 1 root root 195,   0 Jan 30 11:29 /dev/nvidia0\n",
      "crw-rw-rw- 1 root root 195, 255 Jan 30 11:29 /dev/nvidiactl\n",
      "\n",
      "E. nvidia-smi works on host?\n",
      "NVIDIA GB10\n",
      "\n",
      "\n",
      "2. CHECKING SPARK-02 CONFIGURATION\n",
      "============================================================\n",
      "A. nvidia-container-runtime installation:\n",
      "  NOT INSTALLED via dpkg\n",
      "/usr/bin/nvidia-container-runtime\n",
      "-rwxr-xr-x 1 root root 6367512 Nov 24 09:01 /usr/bin/nvidia-container-runtime\n",
      "\n",
      "B. MicroK8s containerd active config (not template):\n",
      "    [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia-container-runtime]\n",
      "      # runtime_type is the runtime type to use in containerd e.g. io.containerd.runtime.v1.linux\n",
      "      runtime_type = \"${RUNTIME_TYPE}\"\n",
      "\n",
      "      [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia-container-runtime.options]\n",
      "        BinaryName = \"nvidia-container-runtime\"\n",
      "\n",
      "   [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.kata]\n",
      "--\n",
      "[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia]\n",
      "  runtime_type = \"io.containerd.runc.v2\"\n",
      "  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia.options]\n",
      "    BinaryName = \"/usr/bin/nvidia-container-runtime\"\n",
      "\n",
      "C. Can containerd see nvidia runtime?\n",
      "  No nvidia plugin visible to containerd\n",
      "\n",
      "D. GPU devices accessible?\n",
      "crw-rw-rw- 1 root root 195, 254 Jan 30 11:29 /dev/nvidia-modeset\n",
      "crw-rw-rw- 1 root root 500,   0 Jan 30 11:29 /dev/nvidia-uvm\n",
      "crw-rw-rw- 1 root root 500,   1 Jan 30 11:29 /dev/nvidia-uvm-tools\n",
      "crw-rw-rw- 1 root root 195,   0 Jan 30 11:29 /dev/nvidia0\n",
      "crw-rw-rw- 1 root root 195, 255 Jan 30 11:29 /dev/nvidiactl\n",
      "\n",
      "E. nvidia-smi works on host?\n",
      "NVIDIA GB10\n",
      "\n",
      "\n",
      "3. CHECKING TOOLKIT DAEMONSET STATUS\n",
      "============================================================\n",
      "Toolkit pods (these install nvidia-container-toolkit):\n",
      "NAME                                       READY   STATUS    RESTARTS   AGE   IP             NODE       NOMINATED NODE   READINESS GATES\n",
      "nvidia-container-toolkit-daemonset-vlj6t   1/1     Running   0          12h   10.1.168.195   spark-01   <none>           <none>\n",
      "nvidia-container-toolkit-daemonset-xw928   1/1     Running   0          12h   10.1.199.132   spark-02   <none>           <none>\n",
      "\n",
      "Checking if toolkit installation completed:\n",
      "time=\"2026-02-01T05:03:29Z\" level=info msg=\"Completed 'setup' for nvidia-ctk-installer\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Load SSH environment\n",
    "with open('/tmp/ssh_agent_env.sh') as f:\n",
    "    for line in f:\n",
    "        if '=' in line and line.startswith('export'):\n",
    "            key, val = line.replace('export ', '').strip().split('=', 1)\n",
    "            os.environ[key] = val\n",
    "\n",
    "ssh_opts = ['-o', 'StrictHostKeyChecking=accept-new']\n",
    "\n",
    "print(\"=== COMPREHENSIVE GPU OPERATOR DIAGNOSTICS ===\\n\")\n",
    "\n",
    "# Check init container logs first - this tells us the actual error\n",
    "print(\"1. CHECKING INIT CONTAINER ERROR MESSAGES\")\n",
    "print(\"=\" * 60)\n",
    "result = subprocess.run(\n",
    "    ['ssh'] + ssh_opts + ['nvidia@192.168.1.75', \"\"\"\n",
    "        POD=$(sudo microk8s kubectl get pods -n gpu-operator -l app=nvidia-device-plugin-daemonset -o jsonpath='{.items[0].metadata.name}')\n",
    "        echo \"Checking pod: $POD\"\n",
    "        echo \"\"\n",
    "        echo \"Init container logs (toolkit-validation):\"\n",
    "        sudo microk8s kubectl logs -n gpu-operator $POD -c toolkit-validation 2>&1 | tail -20\n",
    "    \"\"\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout)\n",
    "\n",
    "# Check GPU nodes for nvidia-container-runtime and config\n",
    "for node_ip, node_name in [(\"192.168.1.76\", \"spark-01\"), (\"192.168.1.77\", \"spark-02\")]:\n",
    "    print(f\"\\n2. CHECKING {node_name.upper()} CONFIGURATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        ['ssh'] + ssh_opts + [f'nvidia@{node_ip}', \"\"\"\n",
    "            echo \"A. nvidia-container-runtime installation:\"\n",
    "            dpkg -l | grep nvidia-container-runtime || echo \"  NOT INSTALLED via dpkg\"\n",
    "            which nvidia-container-runtime 2>/dev/null || echo \"  NOT in PATH\"\n",
    "            ls -la /usr/bin/nvidia-container-runtime 2>/dev/null || echo \"  NOT found in /usr/bin\"\n",
    "            \n",
    "            echo \"\"\n",
    "            echo \"B. MicroK8s containerd active config (not template):\"\n",
    "            if [ -f /var/snap/microk8s/current/args/containerd-template.toml ]; then\n",
    "                sudo grep -A 3 'runtimes.nvidia' /var/snap/microk8s/current/args/containerd-template.toml 2>/dev/null || echo \"  No nvidia runtime in config\"\n",
    "            else\n",
    "                echo \"  Config file not found\"\n",
    "            fi\n",
    "            \n",
    "            echo \"\"\n",
    "            echo \"C. Can containerd see nvidia runtime?\"\n",
    "            sudo microk8s ctr plugin ls 2>/dev/null | grep nvidia || echo \"  No nvidia plugin visible to containerd\"\n",
    "            \n",
    "            echo \"\"\n",
    "            echo \"D. GPU devices accessible?\"\n",
    "            ls -la /dev/nvidia* 2>/dev/null | head -5 || echo \"  No /dev/nvidia* devices\"\n",
    "            \n",
    "            echo \"\"\n",
    "            echo \"E. nvidia-smi works on host?\"\n",
    "            nvidia-smi --query-gpu=name --format=csv,noheader 2>&1 | head -3\n",
    "        \"\"\"],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    print(result.stdout)\n",
    "\n",
    "print(\"\\n3. CHECKING TOOLKIT DAEMONSET STATUS\")\n",
    "print(\"=\" * 60)\n",
    "result = subprocess.run(\n",
    "    ['ssh'] + ssh_opts + ['nvidia@192.168.1.75', \"\"\"\n",
    "        echo \"Toolkit pods (these install nvidia-container-toolkit):\"\n",
    "        sudo microk8s kubectl get pods -n gpu-operator -l app=nvidia-container-toolkit-daemonset -o wide\n",
    "        echo \"\"\n",
    "        echo \"Checking if toolkit installation completed:\"\n",
    "        POD=$(sudo microk8s kubectl get pods -n gpu-operator -l app=nvidia-container-toolkit-daemonset -o jsonpath='{.items[0].metadata.name}')\n",
    "        sudo microk8s kubectl logs -n gpu-operator $POD --tail=30 2>&1 | grep -E \"(Completed|Error|Installing|Failed)\" || echo \"Check full logs manually\"\n",
    "    \"\"\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fbf0f4",
   "metadata": {},
   "source": [
    "#### FIX: Add nvidia Runtime Configuration\n",
    "\n",
    "**The Problem:** GPU Operator init containers are stuck in `PodInitializing` because they cannot find the required container runtime.\n",
    "\n",
    "**Root Cause:** The GPU Operator expects a containerd runtime named `nvidia`, but MicroK8s on DGX Spark configures a runtime named `nvidia-container-runtime`. This is a naming mismatch.\n",
    "\n",
    "**How to Identify:**\n",
    "```bash\n",
    "# Check containerd config on GPU nodes\n",
    "sudo grep -A 3 'runtimes.nvidia' /var/snap/microk8s/current/args/containerd-template.toml\n",
    "\n",
    "# You'll see:\n",
    "[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia-container-runtime]\n",
    "  # Wrong name! GPU Operator looks for \"nvidia\", not \"nvidia-container-runtime\"\n",
    "```\n",
    "\n",
    "**The Fix:** Add a runtime entry named `nvidia` that points to the same `/usr/bin/nvidia-container-runtime` binary. Both names can coexist - the existing `nvidia-container-runtime` config remains, and we add a `nvidia` alias for GPU Operator compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38dc3ac",
   "metadata": {},
   "source": [
    "### 5.4 Verify GPU Resources Are Visible\n",
    "\n",
    "Check that GPUs are now exposed as allocatable resources on worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8489d7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Adding 'nvidia' Runtime to Containerd Config ===\n",
      "\n",
      "=== Configuring spark-01 ===\n",
      "✓ nvidia runtime already configured\n",
      "Restarting MicroK8s containerd...\n",
      "Restarted.\n",
      "✓ Done\n",
      "\n",
      "\n",
      "=== Configuring spark-02 ===\n",
      "✓ nvidia runtime already configured\n",
      "Restarting MicroK8s containerd...\n",
      "Restarted.\n",
      "✓ Done\n",
      "\n",
      "\n",
      "\n",
      "=== Waiting 45 seconds for pods to restart ===\n",
      "\n",
      "=== Checking Pod Status ===\n",
      "NAME                                                          READY   STATUS      RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES\n",
      "nvidia-cuda-validator-2bnrh                                   0/1     Completed   0          12h   10.1.168.200   spark-01     <none>           <none>\n",
      "nvidia-cuda-validator-gl2hj                                   0/1     Completed   0          12h   10.1.199.137   spark-02     <none>           <none>\n",
      "nvidia-dcgm-exporter-88q4k                                    1/1     Running     0          12h   10.1.168.199   spark-01     <none>           <none>\n",
      "nvidia-dcgm-exporter-8jlvv                                    1/1     Running     0          12h   10.1.199.133   spark-02     <none>           <none>\n",
      "nvidia-device-plugin-daemonset-7fbqc                          1/1     Running     0          12h   10.1.199.134   spark-02     <none>           <none>\n",
      "nvidia-device-plugin-daemonset-swtvh                          1/1     Running     0          12h   10.1.168.198   spark-01     <none>           <none>\n",
      "nvidia-operator-validator-5bqhs                               1/1     Running     0          12h   10.1.199.136   spark-02     <none>           <none>\n",
      "nvidia-operator-validator-l9c4s                               1/1     Running     0          12h   10.1.168.197   spark-01     <none>           <none>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Load SSH environment\n",
    "with open('/tmp/ssh_agent_env.sh') as f:\n",
    "    for line in f:\n",
    "        if '=' in line and line.startswith('export'):\n",
    "            key, val = line.replace('export ', '').strip().split('=', 1)\n",
    "            os.environ[key] = val\n",
    "\n",
    "ssh_opts = ['-o', 'StrictHostKeyChecking=accept-new']\n",
    "\n",
    "print(\"=== Adding 'nvidia' Runtime to Containerd Config ===\\n\")\n",
    "\n",
    "for node_ip, node_name in [(\"192.168.1.76\", \"spark-01\"), (\"192.168.1.77\", \"spark-02\")]:\n",
    "    print(f\"=== Configuring {node_name} ===\")\n",
    "    \n",
    "    fix_script = \"\"\"\n",
    "    # Check if 'nvidia' runtime already exists\n",
    "    if sudo grep -q '\\\\[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia\\\\]' /var/snap/microk8s/current/args/containerd-template.toml; then\n",
    "        echo \"✓ nvidia runtime already configured\"\n",
    "    else\n",
    "        echo \"Adding nvidia runtime configuration...\"\n",
    "        \n",
    "        # Add nvidia runtime (GPU Operator expects this name)\n",
    "        sudo tee -a /var/snap/microk8s/current/args/containerd-template.toml > /dev/null <<'EOF'\n",
    "\n",
    "[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia]\n",
    "  runtime_type = \"io.containerd.runc.v2\"\n",
    "  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.nvidia.options]\n",
    "    BinaryName = \"/usr/bin/nvidia-container-runtime\"\n",
    "EOF\n",
    "        \n",
    "        echo \"✓ nvidia runtime added\"\n",
    "    fi\n",
    "    \n",
    "    # Restart containerd to apply changes\n",
    "    echo \"Restarting MicroK8s containerd...\"\n",
    "    sudo snap restart microk8s.daemon-containerd\n",
    "    sleep 5\n",
    "    \n",
    "    echo \"✓ Done\"\n",
    "    \"\"\"\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        ['ssh'] + ssh_opts + [f'nvidia@{node_ip}', 'bash -s'],\n",
    "        input=fix_script,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(f\"STDERR: {result.stderr}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n=== Waiting 45 seconds for pods to restart ===\")\n",
    "import time\n",
    "time.sleep(45)\n",
    "\n",
    "print(\"\\n=== Checking Pod Status ===\")\n",
    "result = subprocess.run(\n",
    "    ['ssh'] + ssh_opts + ['nvidia@192.168.1.75', \n",
    "     'sudo microk8s kubectl get pods -n gpu-operator -o wide | grep -E \"(NAME|device-plugin|dcgm-exporter|validator)\"'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6cf2b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU Resources on Nodes ===\n",
      "  nvidia.com/gpu:     1\n",
      "  nvidia.com/gpu:     1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"=== GPU Resources on Nodes ===\"\n",
    "ssh nvidia@192.168.1.75 'sudo microk8s kubectl describe nodes | grep -A 10 \"Allocatable:\" | grep -E \"(nvidia.com/gpu|Name:)\"'\n",
    "\n",
    "echo \"\"\n",
    "echo \"Each DGX Spark node should show nvidia.com/gpu: <count>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85aee4e",
   "metadata": {},
   "source": [
    "## Step 6: Test GPU Access\n",
    "\n",
    "Deploy a simple GPU test pod to verify that containers can access GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ea131bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Recreating GPU Test Pod with Explicit Runtime ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pseudo-terminal will not be allocated because stdin is not a terminal.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Ubuntu 24.04.3 LTS (GNU/Linux 6.8.0-90-generic x86_64)\n",
      "\n",
      " * Documentation:  https://help.ubuntu.com\n",
      " * Management:     https://landscape.canonical.com\n",
      " * Support:        https://ubuntu.com/pro\n",
      "\n",
      " System information as of Sun Feb  1 06:09:03 PM UTC 2026\n",
      "\n",
      "  System load:             0.27\n",
      "  Usage of /:              1.8% of 835.58GB\n",
      "  Memory usage:            6%\n",
      "  Swap usage:              0%\n",
      "  Temperature:             47.1 C\n",
      "  Processes:               357\n",
      "  Users logged in:         1\n",
      "  IPv4 address for wlp2s0: 192.168.1.75\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:dba1:cc44:2510:46a6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:36b9:c4a0:a7e9:31ed\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:9d6d:19f6:90da:d7f6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:ef2d:9464:3557:9dec\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:7a8d:97c:e56c:fe96\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10::48\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:22:bc19:d505:ab6a\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:5152:63e:7ef:88e3\n",
      "\n",
      " * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s\n",
      "   just raised the bar for easy, resilient and secure K8s cluster deployment.\n",
      "\n",
      "   https://ubuntu.com/engage/secure-kubernetes-at-the-edge\n",
      "\n",
      "Expanded Security Maintenance for Applications is not enabled.\n",
      "\n",
      "68 updates can be applied immediately.\n",
      "To see these additional updates run: apt list --upgradable\n",
      "\n",
      "Enable ESM Apps to receive additional future security updates.\n",
      "See https://ubuntu.com/esm or run: sudo pro status\n",
      "\n",
      "\n",
      "1. CREATE NVIDIA RUNTIMECLASS\n",
      "==============================\n",
      "runtimeclass.node.k8s.io/nvidia configured\n",
      "\n",
      "2. DELETE EXISTING POD\n",
      "======================\n",
      "pod \"gpu-test\" deleted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: resource runtimeclasses/nvidia is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. CREATE NEW GPU TEST POD\n",
      "==========================\n",
      "pod/gpu-test created\n",
      "\n",
      "Waiting 15 seconds for pod to start...\n",
      "\n",
      "4. POD STATUS\n",
      "=============\n",
      "NAME       READY   STATUS      RESTARTS   AGE   IP             NODE       NOMINATED NODE   READINESS GATES\n",
      "gpu-test   0/1     Completed   0          15s   10.1.199.139   spark-02   <none>           <none>\n",
      "\n",
      "5. POD LOGS (nvidia-smi output)\n",
      "================================\n",
      "Sun Feb  1 18:09:11 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GB10                    On  |   0000000F:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P8              4W /  N/A  | Not Supported          |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "If pod shows 'Completed' status, GPU access is working!\n",
      "If still in error, run: kubectl describe pod gpu-test\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"=== Recreating GPU Test Pod with Explicit Runtime ===\"\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "\n",
    "echo \"1. CREATE NVIDIA RUNTIMECLASS\"\n",
    "echo \"==============================\"\n",
    "cat <<YAML | sudo microk8s kubectl apply -f -\n",
    "apiVersion: node.k8s.io/v1\n",
    "kind: RuntimeClass\n",
    "metadata:\n",
    "  name: nvidia\n",
    "handler: nvidia\n",
    "YAML\n",
    "\n",
    "echo \"\"\n",
    "echo \"2. DELETE EXISTING POD\"\n",
    "echo \"======================\"\n",
    "sudo microk8s kubectl delete pod gpu-test --ignore-not-found\n",
    "sleep 5\n",
    "\n",
    "echo \"\"\n",
    "echo \"3. CREATE NEW GPU TEST POD\"\n",
    "echo \"==========================\"\n",
    "cat <<YAML | sudo microk8s kubectl apply -f -\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: gpu-test\n",
    "spec:\n",
    "  restartPolicy: Never\n",
    "  runtimeClassName: nvidia\n",
    "  containers:\n",
    "  - name: cuda-test\n",
    "    image: nvidia/cuda:12.2.0-base-ubuntu22.04\n",
    "    command: [\"nvidia-smi\"]\n",
    "    resources:\n",
    "      limits:\n",
    "        nvidia.com/gpu: 1\n",
    "YAML\n",
    "\n",
    "echo \"\"\n",
    "echo \"Waiting 15 seconds for pod to start...\"\n",
    "sleep 15\n",
    "\n",
    "echo \"\"\n",
    "echo \"4. POD STATUS\"\n",
    "echo \"=============\"\n",
    "sudo microk8s kubectl get pod gpu-test -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"5. POD LOGS (nvidia-smi output)\"\n",
    "echo \"================================\"\n",
    "sudo microk8s kubectl logs gpu-test 2>&1 || echo \"Pod not ready yet - check status above\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"If pod shows 'Completed' status, GPU access is working!\"\n",
    "echo \"If still in error, run: kubectl describe pod gpu-test\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a436c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking GPU Test Pod Status ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pseudo-terminal will not be allocated because stdin is not a terminal.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Ubuntu 24.04.3 LTS (GNU/Linux 6.8.0-90-generic x86_64)\n",
      "\n",
      " * Documentation:  https://help.ubuntu.com\n",
      " * Management:     https://landscape.canonical.com\n",
      " * Support:        https://ubuntu.com/pro\n",
      "\n",
      " System information as of Sun Feb  1 06:10:19 PM UTC 2026\n",
      "\n",
      "  System load:             0.25\n",
      "  Usage of /:              1.8% of 835.58GB\n",
      "  Memory usage:            6%\n",
      "  Swap usage:              0%\n",
      "  Temperature:             47.8 C\n",
      "  Processes:               363\n",
      "  Users logged in:         1\n",
      "  IPv4 address for wlp2s0: 192.168.1.75\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:dba1:cc44:2510:46a6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:36b9:c4a0:a7e9:31ed\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:9d6d:19f6:90da:d7f6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:ef2d:9464:3557:9dec\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:7a8d:97c:e56c:fe96\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10::48\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:22:bc19:d505:ab6a\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:5152:63e:7ef:88e3\n",
      "\n",
      " * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s\n",
      "   just raised the bar for easy, resilient and secure K8s cluster deployment.\n",
      "\n",
      "   https://ubuntu.com/engage/secure-kubernetes-at-the-edge\n",
      "\n",
      "Expanded Security Maintenance for Applications is not enabled.\n",
      "\n",
      "68 updates can be applied immediately.\n",
      "To see these additional updates run: apt list --upgradable\n",
      "\n",
      "Enable ESM Apps to receive additional future security updates.\n",
      "See https://ubuntu.com/esm or run: sudo pro status\n",
      "\n",
      "\n",
      "Pod Status:\n",
      "NAME       READY   STATUS      RESTARTS   AGE   IP             NODE       NOMINATED NODE   READINESS GATES\n",
      "gpu-test   0/1     Completed   0          70s   10.1.199.139   spark-02   <none>           <none>\n",
      "\n",
      "Pod Events:\n",
      "  ContainersReady             False \n",
      "  PodScheduled                True \n",
      "Volumes:\n",
      "  kube-api-access-bj7nh:\n",
      "    Type:                    Projected (a volume that contains injected data from multiple sources)\n",
      "    TokenExpirationSeconds:  3607\n",
      "    ConfigMapName:           kube-root-ca.crt\n",
      "    ConfigMapOptional:       <nil>\n",
      "    DownwardAPI:             true\n",
      "QoS Class:                   BestEffort\n",
      "Node-Selectors:              <none>\n",
      "Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n",
      "                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\n",
      "Events:\n",
      "  Type    Reason     Age   From               Message\n",
      "  ----    ------     ----  ----               -------\n",
      "  Normal  Scheduled  70s   default-scheduler  Successfully assigned default/gpu-test to spark-02\n",
      "  Normal  Pulled     70s   kubelet            Container image \"nvidia/cuda:12.2.0-base-ubuntu22.04\" already present on machine\n",
      "  Normal  Created    70s   kubelet            Created container: cuda-test\n",
      "  Normal  Started    69s   kubelet            Started container cuda-test\n",
      "\n",
      "If status is Completed, check logs:\n",
      "Sun Feb  1 18:09:11 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GB10                    On  |   0000000F:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P8              4W /  N/A  | Not Supported          |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"=== Checking GPU Test Pod Status ===\"\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"Pod Status:\"\n",
    "sudo microk8s kubectl get pod gpu-test -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"Pod Events:\"\n",
    "sudo microk8s kubectl describe pod gpu-test | tail -20\n",
    "\n",
    "echo \"\"\n",
    "echo \"If status is Completed, check logs:\"\n",
    "sudo microk8s kubectl logs gpu-test 2>&1 || echo \"Pod not completed yet\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd512e5",
   "metadata": {},
   "source": [
    "## Step 7: Deploy vLLM for Inference\n",
    "\n",
    "Now that the cluster is running with GPU support, deploy vLLM to serve LLM inference requests.\n",
    "\n",
    "**Test Plan:**\n",
    "1. Single-node baseline: Deploy Llama 3.1 8B on one GPU\n",
    "2. Measure baseline throughput (tokens/sec)\n",
    "3. Deploy distributed vLLM with tensor parallelism across both nodes\n",
    "4. Compare performance and validate the InfiniBand/RDMA link matters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88068ddb",
   "metadata": {},
   "source": [
    "### 7.1 Deploy vLLM Single-Node Baseline\n",
    "\n",
    "Start with a single-GPU deployment to establish baseline performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00672d0e",
   "metadata": {},
   "source": [
    "### 7.0 Set Up Hugging Face Token\n",
    "\n",
    "Load your Hugging Face token from environment or `.env` file. The token is needed to download gated models like Llama.\n",
    "\n",
    "**Option 1:** Set environment variable before starting Jupyter:\n",
    "```bash\n",
    "export HF_TOKEN=\"hf_...\"\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "**Option 2:** Create `.env` file in workspace root:\n",
    "```bash\n",
    "HF_TOKEN=hf_...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81806d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to load from environment first\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "\n",
    "# If not in environment, try .env file\n",
    "if not hf_token:\n",
    "    env_file = Path.cwd() / '.env'\n",
    "    if env_file.exists():\n",
    "        with open(env_file) as f:\n",
    "            for line in f:\n",
    "                if line.startswith('HF_TOKEN='):\n",
    "                    hf_token = line.split('=', 1)[1].strip()\n",
    "                    break\n",
    "\n",
    "if hf_token:\n",
    "    print(f\"✓ Hugging Face token loaded (starts with: {hf_token[:10]}...)\")\n",
    "    os.environ['HF_TOKEN'] = hf_token\n",
    "else:\n",
    "    print(\"⚠ No HF_TOKEN found in environment or .env file\")\n",
    "    print(\"  Models may fail to download if they require authentication\")\n",
    "    hf_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3076f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Load SSH environment\n",
    "with open('/tmp/ssh_agent_env.sh') as f:\n",
    "    for line in f:\n",
    "        if '=' in line and line.startswith('export'):\n",
    "            key, val = line.replace('export ', '').strip().split('=', 1)\n",
    "            os.environ[key] = val\n",
    "\n",
    "# Get HF token from environment (set in previous cell)\n",
    "hf_token = os.getenv('HF_TOKEN', '')\n",
    "\n",
    "print(\"=== Deploying vLLM Single-Node (Llama 3.1 8B) ===\")\n",
    "\n",
    "yaml_content = f\"\"\"apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: vllm-single\n",
    "  labels:\n",
    "    app: vllm-single\n",
    "spec:\n",
    "  containers:\n",
    "  - name: vllm\n",
    "    image: vllm/vllm-openai:latest\n",
    "    command:\n",
    "      - python3\n",
    "      - -m\n",
    "      - vllm.entrypoints.openai.api_server\n",
    "      - --model\n",
    "      - meta-llama/Llama-3.1-8B-Instruct\n",
    "      - --host\n",
    "      - \"0.0.0.0\"\n",
    "      - --port\n",
    "      - \"8000\"\n",
    "    ports:\n",
    "    - containerPort: 8000\n",
    "      name: http\n",
    "    resources:\n",
    "      limits:\n",
    "        nvidia.com/gpu: 1\n",
    "    env:\n",
    "    - name: HUGGING_FACE_HUB_TOKEN\n",
    "      value: \"{hf_token}\"\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: vllm-single-svc\n",
    "spec:\n",
    "  selector:\n",
    "    app: vllm-single\n",
    "  ports:\n",
    "  - port: 8000\n",
    "    targetPort: 8000\n",
    "  type: ClusterIP\n",
    "\"\"\"\n",
    "\n",
    "ssh_opts = ['-o', 'StrictHostKeyChecking=accept-new']\n",
    "\n",
    "# Apply the YAML via SSH\n",
    "result = subprocess.run(\n",
    "    ['ssh'] + ssh_opts + ['nvidia@192.168.1.75', \n",
    "     f'sudo microk8s kubectl apply -f - <<EOF\\n{yaml_content}\\nEOF'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"STDERR:\", result.stderr)\n",
    "\n",
    "print(\"\\nvLLM pod and service created.\")\n",
    "print(\"Model download may take several minutes on first run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de3569",
   "metadata": {},
   "source": [
    "### 7.2 Monitor vLLM Startup\n",
    "\n",
    "Watch the pod logs to see when the model is loaded and ready to serve requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba750dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"=== vLLM Pod Status ===\"\n",
    "sudo microk8s kubectl get pod vllm-single -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Last 50 Lines of Logs ===\"\n",
    "sudo microk8s kubectl logs vllm-single --tail=50 || echo \"Pod not ready yet\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520dc109",
   "metadata": {},
   "source": [
    "### 7.3 Test vLLM Endpoint\n",
    "\n",
    "Send a test request to the vLLM OpenAI-compatible API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85505c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"=== Testing vLLM Inference ===\"\n",
    "curl -X POST http://vllm-single-svc:8000/v1/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"model\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"prompt\": \"Explain RDMA in one sentence:\",\n",
    "    \"max_tokens\": 50,\n",
    "    \"temperature\": 0.7\n",
    "  }' | python3 -m json.tool\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202085e",
   "metadata": {},
   "source": [
    "### 7.4 Benchmark Single-Node Performance\n",
    "\n",
    "Use a simple benchmark script to measure tokens per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f0bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def benchmark_vllm(endpoint, num_requests=10, prompt=\"Explain distributed systems:\", max_tokens=100):\n",
    "    \"\"\"Simple throughput benchmark for vLLM\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"Running {num_requests} requests...\")\n",
    "    for i in range(num_requests):\n",
    "        start = time.time()\n",
    "        \n",
    "        response = requests.post(\n",
    "            f\"{endpoint}/v1/completions\",\n",
    "            json={\n",
    "                \"model\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "                \"prompt\": prompt,\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\": 0.7\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            tokens = data['usage']['completion_tokens']\n",
    "            tokens_per_sec = tokens / elapsed if elapsed > 0 else 0\n",
    "            \n",
    "            results.append({\n",
    "                'request': i + 1,\n",
    "                'tokens': tokens,\n",
    "                'time_sec': elapsed,\n",
    "                'tokens_per_sec': tokens_per_sec\n",
    "            })\n",
    "            \n",
    "            print(f\"  Request {i+1}: {tokens} tokens in {elapsed:.2f}s ({tokens_per_sec:.1f} tok/s)\")\n",
    "        else:\n",
    "            print(f\"  Request {i+1}: ERROR {response.status_code}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    if results:\n",
    "        avg_tokens_per_sec = sum(r['tokens_per_sec'] for r in results) / len(results)\n",
    "        total_tokens = sum(r['tokens'] for r in results)\n",
    "        total_time = sum(r['time_sec'] for r in results)\n",
    "        \n",
    "        print(f\"\\n=== Single-Node Baseline Results ===\")\n",
    "        print(f\"Total requests: {len(results)}\")\n",
    "        print(f\"Total tokens: {total_tokens}\")\n",
    "        print(f\"Total time: {total_time:.2f}s\")\n",
    "        print(f\"Average throughput: {avg_tokens_per_sec:.1f} tokens/sec\")\n",
    "        \n",
    "        return avg_tokens_per_sec\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# Run benchmark (update endpoint URL after deployment)\n",
    "# endpoint = \"http://vllm-single-svc:8000\"\n",
    "# baseline_throughput = benchmark_vllm(endpoint)\n",
    "\n",
    "print(\"NOTE: Update endpoint URL and uncomment to run benchmark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbfde55",
   "metadata": {},
   "source": [
    "## Step 8: Deploy vLLM with Tensor Parallelism\n",
    "\n",
    "Deploy vLLM distributed across both DGX Spark nodes using tensor parallelism. This requires:\n",
    "- Ray cluster for coordination\n",
    "- NCCL over your InfiniBand/RoCE link for GPU-to-GPU communication\n",
    "- Larger model that benefits from distribution (Llama 3.1 70B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a99d24",
   "metadata": {},
   "source": [
    "### 8.1 Label GPU Nodes\n",
    "\n",
    "Add node labels to schedule distributed vLLM pods correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"=== Labeling GPU Nodes ===\"\n",
    "sudo microk8s kubectl label node spark-01 nvidia.com/gpu.present=true --overwrite\n",
    "sudo microk8s kubectl label node spark-02 nvidia.com/gpu.present=true --overwrite\n",
    "\n",
    "echo \"\"\n",
    "sudo microk8s kubectl get nodes --show-labels | grep \"nvidia.com/gpu\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73449080",
   "metadata": {},
   "source": [
    "### 8.2 Notes on Distributed vLLM Deployment\n",
    "\n",
    "Distributed vLLM deployment requires additional setup:\n",
    "\n",
    "**Option 1: KubeRay Operator**\n",
    "- Deploy KubeRay operator to manage Ray clusters\n",
    "- Create RayCluster resource with worker nodes on both Spark nodes\n",
    "- Deploy vLLM with `--tensor-parallel-size=2`\n",
    "\n",
    "**Option 2: Manual Multi-Pod Deployment**\n",
    "- StatefulSet with pod affinity to pin to specific nodes\n",
    "- Shared storage for model weights (NFS or similar)\n",
    "- NCCL configuration to use InfiniBand\n",
    "\n",
    "**Key Configuration:**\n",
    "```bash\n",
    "# vLLM command for tensor parallelism\n",
    "python -m vllm.entrypoints.openai.api_server \\\n",
    "  --model meta-llama/Llama-3.1-70B-Instruct \\\n",
    "  --tensor-parallel-size 2 \\\n",
    "  --host 0.0.0.0 \\\n",
    "  --port 8000\n",
    "```\n",
    "\n",
    "**NCCL Environment Variables for InfiniBand:**\n",
    "```yaml\n",
    "- name: NCCL_IB_DISABLE\n",
    "  value: \"0\"\n",
    "- name: NCCL_SOCKET_IFNAME\n",
    "  value: \"ib0\"  # or your IB interface name\n",
    "- name: NCCL_DEBUG\n",
    "  value: \"INFO\"\n",
    "```\n",
    "\n",
    "This is the critical link to your InfiniBand article—NCCL will use RDMA over your high-speed interconnect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357582e1",
   "metadata": {},
   "source": [
    "## Step 9: Add Monitoring with Prometheus and DCGM\n",
    "\n",
    "Monitor GPU utilization and inference metrics using Prometheus and NVIDIA DCGM Exporter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df3169",
   "metadata": {},
   "source": [
    "### 9.1 Enable Prometheus in MicroK8s\n",
    "\n",
    "MicroK8s includes a Prometheus addon for monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"=== Enabling Prometheus ===\"\n",
    "sudo microk8s enable prometheus\n",
    "\n",
    "echo \"\"\n",
    "echo \"Waiting for Prometheus pods to start...\"\n",
    "sleep 30\n",
    "sudo microk8s kubectl get pods -n observability\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e05f75",
   "metadata": {},
   "source": [
    "### 9.2 Verify DCGM Exporter\n",
    "\n",
    "The GPU Operator includes DCGM Exporter, which exposes GPU metrics to Prometheus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd59f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"=== DCGM Exporter Pods ===\"\n",
    "sudo microk8s kubectl get pods -n gpu-operator | grep dcgm\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Sample GPU Metrics ===\"\n",
    "# Get one DCGM exporter pod\n",
    "DCGM_POD=$(sudo microk8s kubectl get pods -n gpu-operator -l app=nvidia-dcgm-exporter -o jsonpath='{.items[0].metadata.name}')\n",
    "\n",
    "if [ -n \"$DCGM_POD\" ]; then\n",
    "    echo \"Fetching metrics from $DCGM_POD...\"\n",
    "    sudo microk8s kubectl exec -n gpu-operator $DCGM_POD -- curl -s localhost:9400/metrics | grep \"DCGM_FI_DEV_GPU_UTIL\" | head -5\n",
    "else\n",
    "    echo \"DCGM Exporter not found\"\n",
    "fi\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c7dee5",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook established the foundation:\n",
    "\n",
    "| Component | Status |\n",
    "|-----------|--------|\n",
    "| 3-node MicroK8s cluster | ✓ Deployed |\n",
    "| GPU Operator | ✓ Installed |\n",
    "| Single-node vLLM | ✓ Configured |\n",
    "| Monitoring (Prometheus/DCGM) | ✓ Enabled |\n",
    "| Distributed vLLM | Documented (requires additional setup) |\n",
    "\n",
    "**To complete the project:**\n",
    "\n",
    "1. **Deploy distributed vLLM** using KubeRay or StatefulSet\n",
    "2. **Configure NCCL** to use your InfiniBand link (`enp1s0f0np0`/`enp1s0f1np1`)\n",
    "3. **Run benchmarks** comparing single-node vs distributed throughput\n",
    "4. **Measure latency** impact of tensor parallelism over RDMA\n",
    "5. **Create dashboards** in Grafana for GPU utilization\n",
    "\n",
    "**The compelling article** writes itself once you have these numbers:\n",
    "- \"vLLM on 2 DGX Spark nodes: X tokens/sec with Llama 3.1 70B\"\n",
    "- \"Why 96 Gbps RDMA matters: tensor parallelism latency comparison\"\n",
    "- \"Cost analysis: $Y home lab vs $Z cloud GPU hours\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e32f53",
   "metadata": {},
   "source": [
    "## Troubleshooting: Complete Cluster Reset\n",
    "\n",
    "If the cluster becomes corrupted or you encounter version skew issues between nodes, you can perform a complete reset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92066e2e",
   "metadata": {},
   "source": [
    "### Symptoms Requiring Reset\n",
    "\n",
    "- Worker nodes show `NotReady` status in `kubectl get nodes`\n",
    "- GPU Operator pods stuck in `CrashLoopBackOff` or `ContainerCreating`\n",
    "- Version mismatch between controller and workers (e.g., v1.32 vs v1.31)\n",
    "- Different containerd versions across nodes\n",
    "\n",
    "**Cause:** Kubernetes requires control plane and worker nodes within ±1 minor version. If you upgraded the controller but not the workers, or installed different MicroK8s channels, reset and reinstall with the same version on all nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508a233",
   "metadata": {},
   "source": [
    "### Step 1: Remove Worker Nodes from Cluster\n",
    "\n",
    "Before resetting, remove the worker nodes from the cluster on the controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c1dbe112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Removing Worker Nodes from Cluster ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pseudo-terminal will not be allocated because stdin is not a terminal.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Ubuntu 24.04.3 LTS (GNU/Linux 6.8.0-90-generic x86_64)\n",
      "\n",
      " * Documentation:  https://help.ubuntu.com\n",
      " * Management:     https://landscape.canonical.com\n",
      " * Support:        https://ubuntu.com/pro\n",
      "\n",
      " System information as of Sun Feb  1 11:11:53 PM UTC 2026\n",
      "\n",
      "  System load:             0.06\n",
      "  Usage of /:              1.8% of 835.58GB\n",
      "  Memory usage:            6%\n",
      "  Swap usage:              0%\n",
      "  Temperature:             45.6 C\n",
      "  Processes:               356\n",
      "  Users logged in:         1\n",
      "  IPv4 address for wlp2s0: 192.168.1.75\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:90ac:c2f6:7999:5aef\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:dba1:cc44:2510:46a6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:36b9:c4a0:a7e9:31ed\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:9d6d:19f6:90da:d7f6\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:ef2d:9464:3557:9dec\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:7a8d:97c:e56c:fe96\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10::48\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:22:bc19:d505:ab6a\n",
      "  IPv6 address for wlp2s0: 2600:1702:56e5:4e10:5152:63e:7ef:88e3\n",
      "\n",
      "\n",
      "Expanded Security Maintenance for Applications is not enabled.\n",
      "\n",
      "68 updates can be applied immediately.\n",
      "To see these additional updates run: apt list --upgradable\n",
      "\n",
      "Enable ESM Apps to receive additional future security updates.\n",
      "See https://ubuntu.com/esm or run: sudo pro status\n",
      "\n",
      "\n",
      "Removing spark-01...\n",
      "Removing spark-02...\n",
      "\n",
      "Remaining nodes:\n",
      "NAME         STATUS   ROLES    AGE   VERSION\n",
      "controller   Ready    <none>   18h   v1.31.14\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Removing Worker Nodes from Cluster ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.75 << 'EOF'\n",
    "    echo \"Removing spark-01...\"\n",
    "    microk8s remove-node spark-01 || echo \"Node already removed or not found\"\n",
    "    \n",
    "    echo \"Removing spark-02...\"\n",
    "    microk8s remove-node spark-02 || echo \"Node already removed or not found\"\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"Remaining nodes:\"\n",
    "    microk8s kubectl get nodes\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11fec14",
   "metadata": {},
   "source": [
    "### Step 2: Leave Cluster from Worker Nodes\n",
    "\n",
    "Each worker node must leave the cluster before it can be fully reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa3d9c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Spark-01: Leaving Cluster ===\n",
      "Configuring services.\n",
      "Generating new cluster certificates.\n",
      "Waiting for node to start.  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Spark-01: Leaving Cluster ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.76 'sudo microk8s leave' || echo \"Already left or not in cluster\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Spark-02: Leaving Cluster ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.77 'sudo microk8s leave' || echo \"Already left or not in cluster\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Workers have left the cluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df22de9e",
   "metadata": {},
   "source": [
    "### Step 3: Purge MicroK8s from All Nodes\n",
    "\n",
    "Remove MicroK8s completely, including all configuration, data, and cluster state. The `--purge` flag ensures a clean slate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15351f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Purging MicroK8s from All Nodes ===\n",
      "\n",
      "Controller (192.168.1.75):\n",
      "  ✓ Controller purged successfully\n",
      "\n",
      "Spark-01 (192.168.1.76):\n",
      "  ✓ Spark-01 purged successfully\n",
      "\n",
      "Spark-02 (192.168.1.77):\n",
      "  ✓ Spark-02 purged successfully\n",
      "\n",
      "=== Cleanup Complete ===\n",
      "All nodes processed. Ready for fresh installation.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Load SSH environment\n",
    "with open('/tmp/ssh_agent_env.sh') as f:\n",
    "    for line in f:\n",
    "        if '=' in line and line.startswith('export'):\n",
    "            key, val = line.replace('export ', '').strip().split('=', 1)\n",
    "            os.environ[key] = val\n",
    "\n",
    "ssh_opts = ['-o', 'StrictHostKeyChecking=accept-new']\n",
    "\n",
    "print(\"=== Purging MicroK8s from All Nodes ===\\n\")\n",
    "\n",
    "nodes = [\n",
    "    (\"192.168.1.75\", \"Controller\"),\n",
    "    (\"192.168.1.76\", \"Spark-01\"),\n",
    "    (\"192.168.1.77\", \"Spark-02\")\n",
    "]\n",
    "\n",
    "for ip, name in nodes:\n",
    "    print(f\"{name} ({ip}):\")\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['ssh'] + ssh_opts + [f'nvidia@{ip}', 'sudo snap remove microk8s --purge'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"  ✓ {name} purged successfully\")\n",
    "        else:\n",
    "            if \"is not installed\" in result.stderr or \"is not installed\" in result.stdout:\n",
    "                print(f\"  ✓ {name} - MicroK8s not installed\")\n",
    "            else:\n",
    "                print(f\"  ✗ {name} purge failed\")\n",
    "                if result.stderr:\n",
    "                    print(f\"  Error: {result.stderr.strip()}\")\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"  ✗ {name} - SSH timeout\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ {name} - Error: {e}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== Cleanup Complete ===\")\n",
    "print(\"All nodes processed. Ready for fresh installation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e121881",
   "metadata": {},
   "source": [
    "### After Reset: Reinstall with Consistent Versions\n",
    "\n",
    "After purging, reinstall MicroK8s using **the same channel** on all three nodes. This prevents version skew issues.\n",
    "\n",
    "**Critical:** Use the same channel (e.g., `1.32/stable`) on all nodes. Go back to cell 18 (Step 3.1: Install MicroK8s on the Controller) and proceed through the installation steps with the updated channel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
