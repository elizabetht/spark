{
  "timestamp": "2026-02-05T22:53:23.380612",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "config": {
    "tensor_parallel_size": 1,
    "gpu_memory_utilization": 0.3
  },
  "single_request": {
    "latency_ms": 6874.111652374268,
    "tokens": 200,
    "throughput_tokens_per_sec": 14.547334267615618
  },
  "batch_processing": {
    "batch_size": 8,
    "total_tokens": 800,
    "throughput_tokens_per_sec": 122.45442751503955,
    "avg_latency_ms": 816.6303336620331
  },
  "memory": {
    "baseline_mb": 0,
    "peak_mb": 0,
    "inference_mb": 0,
    "memory_per_token_mb": 0
  }
}