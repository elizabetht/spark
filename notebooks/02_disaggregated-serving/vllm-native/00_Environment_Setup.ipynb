{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f39894",
   "metadata": {},
   "source": [
    "# Environment Setup for Disaggregated Serving\n",
    "\n",
    "Before building a disaggregated inference system, we need a working baseline environment. This notebook sets up two DGX Spark nodes for distributed LLM inference.\n",
    "\n",
    "## What We're Setting Up\n",
    "\n",
    "- **Node 1 (spark-01)**: Primary inference node (prefill)\n",
    "- **Node 2 (spark-02)**: Secondary inference node (decode)\n",
    "- **Network**: RDMA-capable RoCE link between nodes\n",
    "- **Software**: PyTorch, vLLM, NIXL, monitoring tools\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Disaggregated serving splits the inference pipeline across multiple machines. Before we optimize with RDMA and cache-aware routing, we need working compute and networking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d9715",
   "metadata": {},
   "source": [
    "## Step 1: Verify Node Configuration\n",
    "\n",
    "Check both nodes are accessible and have the expected hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ded05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: spark-01\n",
      "GPUs: 1x NVIDIA GB10\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import socket\n",
    "\n",
    "def get_hostname():\n",
    "    return socket.gethostname()\n",
    "\n",
    "def get_gpu_info():\n",
    "    \"\"\"Get GPU count and model from nvidia-smi\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=name,count', '--format=csv,noheader'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        gpu_info = result.stdout.strip().split('\\n')\n",
    "        return len(gpu_info), gpu_info[0].split(',')[0] if gpu_info else \"Unknown\"\n",
    "    except Exception as e:\n",
    "        return 0, str(e)\n",
    "\n",
    "hostname = get_hostname()\n",
    "gpu_count, gpu_model = get_gpu_info()\n",
    "\n",
    "print(f\"Hostname: {hostname}\")\n",
    "print(f\"GPUs: {gpu_count}x {gpu_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae4ac5",
   "metadata": {},
   "source": [
    "## Step 2: Check RDMA Network (Both Nodes)\n",
    "\n",
    "Verify RDMA-capable interfaces are present and active on both nodes. NIXL uses these for GPU-to-GPU KV cache transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6da0df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-01 (192.168.100.10) - RDMA devices:\n",
      "\n",
      "  ✓ roceP2p1s0f0: Active\n",
      "  ✓ roceP2p1s0f1: Active\n",
      "  ✓ rocep1s0f0: Active\n",
      "  ✓ rocep1s0f1: Active\n",
      "\n",
      "spark-02 (192.168.100.11) - RDMA devices:\n",
      "\n",
      "  ✓ roceP2p1s0f0: Active\n",
      "  ✓ roceP2p1s0f1: Active\n",
      "  ✓ rocep1s0f0: Active\n",
      "  ✓ rocep1s0f1: Active\n",
      "\n",
      "✓ Both nodes have active RDMA interfaces (4 on spark-01, 4 on spark-02).\n"
     ]
    }
   ],
   "source": [
    "# Node IPs - used by this cell and subsequent cells\n",
    "NODE1_IP = \"192.168.100.10\"  # spark-01\n",
    "NODE2_IP = \"192.168.100.11\"  # spark-02\n",
    "\n",
    "def check_ib_devices():\n",
    "    \"\"\"List InfiniBand/RoCE devices using ibstat.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['ibstat', '-l'],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        devices = result.stdout.strip().split('\\n')\n",
    "        return [d for d in devices if d]\n",
    "    except subprocess.CalledProcessError:\n",
    "        return []\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "\n",
    "def check_ib_link_state(device):\n",
    "    \"\"\"Check if an RDMA device port is active.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['ibstat', device],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        return \"State: Active\" in result.stdout\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def check_remote_ib_devices(remote_ip):\n",
    "    \"\"\"List RDMA devices and their link state on a remote node via SSH.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['ssh', '-o', 'ConnectTimeout=5', f'nvidia@{remote_ip}',\n",
    "             'ibstat -l 2>/dev/null && echo \"---\" && for d in $(ibstat -l 2>/dev/null); do echo \"$d: $(ibstat $d 2>/dev/null | grep -c \\\"State: Active\\\") active ports\"; done'],\n",
    "            capture_output=True, text=True, timeout=15\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            return [], \"ibstat not available\"\n",
    "\n",
    "        lines = result.stdout.strip().split('\\n')\n",
    "        separator = lines.index('---') if '---' in lines else len(lines)\n",
    "        devices = [d for d in lines[:separator] if d]\n",
    "        states = lines[separator+1:] if separator < len(lines) else []\n",
    "        return devices, states\n",
    "    except Exception as e:\n",
    "        return [], str(e)\n",
    "\n",
    "# --- Check spark-01 (local) ---\n",
    "print(f\"spark-01 ({NODE1_IP}) - RDMA devices:\\n\")\n",
    "ib_devices = check_ib_devices()\n",
    "active_local = 0\n",
    "for device in ib_devices:\n",
    "    active = check_ib_link_state(device)\n",
    "    state = \"Active\" if active else \"Down\"\n",
    "    status = \"✓\" if active else \"✗\"\n",
    "    print(f\"  {status} {device}: {state}\")\n",
    "    if active:\n",
    "        active_local += 1\n",
    "\n",
    "if not ib_devices:\n",
    "    print(\"  ✗ No RDMA devices found (ibstat not available or no devices)\")\n",
    "\n",
    "# --- Check spark-02 (remote) ---\n",
    "print(f\"\\nspark-02 ({NODE2_IP}) - RDMA devices:\\n\")\n",
    "remote_devices, remote_states = check_remote_ib_devices(NODE2_IP)\n",
    "active_remote = 0\n",
    "\n",
    "if isinstance(remote_states, str):\n",
    "    # Error case\n",
    "    print(f\"  ✗ {remote_states}\")\n",
    "elif remote_devices:\n",
    "    for state_line in remote_states:\n",
    "        if state_line.strip():\n",
    "            has_active = \"0 active\" not in state_line\n",
    "            status = \"✓\" if has_active else \"✗\"\n",
    "            dev_name = state_line.split(':')[0].strip()\n",
    "            state_text = \"Active\" if has_active else \"Down\"\n",
    "            print(f\"  {status} {dev_name}: {state_text}\")\n",
    "            if has_active:\n",
    "                active_remote += 1\n",
    "else:\n",
    "    print(\"  ✗ No RDMA devices found\")\n",
    "\n",
    "# Summary\n",
    "print()\n",
    "if active_local > 0 and active_remote > 0:\n",
    "    print(f\"✓ Both nodes have active RDMA interfaces ({active_local} on spark-01, {active_remote} on spark-02).\")\n",
    "elif active_local > 0:\n",
    "    print(f\"✗ spark-02 has no active RDMA interfaces. NIXL requires RDMA on both nodes.\")\n",
    "elif active_remote > 0:\n",
    "    print(f\"✗ spark-01 has no active RDMA interfaces. NIXL requires RDMA on both nodes.\")\n",
    "else:\n",
    "    print(\"✗ Neither node has active RDMA interfaces. KV cache transfer will fall back to TCP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8c0ee",
   "metadata": {},
   "source": [
    "## Step 3: Test Network Connectivity\n",
    "\n",
    "Ping the other node to verify basic network connectivity. Update the IP address for your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c05f59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing connectivity to remote node (192.168.100.11)...\n",
      "✓ Remote node reachable (avg latency: 1.253 ms)\n"
     ]
    }
   ],
   "source": [
    "# NODE1_IP and NODE2_IP are defined in Step 2\n",
    "\n",
    "def ping_host(ip_address, count=4):\n",
    "    \"\"\"Test network connectivity to remote host\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['ping', '-c', str(count), ip_address],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=10\n",
    "        )\n",
    "        # Extract average latency from ping output\n",
    "        for line in result.stdout.split('\\n'):\n",
    "            if 'avg' in line:\n",
    "                # Format: min/avg/max/mdev = 0.123/0.456/0.789/0.012 ms\n",
    "                avg_latency = line.split('=')[1].strip().split('/')[1]\n",
    "                return True, f\"{avg_latency} ms\"\n",
    "        return result.returncode == 0, \"success\"\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "current_node = get_hostname()\n",
    "remote_ip = NODE2_IP if \"01\" in current_node else NODE1_IP\n",
    "\n",
    "print(f\"Testing connectivity to remote node ({remote_ip})...\")\n",
    "success, latency = ping_host(remote_ip)\n",
    "\n",
    "if success:\n",
    "    print(f\"✓ Remote node reachable (avg latency: {latency})\")\n",
    "else:\n",
    "    print(f\"✗ Cannot reach remote node: {latency}\")\n",
    "    print(\"  Check network configuration and IP addresses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6654aaa6",
   "metadata": {},
   "source": [
    "## Step 4: Verify Core Dependencies (Both Nodes)\n",
    "\n",
    "Both nodes need PyTorch, vLLM, and Transformers installed. Prefill runs on spark-01, decode runs on spark-02, and both load the same model. This cell checks spark-01 (local) and then verifies spark-02 via SSH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53af46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-01 (192.168.100.10) - local packages:\n",
      "\n",
      "  ✓ torch: PyTorch (deep learning framework)\n",
      "  ✓ vllm: vLLM (high-performance LLM serving)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/src/github.com/elizabetht/spark/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ transformers: HuggingFace Transformers (model loading)\n",
      "\n",
      "  All packages installed.\n",
      "\n",
      "spark-02 (192.168.100.11) - remote packages:\n",
      "\n",
      "  ✓ torch=2.9.1+cu130\n",
      "  ✓ vllm=0.13.0\n",
      "  ✓ transformers=4.57.6\n",
      "\n",
      "  All packages installed.\n",
      "\n",
      "✓ Both nodes have all required packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Virtual environment path (same on both nodes)\n",
    "VENV_PATH = os.path.expanduser(\"~/src/github.com/elizabetht/spark/.venv\")\n",
    "VENV_PYTHON = f\"{VENV_PATH}/bin/python\"\n",
    "\n",
    "def check_package(package_name):\n",
    "    \"\"\"Check if a Python package is installed locally.\"\"\"\n",
    "    try:\n",
    "        __import__(package_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "def check_remote_packages(remote_ip, venv_path):\n",
    "    \"\"\"Check if required packages are installed on a remote node via SSH.\"\"\"\n",
    "    # Use the venv python directly to avoid shell quoting issues with 'source'\n",
    "    venv_python = f\"{venv_path}/bin/python\"\n",
    "    check_cmd = (\n",
    "        f'{venv_python} -c \"'\n",
    "        f'import torch; import vllm; import transformers; '\n",
    "        f'print(f\\\\\"torch={{torch.__version__}}\\\\\"); '\n",
    "        f'print(f\\\\\"vllm={{vllm.__version__}}\\\\\"); '\n",
    "        f'print(f\\\\\"transformers={{transformers.__version__}}\\\\\")'\n",
    "        f'\"'\n",
    "    )\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['ssh', '-o', 'ConnectTimeout=5', f'nvidia@{remote_ip}', check_cmd],\n",
    "            capture_output=True, text=True, timeout=30\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout.strip()\n",
    "        else:\n",
    "            # Try to identify which package failed\n",
    "            return False, result.stderr.strip()\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "packages = {\n",
    "    'torch': 'PyTorch (deep learning framework)',\n",
    "    'vllm': 'vLLM (high-performance LLM serving)',\n",
    "    'transformers': 'HuggingFace Transformers (model loading)',\n",
    "}\n",
    "\n",
    "# --- Check spark-01 (local) ---\n",
    "print(f\"spark-01 ({NODE1_IP}) - local packages:\\n\")\n",
    "missing_local = []\n",
    "for pkg, description in packages.items():\n",
    "    installed = check_package(pkg)\n",
    "    status = \"✓\" if installed else \"✗\"\n",
    "    print(f\"  {status} {pkg}: {description}\")\n",
    "    if not installed:\n",
    "        missing_local.append(pkg)\n",
    "\n",
    "if missing_local:\n",
    "    print(f\"\\n  Missing: {', '.join(missing_local)}\")\n",
    "else:\n",
    "    print(\"\\n  All packages installed.\")\n",
    "\n",
    "# --- Check spark-02 (remote) ---\n",
    "print(f\"\\nspark-02 ({NODE2_IP}) - remote packages:\\n\")\n",
    "remote_ok, remote_detail = check_remote_packages(NODE2_IP, VENV_PATH)\n",
    "\n",
    "if remote_ok:\n",
    "    for line in remote_detail.split('\\n'):\n",
    "        print(f\"  ✓ {line}\")\n",
    "    print(\"\\n  All packages installed.\")\n",
    "else:\n",
    "    print(f\"  ✗ Package check failed\")\n",
    "    print(f\"  Error: {remote_detail[:200]}\")\n",
    "\n",
    "# --- Print install commands if anything is missing ---\n",
    "if missing_local or not remote_ok:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"INSTALL COMMANDS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nActivate the virtual environment first:\")\n",
    "    print(f\"  source {VENV_PATH}/bin/activate\")\n",
    "    print(f\"\\nThen run:\")\n",
    "    print(f\"  pip install transformers\")\n",
    "    print(f\"  pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 --index-url https://download.pytorch.org/whl/cu130\")\n",
    "    print(f\"  pip install vllm==0.13.0 --extra-index-url https://wheels.vllm.ai/0.13.0/cu130\")\n",
    "    if missing_local and not remote_ok:\n",
    "        print(f\"\\nRun these commands on BOTH spark-01 and spark-02.\")\n",
    "    elif missing_local:\n",
    "        print(f\"\\nRun these commands on spark-01.\")\n",
    "    else:\n",
    "        print(f\"\\nRun these commands on spark-02:\")\n",
    "        print(f\"  ssh nvidia@{NODE2_IP}\")\n",
    "        print(f\"  source {VENV_PATH}/bin/activate\")\n",
    "        print(f\"  # Then run the pip install commands above\")\n",
    "else:\n",
    "    print(\"\\n✓ Both nodes have all required packages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568caf2c",
   "metadata": {},
   "source": [
    "## Step 5: Verify PyTorch GPU Access (Both Nodes)\n",
    "\n",
    "Confirm PyTorch can see and use the GPUs on both nodes. Both nodes need working GPU compute for disaggregated serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e0ae48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_HOME: /usr/local/cuda-13.0\n",
      "LD_LIBRARY_PATH: /usr/local/cuda-13.0/lib64\n",
      "\n",
      "✓ CUDA 13.0 environment configured\n"
     ]
    }
   ],
   "source": [
    "# Set CUDA environment variables for PyTorch\n",
    "import os\n",
    "\n",
    "# CUDA 13.0 paths for DGX Spark\n",
    "os.environ['CUDA_HOME'] = '/usr/local/cuda-13.0'\n",
    "cuda_lib_path = '/usr/local/cuda-13.0/lib64'\n",
    "\n",
    "if 'LD_LIBRARY_PATH' in os.environ:\n",
    "    os.environ['LD_LIBRARY_PATH'] = f\"{cuda_lib_path}:{os.environ['LD_LIBRARY_PATH']}\"\n",
    "else:\n",
    "    os.environ['LD_LIBRARY_PATH'] = cuda_lib_path\n",
    "\n",
    "print(f\"CUDA_HOME: {os.environ['CUDA_HOME']}\")\n",
    "print(f\"LD_LIBRARY_PATH: {os.environ['LD_LIBRARY_PATH']}\")\n",
    "print(\"\\n✓ CUDA 13.0 environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b174617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-01 (192.168.100.10) - PyTorch GPU check:\n",
      "\n",
      "  CUDA available: True\n",
      "  GPUs visible to PyTorch: 1\n",
      "\n",
      "  GPU 0: NVIDIA GB10 (128.5 GB)\n",
      "\n",
      "  Testing GPU compute...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/src/github.com/elizabetht/spark/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ GPU compute working\n",
      "\n",
      "spark-02 (192.168.100.11) - PyTorch GPU check:\n",
      "\n",
      "  ✓ CUDA available: True\n",
      "  ✓ GPU count: 1\n",
      "  ✓ GPU 0: NVIDIA GB10 (128.5 GB)\n",
      "  ✓ Compute test: OK\n",
      "\n",
      "✓ Both nodes have working GPU compute.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# --- Check spark-01 (local) ---\n",
    "print(f\"spark-01 ({NODE1_IP}) - PyTorch GPU check:\\n\")\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"  CUDA available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"  GPUs visible to PyTorch: {gpu_count}\\n\")\n",
    "    \n",
    "    for i in range(gpu_count):\n",
    "        name = torch.cuda.get_device_name(i)\n",
    "        memory_gb = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
    "        print(f\"  GPU {i}: {name} ({memory_gb:.1f} GB)\")\n",
    "    \n",
    "    print(\"\\n  Testing GPU compute...\")\n",
    "    x = torch.randn(1000, 1000, device='cuda')\n",
    "    y = torch.matmul(x, x)\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"  ✓ GPU compute working\")\n",
    "else:\n",
    "    print(\"  ✗ CUDA not available\")\n",
    "    print(\"\\n  Restart the kernel and run cells in order.\")\n",
    "\n",
    "# --- Check spark-02 (remote) ---\n",
    "print(f\"\\nspark-02 ({NODE2_IP}) - PyTorch GPU check:\\n\")\n",
    "\n",
    "venv_python = f\"{VENV_PATH}/bin/python\"\n",
    "gpu_check_cmd = (\n",
    "    f'{venv_python} -c \"'\n",
    "    f'import torch; '\n",
    "    f'print(f\\\\\"CUDA available: {{torch.cuda.is_available()}}\\\\\"); '\n",
    "    f'print(f\\\\\"GPU count: {{torch.cuda.device_count()}}\\\\\"); '\n",
    "    f'[print(f\\\\\"GPU {{i}}: {{torch.cuda.get_device_name(i)}} ({{torch.cuda.get_device_properties(i).total_memory / 1e9:.1f}} GB)\\\\\") for i in range(torch.cuda.device_count())]; '\n",
    "    f'x = torch.randn(100, 100, device=\\\\\"cuda\\\\\"); '\n",
    "    f'y = torch.matmul(x, x); '\n",
    "    f'torch.cuda.synchronize(); '\n",
    "    f'print(\\\\\"Compute test: OK\\\\\")'\n",
    "    f'\"'\n",
    ")\n",
    "\n",
    "result = subprocess.run(\n",
    "    ['ssh', '-o', 'ConnectTimeout=5', f'nvidia@{NODE2_IP}', gpu_check_cmd],\n",
    "    capture_output=True, text=True, timeout=30\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    for line in result.stdout.strip().split('\\n'):\n",
    "        print(f\"  ✓ {line}\")\n",
    "else:\n",
    "    print(f\"  ✗ GPU check failed\")\n",
    "    if result.stderr.strip():\n",
    "        # Show last few lines of error\n",
    "        err_lines = result.stderr.strip().split('\\n')\n",
    "        for line in err_lines[-3:]:\n",
    "            print(f\"    {line}\")\n",
    "\n",
    "print()\n",
    "if cuda_available and result.returncode == 0:\n",
    "    print(\"✓ Both nodes have working GPU compute.\")\n",
    "else:\n",
    "    print(\"✗ Fix GPU access before continuing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee10ab0",
   "metadata": {},
   "source": [
    "## Step 6: Verify Model Cache (Both Nodes)\n",
    "\n",
    "Both nodes need `meta-llama/Llama-3.1-8B-Instruct` cached locally. The prefill node loads it for prompt processing, the decode node loads it for token generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ea4592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-01 (192.168.100.10) - model cache:\n",
      "\n",
      "  ✓ meta-llama/Llama-3.1-8B-Instruct found in cache\n",
      "    /home/nvidia/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B-Instruct\n",
      "\n",
      "spark-02 (192.168.100.11) - model cache:\n",
      "\n",
      "  ✓ meta-llama/Llama-3.1-8B-Instruct found in cache\n",
      "    /home/nvidia/.cache/huggingface/hub/models--meta-llama--Llama-3.1-8B-Instruct\n",
      "\n",
      "✓ Model cached on both nodes.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "CACHE_DIR = Path.home() / \".cache\" / \"huggingface\" / \"hub\"\n",
    "model_slug = MODEL_NAME.replace(\"/\", \"--\")\n",
    "\n",
    "# --- Check spark-01 (local) ---\n",
    "print(f\"spark-01 ({NODE1_IP}) - model cache:\\n\")\n",
    "\n",
    "local_model_dirs = list(CACHE_DIR.glob(f\"models--{model_slug}*\"))\n",
    "if local_model_dirs:\n",
    "    print(f\"  ✓ {MODEL_NAME} found in cache\")\n",
    "    print(f\"    {local_model_dirs[0]}\")\n",
    "else:\n",
    "    print(f\"  ✗ {MODEL_NAME} not found in cache\")\n",
    "    print(f\"    Run: huggingface-cli download {MODEL_NAME}\")\n",
    "\n",
    "# --- Check spark-02 (remote) ---\n",
    "print(f\"\\nspark-02 ({NODE2_IP}) - model cache:\\n\")\n",
    "\n",
    "result = subprocess.run(\n",
    "    ['ssh', '-o', 'ConnectTimeout=5', f'nvidia@{NODE2_IP}',\n",
    "     f'ls -d ~/.cache/huggingface/hub/models--{model_slug}* 2>/dev/null && echo FOUND || echo MISSING'],\n",
    "    capture_output=True, text=True, timeout=10\n",
    ")\n",
    "\n",
    "remote_lines = result.stdout.strip().split('\\n')\n",
    "remote_status = remote_lines[-1] if remote_lines else \"MISSING\"\n",
    "\n",
    "if remote_status == \"FOUND\":\n",
    "    print(f\"  ✓ {MODEL_NAME} found in cache\")\n",
    "    if len(remote_lines) > 1:\n",
    "        print(f\"    {remote_lines[0]}\")\n",
    "else:\n",
    "    print(f\"  ✗ {MODEL_NAME} not found in cache\")\n",
    "    print(f\"    Run on spark-02: huggingface-cli download {MODEL_NAME}\")\n",
    "\n",
    "print()\n",
    "if local_model_dirs and remote_status == \"FOUND\":\n",
    "    print(\"✓ Model cached on both nodes.\")\n",
    "else:\n",
    "    print(\"✗ Model must be cached on both nodes before continuing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505c3ae",
   "metadata": {},
   "source": [
    "## Step 7: Environment Summary\n",
    "\n",
    "Collect all configuration details for reference in later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "939af176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying remote node at 192.168.100.11...\n",
      "✓ Remote node: spark-02\n",
      "  GPUs: 1x NVIDIA GB10\n",
      "  IB devices: roceP2p1s0f0, roceP2p1s0f1, rocep1s0f0, rocep1s0f1\n",
      "\n",
      "Environment Configuration:\n",
      "{\n",
      "  \"timestamp\": \"2026-02-05T18:06:29.961537\",\n",
      "  \"hostname\": \"spark-01\",\n",
      "  \"gpus\": {\n",
      "    \"count\": 1,\n",
      "    \"model\": \"NVIDIA GB10\"\n",
      "  },\n",
      "  \"nodes\": {\n",
      "    \"spark-01\": {\n",
      "      \"ip\": \"192.168.100.10\",\n",
      "      \"gpus\": {\n",
      "        \"count\": 1,\n",
      "        \"model\": \"NVIDIA GB10\"\n",
      "      },\n",
      "      \"ib_devices\": [\n",
      "        \"roceP2p1s0f0\",\n",
      "        \"roceP2p1s0f1\",\n",
      "        \"rocep1s0f0\",\n",
      "        \"rocep1s0f1\"\n",
      "      ]\n",
      "    },\n",
      "    \"spark-02\": {\n",
      "      \"ip\": \"192.168.100.11\",\n",
      "      \"gpus\": {\n",
      "        \"count\": 1,\n",
      "        \"model\": \"NVIDIA GB10\"\n",
      "      },\n",
      "      \"ib_devices\": [\n",
      "        \"roceP2p1s0f0\",\n",
      "        \"roceP2p1s0f1\",\n",
      "        \"rocep1s0f0\",\n",
      "        \"rocep1s0f1\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"network\": {\n",
      "    \"node1_ip\": \"192.168.100.10\",\n",
      "    \"node2_ip\": \"192.168.100.11\",\n",
      "    \"ib_devices\": [\n",
      "      \"roceP2p1s0f0\",\n",
      "      \"roceP2p1s0f1\",\n",
      "      \"rocep1s0f0\",\n",
      "      \"rocep1s0f1\"\n",
      "    ]\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"name\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
      "    \"cache_dir\": \"/home/nvidia/.cache/huggingface/hub\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Configuration saved to: environment_config.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def get_remote_info(remote_ip):\n",
    "    \"\"\"Query remote node hostname, GPU, and InfiniBand configuration via SSH\"\"\"\n",
    "    try:\n",
    "        # Get hostname\n",
    "        hostname_result = subprocess.run(\n",
    "            ['ssh', '-o', 'ConnectTimeout=5', f'nvidia@{remote_ip}', 'hostname'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        # Get GPU info\n",
    "        gpu_result = subprocess.run(\n",
    "            ['ssh', '-o', 'ConnectTimeout=5', f'nvidia@{remote_ip}', \n",
    "             'nvidia-smi --query-gpu=name,count --format=csv,noheader'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        # Get InfiniBand devices\n",
    "        ib_result = subprocess.run(\n",
    "            ['ssh', '-o', 'ConnectTimeout=5', f'nvidia@{remote_ip}', 'ibstat -l'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if hostname_result.returncode == 0 and gpu_result.returncode == 0:\n",
    "            hostname = hostname_result.stdout.strip()\n",
    "            gpu_info = gpu_result.stdout.strip().split('\\n')\n",
    "            gpu_count = len(gpu_info)\n",
    "            gpu_model = gpu_info[0].split(',')[0] if gpu_info else \"Unknown\"\n",
    "            \n",
    "            # Parse IB devices\n",
    "            if ib_result.returncode == 0:\n",
    "                ib_devices = [d for d in ib_result.stdout.strip().split('\\n') if d]\n",
    "            else:\n",
    "                ib_devices = [\"ibstat not found\"]\n",
    "            \n",
    "            return hostname, gpu_count, gpu_model, ib_devices\n",
    "        else:\n",
    "            return None, None, \"SSH failed\", []\n",
    "    except Exception as e:\n",
    "        return None, None, str(e), []\n",
    "\n",
    "# Gather local node information\n",
    "local_node = get_hostname()\n",
    "env_config = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"hostname\": local_node,  # For backward compatibility\n",
    "    \"gpus\": {\n",
    "        \"count\": gpu_count,\n",
    "        \"model\": gpu_model\n",
    "    },\n",
    "    \"nodes\": {\n",
    "        local_node: {\n",
    "            \"ip\": NODE1_IP if \"01\" in local_node else NODE2_IP,\n",
    "            \"gpus\": {\n",
    "                \"count\": gpu_count,\n",
    "                \"model\": gpu_model\n",
    "            },\n",
    "            \"ib_devices\": ib_devices\n",
    "        }\n",
    "    },\n",
    "    \"network\": {\n",
    "        \"node1_ip\": NODE1_IP,\n",
    "        \"node2_ip\": NODE2_IP,\n",
    "        \"ib_devices\": ib_devices\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"name\": MODEL_NAME,\n",
    "        \"cache_dir\": str(CACHE_DIR)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Try to query remote node\n",
    "remote_ip = NODE2_IP if \"01\" in local_node else NODE1_IP\n",
    "print(f\"Querying remote node at {remote_ip}...\")\n",
    "remote_hostname, remote_gpu_count, remote_gpu_model, remote_ib_devices = get_remote_info(remote_ip)\n",
    "\n",
    "if remote_hostname:\n",
    "    env_config[\"nodes\"][remote_hostname] = {\n",
    "        \"ip\": remote_ip,\n",
    "        \"gpus\": {\n",
    "            \"count\": remote_gpu_count,\n",
    "            \"model\": remote_gpu_model\n",
    "        },\n",
    "        \"ib_devices\": remote_ib_devices\n",
    "    }\n",
    "    print(f\"✓ Remote node: {remote_hostname}\")\n",
    "    print(f\"  GPUs: {remote_gpu_count}x {remote_gpu_model}\")\n",
    "    print(f\"  IB devices: {', '.join(remote_ib_devices) if remote_ib_devices else 'none'}\")\n",
    "else:\n",
    "    print(f\"✗ Could not query remote node: {remote_gpu_model}\")\n",
    "    print(\"  Check SSH connectivity or run this notebook on both nodes\")\n",
    "\n",
    "# Save to file for reference\n",
    "config_file = Path(\"environment_config.json\")\n",
    "with open(config_file, 'w') as f:\n",
    "    json.dump(env_config, f, indent=2)\n",
    "\n",
    "print(\"\\nEnvironment Configuration:\")\n",
    "print(json.dumps(env_config, indent=2))\n",
    "print(f\"\\nConfiguration saved to: {config_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea5d1a",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Environment is ready. The next notebook ([01_Local_Inference_Baseline.ipynb](01_Local_Inference_Baseline.ipynb)) establishes single-node vLLM performance.\n",
    "\n",
    "**Remaining notebooks:**\n",
    "1. **01_Local_Inference_Baseline**: Measure throughput, latency, and memory (the bar to beat)\n",
    "2. **02_Understanding_KV_Cache**: Calculate cache dimensions and transfer cost (arithmetic only)\n",
    "3. **03_Disaggregated_Serving**: Split prefill/decode across spark-01 and spark-02"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
