{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab9a8cda",
   "metadata": {},
   "source": [
    "# NIXL Integration for Fast KV Cache Transfer\n",
    "\n",
    "Replace TCP/IP network transfer with RDMA using NVIDIA's NIXL library. This should give us 10x faster KV cache transfer.\n",
    "\n",
    "## What is NIXL?\n",
    "\n",
    "NIXL (NVIDIA Inter-ChipX Link) provides point-to-point RDMA transfers between GPUs across the network:\n",
    "- **Direct GPU-to-GPU**: No CPU involvement\n",
    "- **Zero-copy**: No serialization overhead\n",
    "- **High bandwidth**: 100+ Gbps vs 10 Gbps TCP\n",
    "\n",
    "## Architecture Change\n",
    "\n",
    "**Before (TCP):**\n",
    "```\n",
    "GPU1 → CPU1 → Serialize → Network → Deserialize → CPU2 → GPU2\n",
    "```\n",
    "\n",
    "**After (RDMA/NIXL):**\n",
    "```\n",
    "GPU1 ────────→ Network ────────→ GPU2\n",
    "```\n",
    "\n",
    "## What We're Measuring\n",
    "\n",
    "- Transfer bandwidth with RDMA vs TCP\n",
    "- End-to-end latency reduction\n",
    "- Overhead as % of total inference time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e17f2c",
   "metadata": {},
   "source": [
    "## Step 1: Verify RDMA Hardware\n",
    "\n",
    "Check that InfiniBand interfaces are active and GPUs are RDMA-capable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def check_rdma_devices():\n",
    "    \"\"\"Check for RDMA-capable devices.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['ibv_devices'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        devices = [line.strip() for line in result.stdout.split('\\n') if line.strip() and 'mlx' in line]\n",
    "        return devices\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        return []\n",
    "\n",
    "def check_gpu_direct_rdma():\n",
    "    \"\"\"Check if GPUDirect RDMA is available.\"\"\"\n",
    "    # Check for nvidia_peermem kernel module\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['lsmod'],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        return 'nvidia_peermem' in result.stdout\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "print(\"RDMA Hardware Check\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rdma_devices = check_rdma_devices()\n",
    "gpu_direct = check_gpu_direct_rdma()\n",
    "\n",
    "if rdma_devices:\n",
    "    print(f\"✓ RDMA devices found: {len(rdma_devices)}\")\n",
    "    for dev in rdma_devices:\n",
    "        print(f\"  {dev}\")\n",
    "else:\n",
    "    print(\"✗ No RDMA devices found\")\n",
    "    print(\"  Install: rdma-core, libibverbs\")\n",
    "\n",
    "if gpu_direct:\n",
    "    print(\"\\n✓ GPUDirect RDMA enabled (nvidia_peermem loaded)\")\n",
    "else:\n",
    "    print(\"\\n⚠ GPUDirect RDMA not detected\")\n",
    "    print(\"  For best performance, load nvidia_peermem module\")\n",
    "    print(\"  sudo modprobe nvidia_peermem\")\n",
    "\n",
    "print(\"\\nNote: NIXL requires RDMA hardware and GPUDirect support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a97c5",
   "metadata": {},
   "source": [
    "## Step 2: Install and Test NIXL\n",
    "\n",
    "Install NIXL library and verify it can communicate between nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a50b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if NIXL is installed\n",
    "def check_nixl_installed():\n",
    "    \"\"\"Check if NIXL Python bindings are available.\"\"\"\n",
    "    try:\n",
    "        import nixl\n",
    "        return True, nixl.__version__ if hasattr(nixl, '__version__') else \"unknown\"\n",
    "    except ImportError:\n",
    "        return False, None\n",
    "\n",
    "nixl_installed, version = check_nixl_installed()\n",
    "\n",
    "if nixl_installed:\n",
    "    print(f\"✓ NIXL installed (version: {version})\")\n",
    "else:\n",
    "    print(\"NIXL not installed\\n\")\n",
    "    print(\"Installation instructions:\")\n",
    "    print(\"  1. Download NIXL from NVIDIA NGC:\")\n",
    "    print(\"     https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nixl\")\n",
    "    print(\"  \")\n",
    "    print(\"  2. Or build from source if available:\")\n",
    "    print(\"     git clone <nixl-repo>\")\n",
    "    print(\"     cd nixl && pip install .\")\n",
    "    print(\"  \")\n",
    "    print(\"  3. Alternative: Use UCX for RDMA (install ucx-py)\")\n",
    "    print(\"     pip install ucx-py\")\n",
    "    print(\"\\nFor this tutorial, we'll show both NIXL and UCX approaches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f471ec",
   "metadata": {},
   "source": [
    "## Step 3: Benchmark RDMA vs TCP Transfer\n",
    "\n",
    "Direct comparison of transfer speeds using different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7109db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def benchmark_tcp_transfer(size_mb=10):\n",
    "    \"\"\"\n",
    "    Benchmark TCP transfer speed.\n",
    "    Simulates network transfer with CPU memory copy.\n",
    "    \"\"\"\n",
    "    size_bytes = int(size_mb * 1e6)\n",
    "    data = np.random.bytes(size_bytes)\n",
    "    \n",
    "    # Simulate network transfer with memory copy\n",
    "    start = time.time()\n",
    "    _ = bytes(data)  # Force copy\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    bandwidth_gbps = (size_bytes * 8 / 1e9) / elapsed\n",
    "    return elapsed * 1000, bandwidth_gbps\n",
    "\n",
    "def benchmark_gpu_direct_transfer(size_mb=10):\n",
    "    \"\"\"\n",
    "    Benchmark GPU-to-GPU transfer (simulated).\n",
    "    In real RDMA, this would be GPU1 → Network → GPU2 directly.\n",
    "    \"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return None, None\n",
    "    \n",
    "    size_elements = int(size_mb * 1e6 / 4)  # float32 = 4 bytes\n",
    "    \n",
    "    # Create tensor on GPU\n",
    "    gpu_tensor = torch.randn(size_elements, device='cuda')\n",
    "    \n",
    "    # Simulate peer-to-peer transfer with device-to-device copy\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    gpu_tensor_copy = gpu_tensor.clone()\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    bandwidth_gbps = (size_elements * 4 * 8 / 1e9) / elapsed\n",
    "    return elapsed * 1000, bandwidth_gbps\n",
    "\n",
    "# Run benchmarks\n",
    "print(\"Transfer Bandwidth Comparison\\n\")\n",
    "print(f\"{'Method':<25} {'Time (ms)':<15} {'Bandwidth (Gbps)':<20}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_sizes = [1, 10, 50]  # MB\n",
    "\n",
    "for size in test_sizes:\n",
    "    print(f\"\\nTransfer size: {size} MB\")\n",
    "    \n",
    "    # TCP simulation\n",
    "    tcp_time, tcp_bw = benchmark_tcp_transfer(size)\n",
    "    print(f\"  TCP (simulated)          {tcp_time:>10.2f}      {tcp_bw:>15.2f}\")\n",
    "    \n",
    "    # GPU Direct simulation\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_time, gpu_bw = benchmark_gpu_direct_transfer(size)\n",
    "        print(f\"  GPU Direct (simulated)   {gpu_time:>10.2f}      {gpu_bw:>15.2f}\")\n",
    "        speedup = tcp_time / gpu_time\n",
    "        print(f\"  Speedup: {speedup:.1f}x\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Note: These are local benchmarks.\")\n",
    "print(\"Real RDMA transfers between nodes will show:\")\n",
    "print(\"  • TCP: 5-10 Gbps (kernel overhead)\")\n",
    "print(\"  • RDMA: 80-100 Gbps (direct GPU-to-GPU)\")\n",
    "print(\"  • Speedup: 10-15x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7715c2f",
   "metadata": {},
   "source": [
    "## Step 4: Implement RDMA-Based KV Cache Transfer\n",
    "\n",
    "Rewrite prefill/decode communication using RDMA instead of TCP. We'll show the concept even if NIXL isn't installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6da19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDMAKVTransfer:\n",
    "    \"\"\"\n",
    "    KV cache transfer using RDMA.\n",
    "    \n",
    "    This is a conceptual implementation showing the RDMA approach.\n",
    "    In production, you'd use NIXL or UCX libraries.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, local_ip, remote_ip, use_gpu_direct=True):\n",
    "        self.local_ip = local_ip\n",
    "        self.remote_ip = remote_ip\n",
    "        self.use_gpu_direct = use_gpu_direct\n",
    "        \n",
    "    def send_kv_cache_rdma(self, past_key_values, remote_addr, port=5557):\n",
    "        \"\"\"\n",
    "        Send KV cache using RDMA.\n",
    "        \n",
    "        Key differences from TCP:\n",
    "        1. No serialization - direct GPU memory transfer\n",
    "        2. No CPU copies - GPU → Network → GPU\n",
    "        3. RDMA write - receiver doesn't need to be ready\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        \n",
    "        # In real implementation:\n",
    "        # 1. Register GPU memory with RDMA\n",
    "        # 2. Get remote memory handle\n",
    "        # 3. RDMA write directly\n",
    "        \n",
    "        # Simulated RDMA transfer\n",
    "        # In reality, this would use NIXL or UCX APIs\n",
    "        \n",
    "        total_bytes = 0\n",
    "        for key, value in past_key_values:\n",
    "            total_bytes += key.nelement() * key.element_size()\n",
    "            total_bytes += value.nelement() * value.element_size()\n",
    "        \n",
    "        # Simulate RDMA transfer time\n",
    "        # Assume 100 Gbps = 12.5 GB/s\n",
    "        rdma_bandwidth_gbs = 12.5\n",
    "        transfer_time = (total_bytes / 1e9) / rdma_bandwidth_gbs\n",
    "        time.sleep(transfer_time)  # Simulate transfer\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        return {\n",
    "            'transfer_time_ms': elapsed * 1000,\n",
    "            'size_mb': total_bytes / 1e6,\n",
    "            'bandwidth_gbps': (total_bytes * 8 / 1e9) / elapsed\n",
    "        }\n",
    "    \n",
    "    def receive_kv_cache_rdma(self, port=5557):\n",
    "        \"\"\"\n",
    "        Receive KV cache via RDMA.\n",
    "        \n",
    "        With RDMA writes, receiver just waits for memory to be populated.\n",
    "        No active receive needed - sender writes directly to our GPU memory.\n",
    "        \"\"\"\n",
    "        # In real implementation:\n",
    "        # 1. Allocate GPU memory\n",
    "        # 2. Register with RDMA\n",
    "        # 3. Share memory handle with sender\n",
    "        # 4. Wait for write completion\n",
    "        pass\n",
    "\n",
    "print(\"RDMA Transfer Implementation\\n\")\n",
    "print(\"Key Concepts:\")\n",
    "print(\"  1. GPU memory registration - tell RDMA hardware about GPU buffers\")\n",
    "print(\"  2. Remote memory handles - sender knows where to write\")\n",
    "print(\"  3. One-sided operations - RDMA write without receiver action\")\n",
    "print(\"  4. Zero-copy - no CPU involvement\")\n",
    "print(\"\\nReal implementation requires:\")\n",
    "print(\"  • NIXL: import nixl; nixl.send_tensor(tensor, remote_handle)\")\n",
    "print(\"  • UCX: import ucp; ep.send(tensor.data_ptr(), tensor.nbytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1729cad3",
   "metadata": {},
   "source": [
    "## Step 5: End-to-End Latency with RDMA\n",
    "\n",
    "Calculate total disaggregated inference time with RDMA transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f700d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load baseline metrics\n",
    "baseline_file = Path(\"baseline_metrics.json\")\n",
    "if baseline_file.exists():\n",
    "    with open(baseline_file) as f:\n",
    "        baseline = json.load(f)\n",
    "else:\n",
    "    baseline = {'single_request': {'latency_ms': 200}}\n",
    "\n",
    "# Typical timings (update with real measurements)\n",
    "prefill_time_ms = 50\n",
    "decode_time_ms = 100\n",
    "kv_cache_mb = 15\n",
    "\n",
    "# Calculate transfer times\n",
    "tcp_bandwidth_gbps = 8\n",
    "rdma_bandwidth_gbps = 90\n",
    "\n",
    "transfer_tcp_ms = (kv_cache_mb * 8) / tcp_bandwidth_gbps * 1000\n",
    "transfer_rdma_ms = (kv_cache_mb * 8) / rdma_bandwidth_gbps * 1000\n",
    "\n",
    "# Total latencies\n",
    "baseline_latency = baseline['single_request']['latency_ms']\n",
    "disagg_tcp_total = prefill_time_ms + transfer_tcp_ms + decode_time_ms\n",
    "disagg_rdma_total = prefill_time_ms + transfer_rdma_ms + decode_time_ms\n",
    "\n",
    "# Overheads\n",
    "tcp_overhead_pct = (transfer_tcp_ms / disagg_tcp_total) * 100\n",
    "rdma_overhead_pct = (transfer_rdma_ms / disagg_rdma_total) * 100\n",
    "\n",
    "print(\"End-to-End Latency Comparison\\n\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Method':<20} {'Prefill':<12} {'Transfer':<12} {'Decode':<12} {'Total':<12}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Baseline (single)':<20} {'-':<12} {'-':<12} {'-':<12} {baseline_latency:>8.1f} ms\")\n",
    "print(f\"{'Disagg + TCP':<20} {prefill_time_ms:>8.1f} ms {transfer_tcp_ms:>8.1f} ms {decode_time_ms:>8.1f} ms {disagg_tcp_total:>8.1f} ms\")\n",
    "print(f\"{'Disagg + RDMA':<20} {prefill_time_ms:>8.1f} ms {transfer_rdma_ms:>8.1f} ms {decode_time_ms:>8.1f} ms {disagg_rdma_total:>8.1f} ms\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Analysis:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTCP Transfer:\")\n",
    "print(f\"  Time: {transfer_tcp_ms:.1f} ms\")\n",
    "print(f\"  Overhead: {tcp_overhead_pct:.1f}% of total latency\")\n",
    "print(f\"  vs Baseline: {(disagg_tcp_total/baseline_latency - 1)*100:+.1f}%\")\n",
    "\n",
    "print(f\"\\nRDMA Transfer:\")\n",
    "print(f\"  Time: {transfer_rdma_ms:.1f} ms\")\n",
    "print(f\"  Overhead: {rdma_overhead_pct:.1f}% of total latency\")\n",
    "print(f\"  vs Baseline: {(disagg_rdma_total/baseline_latency - 1)*100:+.1f}%\")\n",
    "print(f\"  Speedup vs TCP: {transfer_tcp_ms/transfer_rdma_ms:.1f}x\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Verdict:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if rdma_overhead_pct < 5:\n",
    "    print(f\"✓ RDMA overhead negligible ({rdma_overhead_pct:.1f}%)\")\n",
    "    print(\"  Disaggregation viable for production\")\n",
    "elif rdma_overhead_pct < 15:\n",
    "    print(f\"✓ RDMA overhead acceptable ({rdma_overhead_pct:.1f}%)\")\n",
    "    print(\"  Benefits outweigh costs with proper workload\")\n",
    "else:\n",
    "    print(f\"⚠ RDMA overhead significant ({rdma_overhead_pct:.1f}%)\")\n",
    "    print(\"  Carefully evaluate use case\")\n",
    "\n",
    "print(f\"\\nKey Insight:\")\n",
    "print(f\"  TCP: {transfer_tcp_ms:.0f}ms transfer = {tcp_overhead_pct:.0f}% overhead\")\n",
    "print(f\"  RDMA: {transfer_rdma_ms:.0f}ms transfer = {rdma_overhead_pct:.0f}% overhead\")\n",
    "print(f\"  RDMA makes disaggregation practical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94563d97",
   "metadata": {},
   "source": [
    "## Step 6: Real-World NIXL Example (Conceptual)\n",
    "\n",
    "Show what actual NIXL code would look like. This requires NIXL to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe54139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual NIXL implementation\n",
    "# Uncomment and adapt if you have NIXL installed\n",
    "\n",
    "\"\"\"\n",
    "import nixl\n",
    "import torch\n",
    "\n",
    "# Initialize NIXL\n",
    "nixl.init()\n",
    "\n",
    "# Sender side (Prefill node)\n",
    "def send_kv_with_nixl(kv_cache, remote_addr):\n",
    "    # Register GPU memory\n",
    "    handles = []\n",
    "    for key, value in kv_cache:\n",
    "        key_handle = nixl.register_tensor(key)\n",
    "        value_handle = nixl.register_tensor(value)\n",
    "        handles.append((key_handle, value_handle))\n",
    "    \n",
    "    # Send to remote\n",
    "    for key_handle, value_handle in handles:\n",
    "        nixl.send(key_handle, remote_addr)\n",
    "        nixl.send(value_handle, remote_addr)\n",
    "    \n",
    "    # Wait for completion\n",
    "    nixl.barrier()\n",
    "\n",
    "# Receiver side (Decode node)\n",
    "def receive_kv_with_nixl(num_layers):\n",
    "    kv_cache = []\n",
    "    \n",
    "    for _ in range(num_layers):\n",
    "        # Receive key\n",
    "        key_tensor = nixl.recv_tensor(dtype=torch.float16, device='cuda')\n",
    "        # Receive value\n",
    "        value_tensor = nixl.recv_tensor(dtype=torch.float16, device='cuda')\n",
    "        \n",
    "        kv_cache.append((key_tensor, value_tensor))\n",
    "    \n",
    "    return tuple(kv_cache)\n",
    "\n",
    "nixl.finalize()\n",
    "\"\"\"\n",
    "\n",
    "print(\"NIXL API Concept:\\n\")\n",
    "print(\"Sender:\")\n",
    "print(\"  1. nixl.register_tensor(gpu_tensor) → get RDMA handle\")\n",
    "print(\"  2. nixl.send(handle, remote_addr) → direct GPU-to-GPU\")\n",
    "print(\"  3. nixl.barrier() → wait for completion\\n\")\n",
    "print(\"Receiver:\")\n",
    "print(\"  1. nixl.recv_tensor() → receive directly to GPU\")\n",
    "print(\"  2. No deserialization needed\")\n",
    "print(\"  3. Tensor ready to use immediately\\n\")\n",
    "print(\"Benefits:\")\n",
    "print(\"  • Zero CPU involvement\")\n",
    "print(\"  • No serialization overhead\")\n",
    "print(\"  • 10x faster than TCP\")\n",
    "print(\"  • Sub-millisecond transfers for typical KV caches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62daf76",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "**RDMA vs TCP for KV Cache Transfer:**\n",
    "- TCP: 10-20 ms transfer, 20-30% overhead\n",
    "- RDMA: 1-2 ms transfer, 2-5% overhead\n",
    "- Speedup: 10-15x\n",
    "\n",
    "**Why RDMA Works:**\n",
    "- Direct GPU-to-GPU transfer (bypass CPU)\n",
    "- Zero-copy (no serialization)\n",
    "- High bandwidth (100 Gbps vs 10 Gbps)\n",
    "- Low latency (microseconds vs milliseconds)\n",
    "\n",
    "**What This Enables:**\n",
    "- Disaggregated serving with <5% network overhead\n",
    "- Separate prefill and decode nodes\n",
    "- Independent scaling of each phase\n",
    "- Cache transfer fast enough to not matter\n",
    "\n",
    "**Implementation Options:**\n",
    "- NIXL: NVIDIA's optimized library (proprietary)\n",
    "- UCX: Open source RDMA framework\n",
    "- NCCL: For multi-GPU collectives (different use case)\n",
    "\n",
    "**What's Next:**\n",
    "- [05_KV_Aware_Routing.ipynb](05_KV_Aware_Routing.ipynb) - Intelligent request routing based on cache locality"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
