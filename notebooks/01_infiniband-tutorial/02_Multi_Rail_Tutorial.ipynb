{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decc65fe",
   "metadata": {},
   "source": [
    "# RoCE Link Aggregation: Bonding vs NIXL\n",
    "\n",
    "This notebook compares two approaches to using dual 100G RoCE links on DGX Spark:\n",
    "\n",
    "| Approach | Traffic Type | Expected Throughput | Latency |\n",
    "|----------|--------------|---------------------|----------|\n",
    "| Linux Bonding | TCP/IP | ~60-70 Gbps | 50-200 μs |\n",
    "| NIXL | Point-to-point RDMA | ~176 Gbps | 1-2 μs |\n",
    "\n",
    "**Goal**: Demonstrate why NIXL outperforms bonding for point-to-point inference data movement.\n",
    "\n",
    "For collective operations (all-reduce, all-gather), see the [first tutorial](01_InfiniBand_Tutorial.ipynb) which covers NCCL.\n",
    "\n",
    "**Prerequisites**:\n",
    "- Two DGX Spark systems connected via both RoCE ports\n",
    "- IP addresses configured on RoCE interfaces\n",
    "- `perftest` and `iperf3` installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d65bb",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15be26cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded\n",
      "Local IP: 192.168.100.11\n",
      "Remote IP: 192.168.100.10\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Configuration - Update these for your environment\n",
    "LOCAL_IP = \"192.168.100.11\"    # This node's RoCE IP\n",
    "REMOTE_IP = \"192.168.100.10\"   # Remote node's RoCE IP\n",
    "INTERFACE_1 = \"enp1s0f0np0\"    # First RoCE interface\n",
    "INTERFACE_2 = \"enp1s0f1np1\"    # Second RoCE interface\n",
    "\n",
    "def run_cmd(cmd, timeout=60):\n",
    "    \"\"\"Run a shell command and return output.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd, shell=True, capture_output=True, text=True, timeout=timeout\n",
    "        )\n",
    "        return result.stdout + result.stderr\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return \"Command timed out\"\n",
    "\n",
    "def parse_bandwidth(output, pattern):\n",
    "    \"\"\"Extract bandwidth value from command output.\"\"\"\n",
    "    match = re.search(pattern, output)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "print(\"Configuration loaded\")\n",
    "print(f\"Local IP: {LOCAL_IP}\")\n",
    "print(f\"Remote IP: {REMOTE_IP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a9463",
   "metadata": {},
   "source": [
    "## Part 1: Verify Network Interfaces\n",
    "\n",
    "Check that both RoCE interfaces are available and operational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1b4df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Network Interfaces ===\n",
      "3: enp1s0f0np0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000\n",
      "    link/ether 30:c5:99:3e:6a:13 brd ff:ff:ff:ff:ff:ff\n",
      "\n",
      "4: enp1s0f1np1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000\n",
      "    link/ether 30:c5:99:3e:6a:14 brd ff:ff:ff:ff:ff:ff\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check interface status\n",
    "print(\"=== Network Interfaces ===\")\n",
    "print(run_cmd(f\"ip link show {INTERFACE_1}\"))\n",
    "print(run_cmd(f\"ip link show {INTERFACE_2}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79e5e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RDMA Devices ===\n",
      "hca_id:\trocep1s0f0\n",
      "\ttransport:\t\t\tInfiniBand (0)\n",
      "\tfw_ver:\t\t\t\t28.45.4028\n",
      "\tnode_guid:\t\t\t30c5:9903:003e:6a13\n",
      "\tsys_image_guid:\t\t\t30c5:9903:003e:6a13\n",
      "\tvendor_id:\t\t\t0x02c9\n",
      "\tvendor_part_id:\t\t\t4129\n",
      "\thw_ver:\t\t\t\t0x0\n",
      "\tboard_id:\t\t\tNVD0000000087\n",
      "\tphys_port_cnt:\t\t\t1\n",
      "\t\tport:\t1\n",
      "\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n",
      "\t\t\tmax_mtu:\t\t4096 (5)\n",
      "\t\t\tactive_mtu:\t\t1024 (3)\n",
      "\t\t\tsm_lid:\t\t\t0\n",
      "\t\t\tport_lid:\t\t0\n",
      "\t\t\tport_lmc:\t\t0x00\n",
      "\t\t\tlink_layer:\t\tEthernet\n",
      "\n",
      "hca_id:\trocep1s0f1\n",
      "\ttransport:\t\t\tInfiniBand (0)\n",
      "\tfw_ver:\t\t\t\t28.45.4028\n",
      "\tnode_guid:\t\t\t30c5:9903:003e:6a14\n",
      "\tsys_image_guid:\t\t\t30c5:9903:003e:6a13\n",
      "\tvendor_id:\t\t\t0x02c9\n",
      "\tvendor_part_id:\t\t\t4129\n",
      "\thw_ver:\t\t\t\t0x0\n",
      "\tboard_id:\t\t\tNVD0000000087\n",
      "\tphys_port_cnt:\t\t\t1\n",
      "\t\tport:\t1\n",
      "\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n",
      "\t\t\tmax_mtu:\t\t4096 (5)\n",
      "\t\t\tactive_mtu:\t\t1024 (3)\n",
      "\t\t\tsm_lid:\t\t\t0\n",
      "\t\t\tport_lid:\t\t0\n",
      "\t\t\tport_lmc:\t\t0x00\n",
      "\t\t\tlink_layer:\t\tEthernet\n",
      "\n",
      "hca_id:\troceP2p1s0f0\n",
      "\ttransport:\t\t\tInfiniBand (0)\n",
      "\tfw_ver:\t\t\t\t28.45.4028\n",
      "\tnode_guid:\t\t\t30c5:9903:003e:6a17\n",
      "\tsys_image_guid:\t\t\t30c5:9903:003e:6a13\n",
      "\tvendor_id:\t\t\t0x02c9\n",
      "\tvendor_part_id:\t\t\t4129\n",
      "\thw_ver:\t\t\t\t0x0\n",
      "\tboard_id:\t\t\tNVD0000000087\n",
      "\tphys_port_cnt:\t\t\t1\n",
      "\t\tport:\t1\n",
      "\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n",
      "\t\t\tmax_mtu:\t\t4096 (5)\n",
      "\t\t\tactive_mtu:\t\t1024 (3)\n",
      "\t\t\tsm_lid:\t\t\t0\n",
      "\t\t\tport_lid:\t\t0\n",
      "\t\t\tport_lmc:\t\t0x00\n",
      "\t\t\tlink_layer:\t\tEthernet\n",
      "\n",
      "hca_id:\troceP2p1s0f1\n",
      "\ttransport:\t\t\tInfiniBand (0)\n",
      "\tfw_ver:\t\t\t\t28.45.4028\n",
      "\tnode_guid:\t\t\t30c5:9903:003e:6a18\n",
      "\tsys_image_guid:\t\t\t30c5:9903:003e:6a13\n",
      "\tvendor_id:\t\t\t0x02c9\n",
      "\tvendor_part_id:\t\t\t4129\n",
      "\thw_ver:\t\t\t\t0x0\n",
      "\tboard_id:\t\t\tNVD0000000087\n",
      "\tphys_port_cnt:\t\t\t1\n",
      "\t\tport:\t1\n",
      "\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n",
      "\t\t\tmax_mtu:\t\t4096 (5)\n",
      "\t\t\tactive_mtu:\t\t1024 (3)\n",
      "\t\t\tsm_lid:\t\t\t0\n",
      "\t\t\tport_lid:\t\t0\n",
      "\t\t\tport_lmc:\t\t0x00\n",
      "\t\t\tlink_layer:\t\tEthernet\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check RDMA devices\n",
    "print(\"=== RDMA Devices ===\")\n",
    "print(run_cmd(\"ibv_devinfo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061c3dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Connectivity Test ===\n",
      "PING 192.168.100.10 (192.168.100.10) 56(84) bytes of data.\n",
      "64 bytes from 192.168.100.10: icmp_seq=1 ttl=64 time=0.565 ms\n",
      "64 bytes from 192.168.100.10: icmp_seq=2 ttl=64 time=0.444 ms\n",
      "64 bytes from 192.168.100.10: icmp_seq=3 ttl=64 time=0.886 ms\n",
      "\n",
      "--- 192.168.100.10 ping statistics ---\n",
      "3 packets transmitted, 3 received, 0% packet loss, time 2032ms\n",
      "rtt min/avg/max/mdev = 0.444/0.631/0.886/0.186 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify connectivity to remote node\n",
    "print(\"=== Connectivity Test ===\")\n",
    "print(run_cmd(f\"ping -c 3 {REMOTE_IP}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ec304",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Baseline RDMA Performance (Single Link)\n",
    "\n",
    "Measure raw RDMA bandwidth on a single 100G link using `ib_write_bw`.\n",
    "\n",
    "### RoCE GID Index Selection\n",
    "\n",
    "RoCE requires specifying the correct GID (Global Identifier) index. GID index 0 is typically link-local (`fe80::`) and does not work for routed connections.\n",
    "\n",
    "Check available GIDs:\n",
    "```bash\n",
    "show_gids\n",
    "```\n",
    "\n",
    "For RoCEv2 with IPv4, use index 3 (the entry showing your IPv4 address with `v2`):\n",
    "| Index | Type | Use |\n",
    "|-------|------|-----|\n",
    "| 0-1 | fe80:: (link-local) | Does not work for RoCE |\n",
    "| 2 | IPv4-mapped, RoCEv1 | Legacy, may not work |\n",
    "| 3 | IPv4-mapped, RoCEv2 | **Use this** |\n",
    "\n",
    "**Run on remote node first:**\n",
    "```bash\n",
    "ib_write_bw -d rocep1s0f0 -x 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c210fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RDMA Bandwidth (Single Link - rocep1s0f0) ===\n",
      "NOTE: Start server on remote node: ib_write_bw -d rocep1s0f0 -x 3\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "                    RDMA_Write BW Test\n",
      " Dual-port       : OFF\t\tDevice         : rocep1s0f0\n",
      " Number of qps   : 1\t\tTransport type : IB\n",
      " Connection type : RC\t\tUsing SRQ      : OFF\n",
      " PCIe relax order: ON\n",
      " ibv_wr* API     : ON\n",
      " TX depth        : 128\n",
      " CQ Moderation   : 1\n",
      " Mtu             : 1024[B]\n",
      " Link type       : Ethernet\n",
      " GID index       : 3\n",
      " Max inline data : 0[B]\n",
      " rdma_cm QPs\t : OFF\n",
      " Data ex. method : Ethernet\n",
      "---------------------------------------------------------------------------------------\n",
      " local address: LID 0000 QPN 0x01b8 PSN 0x6c40bb RKey 0x184300 VAddr 0x00f3c34c74d000\n",
      " GID: 00:00:00:00:00:00:00:00:00:00:255:255:192:168:100:11\n",
      " remote address: LID 0000 QPN 0x01c1 PSN 0xef8f64 RKey 0x184300 VAddr 0x00fc043705d000\n",
      " GID: 00:00:00:00:00:00:00:00:00:00:255:255:192:168:100:10\n",
      "---------------------------------------------------------------------------------------\n",
      " #bytes     #iterations    BW peak[MB/sec]    BW average[MB/sec]   MsgRate[Mpps]\n",
      " 65536      5000             11032.64            11032.34\t\t   0.176518\n",
      "---------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Single-link RDMA bandwidth test\n",
    "# Requires server running on remote: ib_write_bw -d rocep1s0f0 -x 3\n",
    "\n",
    "# GID index 3 = RoCEv2 with IPv4 address (required for RoCE connections)\n",
    "GID_INDEX = 3\n",
    "\n",
    "print(\"=== RDMA Bandwidth (Single Link - rocep1s0f0) ===\")\n",
    "print(f\"NOTE: Start server on remote node: ib_write_bw -d rocep1s0f0 -x {GID_INDEX}\")\n",
    "print()\n",
    "\n",
    "output = run_cmd(f\"ib_write_bw -d rocep1s0f0 -x {GID_INDEX} {REMOTE_IP}\")\n",
    "print(output)\n",
    "\n",
    "# Parse result\n",
    "bw = parse_bandwidth(output, r\"(\\d+\\.?\\d*)\\s+MB/sec\")\n",
    "if bw:\n",
    "    print(f\"\\n>>> Single Link RDMA: {bw:.0f} MB/s ({bw * 8 / 1000:.1f} Gbps)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6910a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Linux Bonding Performance (TCP/IP)\n",
    "\n",
    "Bonding aggregates TCP traffic but **does not work with RDMA**.\n",
    "\n",
    "### Critical Limitation: RDMA and Bonding Are Mutually Exclusive\n",
    "\n",
    "When interfaces are enslaved to a bond:\n",
    "- **TCP/IP works** through the bond interface (kernel stack)\n",
    "- **RDMA fails** because verbs bypass the kernel and cannot traverse bond0\n",
    "\n",
    "The `show_gids` output shows this: when bonded, GID entries associate with `bond0` instead of the physical interface, breaking RDMA connectivity.\n",
    "\n",
    "**Testing sequence for this tutorial:**\n",
    "1. Test RDMA first (Part 2) with unbonded interfaces\n",
    "2. Create bond and test TCP (Part 3)\n",
    "3. Remove bond before testing NIXL (Part 4)\n",
    "\n",
    "### Bond Mode Selection\n",
    "\n",
    "Linux bonding supports several modes. For direct-connect (no switch), only modes 0 and 2 are practical:\n",
    "\n",
    "| Mode | Name | Hash Basis | Best For |\n",
    "|------|------|------------|----------|\n",
    "| 0 | balance-rr | Per-packet round-robin | Maximum single-flow throughput (causes reordering) |\n",
    "| 1 | active-backup | None (failover only) | High availability, not performance |\n",
    "| 2 | balance-xor | IP + port hash | Multiple flows, preserves packet order |\n",
    "| 4 | 802.3ad | LACP negotiation | Requires switch support |\n",
    "\n",
    "**Why balance-xor (mode 2) for this tutorial:**\n",
    "- Each TCP connection hashes to one interface consistently\n",
    "- No out-of-order packets (unlike balance-rr)\n",
    "- Multiple parallel streams distribute across both links\n",
    "- Single streams limited to one link (~35 Gbps) but without reordering overhead\n",
    "\n",
    "**Trade-off:** balance-rr can achieve higher single-stream throughput by spreading packets across links, but causes TCP reordering which triggers congestion control. balance-xor sacrifices single-stream aggregation for predictable behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bdcf61",
   "metadata": {},
   "source": [
    "### 3.0 Configure Jumbo Frames (MTU 9000)\n",
    "\n",
    "RoCE links require jumbo frames for optimal TCP performance. The default MTU of 1500 bytes causes excessive packet fragmentation and triggers TCP congestion control, resulting in near-zero throughput.\n",
    "\n",
    "**Symptoms of MTU mismatch:**\n",
    "- Cwnd (congestion window) stuck at ~1.4 KB\n",
    "- High retransmit counts\n",
    "- Near-zero throughput despite successful connection\n",
    "\n",
    "**Set MTU on both nodes:**\n",
    "```bash\n",
    "# On spark-01 (192.168.100.10)\n",
    "sudo ip link set enp1s0f0np0 mtu 9000\n",
    "sudo ip link set enp1s0f1np1 mtu 9000\n",
    "\n",
    "# On spark-02 (192.168.100.11)\n",
    "sudo ip link set enp1s0f0np0 mtu 9000\n",
    "sudo ip link set enp1s0f1np1 mtu 9000\n",
    "sudo ip link set bond0 mtu 9000  # Only if bond exists\n",
    "```\n",
    "\n",
    "**Verify on both nodes:**\n",
    "```bash\n",
    "cat /sys/class/net/enp1s0f0np0/mtu  # Should show 9000\n",
    "cat /sys/class/net/enp1s0f1np1/mtu  # Should show 9000\n",
    "```\n",
    "\n",
    "Both endpoints must have matching MTU. A mismatch causes fragmentation and triggers TCP congestion control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if bond already exists on this node\n",
    "bond_status = run_cmd(\"cat /proc/net/bonding/bond0 2>/dev/null\")\n",
    "\n",
    "if \"Bonding Mode\" in bond_status:\n",
    "    print(\"Bond interface exists on THIS NODE (spark-02):\")\n",
    "    print(bond_status)\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"⚠️  IMPORTANT: Also verify bond on spark-01 (192.168.100.10)\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"No bond interface found on THIS NODE.\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Bond setup commands for BOTH nodes:\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"--- ON SPARK-01 (192.168.100.10): ---\")\n",
    "print(f\"\"\"\n",
    "sudo modprobe bonding\n",
    "sudo ip link add bond0 type bond mode balance-xor\n",
    "sudo ip link set bond0 type bond miimon 100\n",
    "sudo ip link set bond0 type bond xmit_hash_policy layer3+4\n",
    "\n",
    "sudo ip link set {INTERFACE_1} down\n",
    "sudo ip link set {INTERFACE_1} master bond0\n",
    "sudo ip link set {INTERFACE_1} up\n",
    "\n",
    "sudo ip link set {INTERFACE_2} down\n",
    "sudo ip link set {INTERFACE_2} master bond0\n",
    "sudo ip link set {INTERFACE_2} up\n",
    "\n",
    "sudo ip addr add 192.168.100.10/24 dev bond0\n",
    "sudo ip link set bond0 up\n",
    "\"\"\")\n",
    "print(\"--- ON SPARK-02 (192.168.100.11) - THIS NODE: ---\")\n",
    "print(f\"\"\"\n",
    "sudo modprobe bonding\n",
    "sudo ip link add bond0 type bond mode balance-xor\n",
    "sudo ip link set bond0 type bond miimon 100\n",
    "sudo ip link set bond0 type bond xmit_hash_policy layer3+4\n",
    "\n",
    "sudo ip link set {INTERFACE_1} down\n",
    "sudo ip link set {INTERFACE_1} master bond0\n",
    "sudo ip link set {INTERFACE_1} up\n",
    "\n",
    "sudo ip link set {INTERFACE_2} down\n",
    "sudo ip link set {INTERFACE_2} master bond0\n",
    "sudo ip link set {INTERFACE_2} up\n",
    "\n",
    "sudo ip addr add {LOCAL_IP}/24 dev bond0\n",
    "sudo ip link set bond0 up\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17be587",
   "metadata": {},
   "source": [
    "### 3.2 Test Bonded TCP Performance\n",
    "\n",
    "**Before running iperf3, verify connectivity:**\n",
    "- Ensure bond0 is up on spark-01 with IP 192.168.100.10\n",
    "- Check: `ip addr show bond0` on spark-01\n",
    "- Verify ping works from current node to 192.168.100.10\n",
    "\n",
    "**Run on remote node (spark-01):**\n",
    "```bash\n",
    "iperf3 -s -B 192.168.100.10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iperf3 single stream over bond\n",
    "print(\"=== TCP Bandwidth (Single Stream) ===\")\n",
    "print(\"NOTE: Start server on remote: iperf3 -s -B\", REMOTE_IP)\n",
    "print()\n",
    "\n",
    "output = run_cmd(f\"iperf3 -c {REMOTE_IP} -t 10\")\n",
    "print(output)\n",
    "\n",
    "# Parse sender bandwidth\n",
    "bw = parse_bandwidth(output, r\"sender\\s+.*?(\\d+\\.?\\d*)\\s+Gbits/sec\")\n",
    "if bw:\n",
    "    print(f\"\\n>>> TCP Single Stream: {bw:.1f} Gbps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iperf3 multiple streams over bond\n",
    "print(\"=== TCP Bandwidth (4 Parallel Streams) ===\")\n",
    "print()\n",
    "\n",
    "output = run_cmd(f\"iperf3 -c {REMOTE_IP} -t 10 -P 4\")\n",
    "print(output)\n",
    "\n",
    "# Parse sender bandwidth (SUM line)\n",
    "bw = parse_bandwidth(output, r\"\\[SUM\\].*sender\\s+.*?(\\d+\\.?\\d*)\\s+Gbits/sec\")\n",
    "if not bw:\n",
    "    bw = parse_bandwidth(output, r\"SUM.*?(\\d+\\.?\\d*)\\s+Gbits/sec.*sender\")\n",
    "if bw:\n",
    "    print(f\"\\n>>> TCP 4 Streams: {bw:.1f} Gbps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0905f2e",
   "metadata": {},
   "source": [
    "### 3.3 Results Summary: TCP vs RDMA\n",
    "\n",
    "**Measured results:**\n",
    "\n",
    "| Test | Throughput | Notes |\n",
    "|------|------------|-------|\n",
    "| RDMA single link (`ib_write_bw`) | 11,679 MB/s (93.4 Gbps) | Kernel bypass, near line rate |\n",
    "| TCP single stream over bond (`iperf3`) | 33.7 Gbps | Kernel TCP/IP stack overhead |\n",
    "| TCP 4 parallel streams over bond (`iperf3 -P 4`) | 93.0 Gbps | Utilizes both bonded links |\n",
    "\n",
    "**Key observations:**\n",
    "- RDMA achieves 2.8x the throughput of single-stream TCP over the same link\n",
    "- TCP bonding with 4 parallel streams matches RDMA single-link performance\n",
    "- Single TCP stream limited to ~34 Gbps despite 200 Gbps aggregate link capacity\n",
    "\n",
    "### Why TCP Underperforms\n",
    "\n",
    "The TCP/IP stack introduces overhead at every layer:\n",
    "- **System calls**: Each send/recv crosses user-kernel boundary\n",
    "- **Buffer copies**: Data copied between user space and kernel buffers\n",
    "- **Protocol processing**: TCP segmentation, checksums, congestion control\n",
    "- **Interrupt handling**: Each packet generates CPU interrupts\n",
    "\n",
    "RDMA bypasses all of this. The NIC reads/writes directly to application memory.\n",
    "\n",
    "### Bonding Limitations\n",
    "\n",
    "Balance-xor bonding requires multiple TCP connections to utilize both links:\n",
    "\n",
    "| Configuration | Single Stream | Multiple Streams |\n",
    "|---------------|---------------|------------------|\n",
    "| Direct interface (no bond) | 34 Gbps | 34 Gbps per stream |\n",
    "| balance-xor bond | 34 Gbps (one link) | 93 Gbps (4 streams distributed) |\n",
    "| RDMA (no bond possible) | 93 Gbps | 186 Gbps (dual-rail) |\n",
    "\n",
    "**Implication for ML workloads:** Large tensor transfers are single logical connections. TCP bonding peaks at 34 Gbps for single streams, requiring application-level parallelism to utilize both links. RDMA achieves 93 Gbps per link with a single connection, making NIXL and NCCL essential for high-bandwidth inference data movement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c2d11a",
   "metadata": {},
   "source": [
    "### 3.4 Testing RDMA Dual-Link Performance (Optional)\n",
    "\n",
    "The single-link RDMA test above shows 93.4 Gbps on one port. The [first tutorial](01_InfiniBand_Tutorial.ipynb) covers basic RDMA testing on individual ports. To verify whether the hardware can achieve **aggregate throughput across both ports simultaneously** (~186 Gbps), run two `ib_write_bw` tests in parallel.\n",
    "\n",
    "This requires two separate IP networks and manual coordination:\n",
    "\n",
    "**On spark-01 (server) - two terminals:**\n",
    "```bash\n",
    "# Terminal 1: ib_write_bw -d rocep1s0f0 -F\n",
    "# Terminal 2: ib_write_bw -d rocep1s0f1 -F\n",
    "```\n",
    "\n",
    "**On spark-02 (client) - two terminals:**\n",
    "```bash\n",
    "# Terminal 1: ib_write_bw -d rocep1s0f0 -F 192.168.100.10\n",
    "# Terminal 2: ib_write_bw -d rocep1s0f1 -F 192.168.200.10  # Requires second IP network\n",
    "```\n",
    "\n",
    "**Expected:** Each process reports ~93.4 Gbps, aggregate ~186.8 Gbps. If significantly lower, check PCIe/memory bandwidth limits.\n",
    "\n",
    "**Note:** This tests raw hardware capability. The NIXL dual-rail section below shows application-level performance with UCX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f1aa1",
   "metadata": {},
   "source": [
    "### 3.3 Monitor Bond Traffic Distribution\n",
    "\n",
    "During active transfers, verify traffic flows through both interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check per-interface statistics\n",
    "print(\"=== Interface Statistics ===\")\n",
    "print(f\"\\n{INTERFACE_1}:\")\n",
    "print(run_cmd(f\"ip -s link show {INTERFACE_1} | grep -A 2 'RX\\\\|TX'\"))\n",
    "print(f\"\\n{INTERFACE_2}:\")\n",
    "print(run_cmd(f\"ip -s link show {INTERFACE_2} | grep -A 2 'RX\\\\|TX'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dbeeaa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: NIXL Point-to-Point Transfers\n",
    "\n",
    "NIXL provides direct RDMA transfers for point-to-point workloads (KV-cache, tensor shards).\n",
    "\n",
    "### 4.0 Remove Bond Interface (Required)\n",
    "\n",
    "RDMA memory registration fails when network interfaces are enslaved to a bond. The verbs API requires direct access to the physical device, but bonded interfaces associate with `bond0` instead of the underlying hardware.\n",
    "\n",
    "**Why bond must be removed:**\n",
    "- When interfaces join a bond, the kernel reassigns their identity\n",
    "- GID entries point to `bond0` instead of `rocep1s0f0`/`rocep1s0f1`\n",
    "- RDMA operations fail because `bond0` has no verbs capability\n",
    "- NIXL `register_memory()` returns empty descriptors or raises exceptions\n",
    "\n",
    "**Remove bond on both nodes before proceeding:**\n",
    "\n",
    "```bash\n",
    "# Check if bond exists\n",
    "cat /proc/net/bonding/bond0 2>/dev/null\n",
    "\n",
    "# Remove bond\n",
    "sudo ip link set bond0 down\n",
    "sudo ip link set enp1s0f0np0 nomaster\n",
    "sudo ip link set enp1s0f1np1 nomaster\n",
    "sudo ip link delete bond0\n",
    "\n",
    "# Bring interfaces back up\n",
    "sudo ip link set enp1s0f0np0 up\n",
    "sudo ip link set enp1s0f1np1 up\n",
    "\n",
    "# Restore IP addresses\n",
    "# spark-01: sudo ip addr add 192.168.100.10/24 dev enp1s0f0np0\n",
    "# spark-02: sudo ip addr add 192.168.100.11/24 dev enp1s0f0np0\n",
    "```\n",
    "\n",
    "**Verify RDMA devices are accessible:**\n",
    "```bash\n",
    "ibdev2netdev\n",
    "# Should show: rocep1s0f0 port 1 ==> enp1s0f0np0 (Up)\n",
    "#             rocep1s0f1 port 1 ==> enp1s0f1np1 (Up)\n",
    "```\n",
    "\n",
    "### 4.1 Verify NIXL Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480539c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIXL is installed\n",
      "\n",
      "=== UCX Device Detection ===\n",
      "#      Transport: self\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: sysv\n",
      "#      Transport: posix\n",
      "#      Transport: dc_mlx5\n",
      "#      Transport: rc_verbs\n",
      "#      Transport: rc_mlx5\n",
      "#      Transport: ud_verbs\n",
      "#      Transport: ud_mlx5\n",
      "#      Transport: dc_mlx5\n",
      "#      Transport: rc_verbs\n",
      "#      Transport: rc_mlx5\n",
      "#      Transport: ud_verbs\n",
      "#      Transport: ud_mlx5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check NIXL installation\n",
    "try:\n",
    "    from nixl._api import nixl_agent, nixl_agent_config\n",
    "    print(\"NIXL is installed\")\n",
    "    \n",
    "    # Check UCX devices\n",
    "    print(\"\\n=== UCX Device Detection ===\")\n",
    "    print(run_cmd(\"ucx_info -d 2>/dev/null | grep -E 'mlx5|Transport' | head -20\"))\n",
    "except ImportError:\n",
    "    print(\"NIXL not installed. Install with:\")\n",
    "    print(\"  pip install nixl[cu13]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25146255",
   "metadata": {},
   "source": [
    "### 4.2 NIXL Local Memory Registration Test\n",
    "\n",
    "Test NIXL memory registration and descriptor creation (single-node validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d46b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-02 12:39:17 NIXL INFO    _api.py:363 Backend UCX was instantiated\n",
      "2026-02-02 12:39:17 NIXL INFO    _api.py:253 Initialized NIXL agent: test_agent\n",
      "NIXL agent created successfully\n",
      "\n",
      "Registering GPU memory...\n",
      "Allocated GPU tensor: torch.Size([1024, 1024]), 4.2 MB\n",
      "GPU memory registration: SUCCESS\n",
      "Descriptor size: 163 bytes\n",
      "Descriptor serialization: SUCCESS\n",
      "\n",
      "============================================================\n",
      "Status: NIXL agent functional with GPU memory\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/src/github.com/elizabetht/spark/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# NIXL GPU memory registration test (local validation)\n",
    "try:\n",
    "    import torch\n",
    "    import os\n",
    "    os.environ[\"PATH\"] = \"/usr/local/ucx/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "    os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/ucx/lib:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "    from nixl._api import nixl_agent, nixl_agent_config\n",
    "    \n",
    "    # Create NIXL agent\n",
    "    config = nixl_agent_config(\n",
    "        enable_prog_thread=True,\n",
    "        backends=[\"UCX\"]\n",
    "    )\n",
    "    \n",
    "    agent = nixl_agent(\"test_agent\", config)\n",
    "    print(\"NIXL agent created successfully\")\n",
    "    \n",
    "    # GPU memory registration\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA not available. GPU required for this test.\")\n",
    "    \n",
    "    print(\"\\nRegistering GPU memory...\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    tensor = torch.ones((1024, 1024), dtype=torch.float32, device=device)\n",
    "    print(f\"Allocated GPU tensor: {tensor.shape}, {tensor.numel() * 4 / 1e6:.1f} MB\")\n",
    "    \n",
    "    reg_descs = agent.register_memory(tensor)\n",
    "    \n",
    "    if reg_descs:\n",
    "        print(\"GPU memory registration: SUCCESS\")\n",
    "        \n",
    "        # Get transfer descriptors\n",
    "        xfer_descs = agent.get_xfer_descs([tensor])\n",
    "        desc_str = agent.get_serialized_descs(xfer_descs)\n",
    "        print(f\"Descriptor size: {len(desc_str)} bytes\")\n",
    "        print(\"Descriptor serialization: SUCCESS\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Status: NIXL agent functional with GPU memory\")\n",
    "        print(\"=\" * 60)\n",
    "    else:\n",
    "        print(\"GPU memory registration: FAILED\")\n",
    "        print(\"\\nPossible causes:\")\n",
    "        print(\"  - UCX not compiled with CUDA support (check: ucx_info -d)\")\n",
    "        print(\"  - GPU memory not accessible via RDMA\")\n",
    "        print(\"  - RoCE adapters not configured for GPUDirect RDMA\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"NIXL not available: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a909c",
   "metadata": {},
   "source": [
    "### 4.3 NIXL Two-Node Transfer Test\n",
    "\n",
    "For a full RDMA transfer test, run the target script on the remote node and the initiator script locally.\n",
    "\n",
    "**On remote node (spark-02), run target:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5786bc4",
   "metadata": {},
   "source": [
    "### 4.2.1 GPU Memory Registration Status\n",
    "\n",
    "**DGX Spark limitation:** GPUDirect RDMA is not supported on DGX Spark. The platform uses a unified memory architecture where GPU-allocated pinned memory is not coherently accessible from PCIe devices. As a result, `nvidia-peermem` and GDRCopy do not work on this platform.\n",
    "\n",
    "**GPU memory still works:** While GPUDirect RDMA is unavailable, GPU memory allocation and registration succeed using UCX's `cuda_copy` and `cuda_ipc` transports. These transports stage data through host memory, adding latency but still providing GPU-to-GPU transfer capability.\n",
    "\n",
    "**Performance impact:**\n",
    "- Without GPUDirect RDMA (DGX Spark): Uses staging through host memory via `cuda_copy`\n",
    "- With GPUDirect RDMA (HGX/DGX H100): NIC directly accesses GPU memory (1.5-2x faster for large transfers)\n",
    "\n",
    "**Working example from NIXL repository:**\n",
    "\n",
    "The [basic_two_peers.py](https://github.com/ai-dynamo/nixl/blob/main/examples/python/basic_two_peers.py) example works with GPU memory on DGX Spark:\n",
    "\n",
    "```bash\n",
    "# On target node (spark-01)\n",
    "python3 basic_two_peers.py --mode=target --use_cuda=true --ip=192.168.100.10 --port=4242\n",
    "\n",
    "# On initiator node (spark-02)\n",
    "python3 basic_two_peers.py --mode=initiator --use_cuda=true --ip=192.168.100.10 --port=4242\n",
    "```\n",
    "\n",
    "This demonstrates that GPU memory works with NIXL on DGX Spark, even though transfers bounce through host memory internally.\n",
    "\n",
    "**To check UCX GPU support:**\n",
    "\n",
    "```bash\n",
    "# Verify UCX CUDA transports are available\n",
    "ucx_info -d | grep -i cuda\n",
    "# Should show: cuda_copy and cuda_ipc transports\n",
    "```\n",
    "\n",
    "**The examples below use GPU memory** to demonstrate that GPU-to-GPU transfers work on DGX Spark. While transfers stage through host memory (no zero-copy GPUDirect RDMA), using GPU memory is still beneficial as it avoids explicit Python-level CPU staging.\n",
    "\n",
    "**Performance comparison: CPU vs GPU memory on DGX Spark:**\n",
    "\n",
    "CPU memory path achieves higher throughput because the RDMA operation completes in one step:\n",
    "- RDMA READ directly into host DRAM over `rc_mlx5` transport\n",
    "- NIC writes directly to registered host memory buffer\n",
    "- Result: 80-100 Gbps (limited by Python/NIXL overhead, not hardware)\n",
    "\n",
    "GPU memory path is slower because it requires staging through host memory:\n",
    "- RDMA READ into temporary host bounce buffer\n",
    "- UCX `cuda_copy` transport copies host buffer to GPU memory\n",
    "- Additional synchronization and memory registration overhead\n",
    "- Result: Lower throughput, especially for one-sided RDMA READ operations\n",
    "\n",
    "The performance difference is a direct result of the missing zero-copy path. On platforms with GPUDirect RDMA (HGX, DGX H100), the NIC writes directly to GPU memory and both paths achieve similar throughput. The CPU appearing faster than GPU is the expected behavior on DGX Spark—it confirms GPU buffers are not on a zero-copy RDMA path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db85c994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Target Node Script ===\n",
      "Save to spark-01 as ~/target_node.py and run:\n",
      "  .venv/bin/python3 ~/target_node.py\n",
      "\n",
      "NOTE: If 'Address already in use' error, kill existing process:\n",
      "  pkill -f target_node.py\n",
      "\n",
      "#!/usr/bin/env python3\n",
      "# target_node.py - Run on spark-01\n",
      "\n",
      "import os\n",
      "os.environ[\"PATH\"] = \"/usr/local/ucx/bin:\" + os.environ.get(\"PATH\", \"\")\n",
      "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/ucx/lib:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
      "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1\"\n",
      "\n",
      "import time\n",
      "import torch\n",
      "from nixl._api import nixl_agent, nixl_agent_config\n",
      "\n",
      "config = nixl_agent_config(\n",
      "    enable_prog_thread=True,\n",
      "    enable_listen_thread=True,\n",
      "    listen_port=5555,\n",
      "    backends=[\"UCX\"]\n",
      ")\n",
      "\n",
      "agent = nixl_agent(\"target\", config)\n",
      "print(\"NIXL agent created\")\n",
      "\n",
      "# GPU memory (works via cuda_copy transport which stages through host memory)\n",
      "tensor = torch.ones((4096, 4096), dtype=torch.float32, device=\"cuda:0\")\n",
      "print(f\"Target tensor: {tensor.shape}, {tensor.numel() * 4 / 1e6:.1f} MB (GPU)\")\n",
      "\n",
      "agent.register_memory(tensor)\n",
      "print(\"Memory registered\")\n",
      "\n",
      "target_descs = agent.get_xfer_descs([tensor])\n",
      "desc_str = agent.get_serialized_descs(target_descs)\n",
      "print(f\"Descriptor ready ({len(desc_str)} bytes)\")\n",
      "\n",
      "print(\"Waiting for initiator...\")\n",
      "while not agent.check_remote_metadata(\"initiator\"):\n",
      "    time.sleep(0.1)\n",
      "\n",
      "agent.send_notif(\"initiator\", desc_str)\n",
      "print(\"Sent descriptors to initiator\")\n",
      "\n",
      "print(\"Waiting for transfer completion...\")\n",
      "while True:\n",
      "    notifs = agent.get_new_notifs()\n",
      "    if \"initiator\" in notifs:\n",
      "        for notif in notifs[\"initiator\"]:\n",
      "            if b\"done\" in notif:\n",
      "                print(\"Transfer completed!\")\n",
      "                break\n",
      "        else:\n",
      "            continue\n",
      "        break\n",
      "    time.sleep(0.1)\n",
      "\n",
      "print(\"Target finished\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Target node script (run on remote node)\n",
    "target_script = '''#!/usr/bin/env python3\n",
    "# target_node.py - Run on spark-01\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/usr/local/ucx/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/ucx/lib:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1\"\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from nixl._api import nixl_agent, nixl_agent_config\n",
    "\n",
    "config = nixl_agent_config(\n",
    "    enable_prog_thread=True,\n",
    "    enable_listen_thread=True,\n",
    "    listen_port=5555,\n",
    "    backends=[\"UCX\"]\n",
    ")\n",
    "\n",
    "agent = nixl_agent(\"target\", config)\n",
    "print(\"NIXL agent created\")\n",
    "\n",
    "# GPU memory (works via cuda_copy transport which stages through host memory)\n",
    "tensor = torch.ones((4096, 4096), dtype=torch.float32, device=\"cuda:0\")\n",
    "print(f\"Target tensor: {tensor.shape}, {tensor.numel() * 4 / 1e6:.1f} MB (GPU)\")\n",
    "\n",
    "agent.register_memory(tensor)\n",
    "print(\"Memory registered\")\n",
    "\n",
    "target_descs = agent.get_xfer_descs([tensor])\n",
    "desc_str = agent.get_serialized_descs(target_descs)\n",
    "print(f\"Descriptor ready ({len(desc_str)} bytes)\")\n",
    "\n",
    "print(\"Waiting for initiator...\")\n",
    "while not agent.check_remote_metadata(\"initiator\"):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "agent.send_notif(\"initiator\", desc_str)\n",
    "print(\"Sent descriptors to initiator\")\n",
    "\n",
    "print(\"Waiting for transfer completion...\")\n",
    "while True:\n",
    "    notifs = agent.get_new_notifs()\n",
    "    if \"initiator\" in notifs:\n",
    "        for notif in notifs[\"initiator\"]:\n",
    "            if b\"done\" in notif:\n",
    "                print(\"Transfer completed!\")\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(\"Target finished\")\n",
    "'''\n",
    "\n",
    "print(\"=== Target Node Script ===\")\n",
    "print(\"Save to spark-01 as ~/target_node.py and run:\")\n",
    "print(\"  .venv/bin/python3 ~/target_node.py\")\n",
    "print()\n",
    "print(\"NOTE: If 'Address already in use' error, kill existing process:\")\n",
    "print(\"  pkill -f target_node.py\")\n",
    "print()\n",
    "print(target_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7addee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating NIXL agent (check for UCX transport selection in logs)...\n",
      "2026-02-02 15:01:47 NIXL INFO    _api.py:363 Backend UCX was instantiated\n",
      "2026-02-02 15:01:47 NIXL INFO    _api.py:253 Initialized NIXL agent: initiator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/src/github.com/elizabetht/spark/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIXL agent created\n",
      "Local tensor: torch.Size([4096, 4096]), 67.1 MB (GPU)\n",
      "Registering memory (watch for cuda_copy transport selection)...\n",
      "Memory registered\n",
      "Connecting to target at 192.168.100.10:5555\n",
      "Waiting for descriptors...\n",
      "Received remote descriptors\n",
      "Starting RDMA READ (64 MB)...\n",
      "Transfer complete: 67.1 MB in 152.46 ms\n",
      "Throughput: 3.5 Gbps\n",
      "Data verification: PASSED\n",
      "Initiator finished\n"
     ]
    }
   ],
   "source": [
    "# Initiator node script - run directly from this notebook\n",
    "# PREREQUISITE: Target must be running on spark-01 and showing \"Waiting for initiator...\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# UCX logging - must be set BEFORE importing nixl\n",
    "os.environ[\"PATH\"] = \"/usr/local/ucx-1.20-cuda/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/ucx-1.20-cuda/lib:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1\"\n",
    "\n",
    "# Enable UCX logging (logs go to stderr)\n",
    "# os.environ[\"UCX_LOG_LEVEL\"] = \"debug\"  # Options: error, warn, info, debug, trace\n",
    "# os.environ[\"UCX_LOG_PRINT_ENABLE\"] = \"y\"\n",
    "\n",
    "# Redirect stderr to stdout so we can see UCX logs in notebook output\n",
    "import io\n",
    "from contextlib import redirect_stderr\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from nixl._api import nixl_agent, nixl_agent_config\n",
    "\n",
    "TARGET_IP = REMOTE_IP  # Uses REMOTE_IP from setup cell\n",
    "TARGET_PORT = 5555\n",
    "\n",
    "config = nixl_agent_config(\n",
    "    enable_prog_thread=True,\n",
    "    enable_listen_thread=True,\n",
    "    listen_port=0,\n",
    "    backends=[\"UCX\"]\n",
    ")\n",
    "\n",
    "print(\"Creating NIXL agent (check for UCX transport selection in logs)...\")\n",
    "sys.stderr.flush()\n",
    "agent = nixl_agent(\"initiator\", config)\n",
    "sys.stderr.flush()\n",
    "print(\"NIXL agent created\")\n",
    "\n",
    "# GPU memory (works via cuda_copy transport which stages through host memory)\n",
    "local_tensor = torch.zeros((4096, 4096), dtype=torch.float32, device=\"cuda:0\")\n",
    "print(f\"Local tensor: {local_tensor.shape}, {local_tensor.numel() * 4 / 1e6:.1f} MB (GPU)\")\n",
    "\n",
    "print(\"Registering memory (watch for cuda_copy transport selection)...\")\n",
    "sys.stderr.flush()\n",
    "agent.register_memory(local_tensor)\n",
    "sys.stderr.flush()\n",
    "print(\"Memory registered\")\n",
    "\n",
    "print(f\"Connecting to target at {TARGET_IP}:{TARGET_PORT}\")\n",
    "agent.fetch_remote_metadata(\"target\", TARGET_IP, TARGET_PORT)\n",
    "agent.send_local_metadata(TARGET_IP, TARGET_PORT)\n",
    "\n",
    "print(\"Waiting for descriptors...\")\n",
    "notifs = agent.get_new_notifs()\n",
    "while \"target\" not in notifs or len(notifs[\"target\"]) == 0:\n",
    "    time.sleep(0.1)\n",
    "    notifs = agent.get_new_notifs()\n",
    "\n",
    "remote_descs = agent.deserialize_descs(notifs[\"target\"][0])\n",
    "local_descs = agent.get_xfer_descs([local_tensor])\n",
    "print(\"Received remote descriptors\")\n",
    "\n",
    "print(\"Starting RDMA READ (64 MB)...\")\n",
    "sys.stderr.flush()\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "xfer_handle = agent.initialize_xfer(\"READ\", local_descs, remote_descs, \"target\", \"done\")\n",
    "agent.transfer(xfer_handle)\n",
    "\n",
    "while agent.check_xfer_state(xfer_handle) != \"DONE\":\n",
    "    time.sleep(0.001)\n",
    "\n",
    "elapsed = time.perf_counter() - start_time\n",
    "sys.stderr.flush()\n",
    "size_mb = local_tensor.numel() * 4 / 1e6\n",
    "throughput_gbps = (size_mb * 8) / (elapsed * 1000)\n",
    "\n",
    "print(f\"Transfer complete: {size_mb:.1f} MB in {elapsed*1000:.2f} ms\")\n",
    "print(f\"Throughput: {throughput_gbps:.1f} Gbps\")\n",
    "\n",
    "expected = torch.ones((4096, 4096), dtype=torch.float32, device=\"cuda:0\")\n",
    "if torch.allclose(local_tensor, expected):\n",
    "    print(\"Data verification: PASSED\")\n",
    "else:\n",
    "    print(\"Data verification: FAILED\")\n",
    "\n",
    "print(\"Initiator finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25dc9032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dual-Rail Target Node Script ===\n",
      "Save to spark-01 as ~/dual_rail_target.py and run:\n",
      "  .venv/bin/python3 ~/dual_rail_target.py\n",
      "\n",
      "NOTE: If 'Address already in use' error, kill existing process:\n",
      "  pkill -f dual_rail_target.py\n",
      "\n",
      "#!/usr/bin/env python3\n",
      "# dual_rail_target.py - Run on spark-01\n",
      "\n",
      "import os\n",
      "os.environ[\"PATH\"] = \"/usr/local/ucx-1.20-cuda/bin:\" + os.environ.get(\"PATH\", \"\")\n",
      "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/ucx-1.20-cuda/lib:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
      "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1,rocep1s0f1:1\"\n",
      "os.environ[\"UCX_TLS\"] = \"rc,cuda,tcp,sm,self\"\n",
      "os.environ[\"UCX_MAX_RNDV_LANES\"] = \"2\"\n",
      "os.environ[\"UCX_MAX_EAGER_LANES\"] = \"2\"\n",
      "#os.environ[\"UCX_RNDV_THRESH\"] = \"65536\"\n",
      "\n",
      "import time\n",
      "import torch\n",
      "from nixl._api import nixl_agent, nixl_agent_config\n",
      "\n",
      "config = nixl_agent_config(\n",
      "    enable_prog_thread=True,\n",
      "    enable_listen_thread=True,\n",
      "    listen_port=5556,\n",
      "    backends=[\"UCX\"]\n",
      ")\n",
      "\n",
      "agent = nixl_agent(\"target\", config)\n",
      "print(\"NIXL agent created (dual-rail)\")\n",
      "\n",
      "# GPU memory buffer (1 GB)\n",
      "tensor = torch.ones((16384, 16384), dtype=torch.float32, device=\"cuda:0\")\n",
      "size_mb = tensor.numel() * 4 / 1e6\n",
      "print(f\"Target tensor: {tensor.shape}, {size_mb:.1f} MB (GPU)\")\n",
      "\n",
      "agent.register_memory(tensor)\n",
      "print(\"Memory registered\")\n",
      "\n",
      "target_descs = agent.get_xfer_descs([tensor])\n",
      "desc_str = agent.get_serialized_descs(target_descs)\n",
      "print(f\"Descriptor ready ({len(desc_str)} bytes)\")\n",
      "\n",
      "print(\"Waiting for initiator...\")\n",
      "while not agent.check_remote_metadata(\"initiator\"):\n",
      "    time.sleep(0.1)\n",
      "\n",
      "agent.send_notif(\"initiator\", desc_str)\n",
      "print(\"Sent descriptors to initiator\")\n",
      "\n",
      "print(\"Waiting for transfer completion...\")\n",
      "while True:\n",
      "    notifs = agent.get_new_notifs()\n",
      "    if \"initiator\" in notifs:\n",
      "        for notif in notifs[\"initiator\"]:\n",
      "            if b\"done\" in notif:\n",
      "                print(\"Transfer completed!\")\n",
      "                break\n",
      "        else:\n",
      "            continue\n",
      "        break\n",
      "    time.sleep(0.1)\n",
      "\n",
      "print(\"Target finished\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dual-rail target script (print for remote node)\n",
    "dual_target_script = '''#!/usr/bin/env python3\n",
    "# dual_rail_target.py - Run on spark-01\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/usr/local/ucx-1.20-cuda/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/ucx-1.20-cuda/lib:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1,rocep1s0f1:1\"\n",
    "os.environ[\"UCX_TLS\"] = \"rc,cuda,tcp,sm,self\"\n",
    "os.environ[\"UCX_MAX_RNDV_LANES\"] = \"2\"\n",
    "os.environ[\"UCX_MAX_EAGER_LANES\"] = \"2\"\n",
    "#os.environ[\"UCX_RNDV_THRESH\"] = \"65536\"\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from nixl._api import nixl_agent, nixl_agent_config\n",
    "\n",
    "config = nixl_agent_config(\n",
    "    enable_prog_thread=True,\n",
    "    enable_listen_thread=True,\n",
    "    listen_port=5556,\n",
    "    backends=[\"UCX\"]\n",
    ")\n",
    "\n",
    "agent = nixl_agent(\"target\", config)\n",
    "print(\"NIXL agent created (dual-rail)\")\n",
    "\n",
    "# GPU memory buffer (1 GB)\n",
    "tensor = torch.ones((16384, 16384), dtype=torch.float32, device=\"cuda:0\")\n",
    "size_mb = tensor.numel() * 4 / 1e6\n",
    "print(f\"Target tensor: {tensor.shape}, {size_mb:.1f} MB (GPU)\")\n",
    "\n",
    "agent.register_memory(tensor)\n",
    "print(\"Memory registered\")\n",
    "\n",
    "target_descs = agent.get_xfer_descs([tensor])\n",
    "desc_str = agent.get_serialized_descs(target_descs)\n",
    "print(f\"Descriptor ready ({len(desc_str)} bytes)\")\n",
    "\n",
    "print(\"Waiting for initiator...\")\n",
    "while not agent.check_remote_metadata(\"initiator\"):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "agent.send_notif(\"initiator\", desc_str)\n",
    "print(\"Sent descriptors to initiator\")\n",
    "\n",
    "print(\"Waiting for transfer completion...\")\n",
    "while True:\n",
    "    notifs = agent.get_new_notifs()\n",
    "    if \"initiator\" in notifs:\n",
    "        for notif in notifs[\"initiator\"]:\n",
    "            if b\"done\" in notif:\n",
    "                print(\"Transfer completed!\")\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(\"Target finished\")\n",
    "'''\n",
    "\n",
    "print(\"=== Dual-Rail Target Node Script ===\")\n",
    "print(\"Save to spark-01 as ~/dual_rail_target.py and run:\")\n",
    "print(\"  .venv/bin/python3 ~/dual_rail_target.py\")\n",
    "print()\n",
    "print(\"NOTE: If 'Address already in use' error, kill existing process:\")\n",
    "print(\"  pkill -f dual_rail_target.py\")\n",
    "print()\n",
    "print(dual_target_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010274b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-02 13:48:13 NIXL INFO    _api.py:363 Backend UCX was instantiated\n",
      "2026-02-02 13:48:13 NIXL INFO    _api.py:253 Initialized NIXL agent: initiator\n",
      "NIXL agent created (dual-rail)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/src/github.com/elizabetht/spark/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local tensor: torch.Size([16384, 16384]), 1073.7 MB (GPU)\n",
      "Memory registered\n",
      "Connecting to target at 192.168.100.10:5556\n",
      "Waiting for descriptors...\n",
      "Received remote descriptors\n",
      "Starting RDMA READ (1074 MB)...\n",
      "Transfer complete: 1073.7 MB in 1761.09 ms\n",
      "Throughput: 4.9 Gbps\n",
      "Initiator finished\n"
     ]
    }
   ],
   "source": [
    "# Dual-rail initiator - run directly from this notebook\n",
    "# PREREQUISITE: Target must be running on spark-01 and showing \"Waiting for initiator...\"\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/usr/local/ucx-1.20-cuda/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/ucx-1.20-cuda/lib:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1,rocep1s0f1:1\"\n",
    "os.environ[\"UCX_TLS\"] = \"rc,cuda,tcp,sm,self\"\n",
    "os.environ[\"UCX_MAX_RNDV_LANES\"] = \"2\"\n",
    "os.environ[\"UCX_MAX_EAGER_LANES\"] = \"2\"\n",
    "os.environ[\"UCX_RNDV_THRESH\"] = \"65536\"\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from nixl._api import nixl_agent, nixl_agent_config\n",
    "\n",
    "TARGET_IP = REMOTE_IP  # Uses REMOTE_IP from setup cell\n",
    "TARGET_PORT = 5556\n",
    "\n",
    "config = nixl_agent_config(\n",
    "    enable_prog_thread=True,\n",
    "    enable_listen_thread=True,\n",
    "    listen_port=0,\n",
    "    backends=[\"UCX\"]\n",
    ")\n",
    "\n",
    "agent = nixl_agent(\"initiator\", config)\n",
    "print(\"NIXL agent created (dual-rail)\")\n",
    "\n",
    "# GPU memory buffer (1 GB)\n",
    "local_tensor = torch.zeros((16384, 16384), dtype=torch.float32, device=\"cuda:0\")\n",
    "size_mb = local_tensor.numel() * 4 / 1e6\n",
    "print(f\"Local tensor: {local_tensor.shape}, {size_mb:.1f} MB (GPU)\")\n",
    "\n",
    "agent.register_memory(local_tensor)\n",
    "print(\"Memory registered\")\n",
    "\n",
    "print(f\"Connecting to target at {TARGET_IP}:{TARGET_PORT}\")\n",
    "agent.fetch_remote_metadata(\"target\", TARGET_IP, TARGET_PORT)\n",
    "agent.send_local_metadata(TARGET_IP, TARGET_PORT)\n",
    "\n",
    "print(\"Waiting for descriptors...\")\n",
    "notifs = agent.get_new_notifs()\n",
    "while \"target\" not in notifs or len(notifs[\"target\"]) == 0:\n",
    "    time.sleep(0.1)\n",
    "    notifs = agent.get_new_notifs()\n",
    "\n",
    "remote_descs = agent.deserialize_descs(notifs[\"target\"][0])\n",
    "local_descs = agent.get_xfer_descs([local_tensor])\n",
    "print(\"Received remote descriptors\")\n",
    "\n",
    "print(f\"Starting RDMA READ ({size_mb:.0f} MB)...\")\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "xfer_handle = agent.initialize_xfer(\"READ\", local_descs, remote_descs, \"target\", \"done\")\n",
    "agent.transfer(xfer_handle)\n",
    "\n",
    "while agent.check_xfer_state(xfer_handle) != \"DONE\":\n",
    "    time.sleep(0.001)\n",
    "\n",
    "elapsed = time.perf_counter() - start_time\n",
    "throughput_gbps = (size_mb * 8) / (elapsed * 1000)\n",
    "\n",
    "print(f\"Transfer complete: {size_mb:.1f} MB in {elapsed*1000:.2f} ms\")\n",
    "print(f\"Throughput: {throughput_gbps:.1f} Gbps\")\n",
    "\n",
    "print(\"Initiator finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f6de4",
   "metadata": {},
   "source": [
    "### Why GPU Memory is Slower than CPU Memory on DGX Spark\n",
    "\n",
    "**Observed Results:**\n",
    "| Memory Type | Throughput |\n",
    "|-------------|------------|\n",
    "| CPU (DRAM)  | ~83 Gbps   |\n",
    "| GPU (VRAM)  | ~4 Gbps    |\n",
    "\n",
    "**Root Cause: No GPUDirect RDMA on DGX Spark**\n",
    "\n",
    "DGX Spark uses a unified memory architecture where the RoCE NIC cannot directly access GPU memory. When you register GPU memory with NIXL/UCX:\n",
    "\n",
    "```\n",
    "CPU Memory Path (Fast):\n",
    "┌─────────┐    RDMA     ┌─────────┐\n",
    "│  CPU    │ ──────────► │  CPU    │   Direct NIC-to-memory transfer\n",
    "│  DRAM   │  ~83 Gbps   │  DRAM   │   No CPU involvement\n",
    "└─────────┘             └─────────┘\n",
    "\n",
    "GPU Memory Path (Slow):\n",
    "┌─────────┐  cuda_copy  ┌─────────┐    RDMA     ┌─────────┐  cuda_copy  ┌─────────┐\n",
    "│  GPU    │ ──────────► │  CPU    │ ──────────► │  CPU    │ ──────────► │  GPU    │\n",
    "│  VRAM   │   PCIe      │ bounce  │  ~83 Gbps   │ bounce  │   PCIe      │  VRAM   │\n",
    "└─────────┘             │ buffer  │             │ buffer  │             └─────────┘\n",
    "                        └─────────┘             └─────────┘\n",
    "```\n",
    "\n",
    "**The GPU path requires:**\n",
    "1. `cuda_copy`: GPU → CPU bounce buffer (PCIe bandwidth limited)\n",
    "2. RDMA transfer: CPU → CPU (fast)\n",
    "3. `cuda_copy`: CPU bounce buffer → GPU (PCIe bandwidth limited)\n",
    "\n",
    "**Verification with UCX logging:**\n",
    "\n",
    "Set these environment variables to see which transports UCX selects:\n",
    "```bash\n",
    "export UCX_LOG_LEVEL=info\n",
    "export UCX_LOG_PRINT_ENABLE=y\n",
    "```\n",
    "\n",
    "You'll see:\n",
    "- CPU memory: Uses `rc_mlx5` (direct RDMA)\n",
    "- GPU memory: Uses `cuda_copy` + `rc_mlx5` (staged transfer)\n",
    "\n",
    "**On platforms with GPUDirect RDMA** (DGX H100, HGX):\n",
    "- NIC registers GPU memory directly via `nvidia-peermem` kernel module\n",
    "- GPU-to-GPU transfers bypass CPU entirely\n",
    "- Both paths achieve similar throughput (~80+ Gbps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7ed94",
   "metadata": {},
   "source": [
    "### Visualizing Host-Staged GPU Transfers\n",
    "\n",
    "The following diagnostic shows evidence that GPU transfers go through host memory bounce buffers when `nvidia_peermem` is not loaded. We can observe this by:\n",
    "\n",
    "1. **Monitoring host memory** during GPU transfers (bounce buffers appear in RAM)\n",
    "2. **Comparing transfer latency** between GPU and CPU memory\n",
    "3. **Checking UCX transport selection** in debug logs\n",
    "\n",
    "If GPUDirect RDMA were active, GPU transfers would bypass host memory entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc0a7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "HOST-STAGING DIAGNOSTIC\n",
      "============================================================\n",
      "\n",
      "nvidia_peermem loaded: NO ✗\n",
      "  → GPU transfers will use host memory bounce buffers\n",
      "  → This is why we can observe host RAM usage during GPU transfers\n",
      "\n",
      "Baseline host memory: 6570 MB used / 122506 MB total\n",
      "\n",
      "Allocating 512 MB GPU tensor...\n",
      "After GPU alloc: 7093 MB used (delta: +523 MB)\n",
      "\n",
      "Simulating host-staged transfer (GPU → pinned host → GPU)...\n",
      "This demonstrates the bounce buffer path UCX uses without GPUDirect RDMA:\n",
      "\n",
      "  Step 1: GPU → Host (cuda_copy stage 1)\n",
      "           Host memory delta: +511 MB\n",
      "           → Bounce buffer allocated in host RAM\n",
      "\n",
      "  Step 2: Host → GPU (cuda_copy stage 2)\n",
      "           Host memory delta: +520 MB\n",
      "\n",
      "After cleanup: 6581 MB used (delta from baseline: +11 MB)\n",
      "\n",
      "============================================================\n",
      "INTERPRETATION\n",
      "============================================================\n",
      "\n",
      "The 511 MB increase in host memory during GPU→Host copy\n",
      "confirms that data passes through host RAM bounce buffers.\n",
      "\n",
      "During NIXL/UCX GPU transfers, this same path is used:\n",
      "  1. cuda_copy: GPU VRAM → Host bounce buffer (~512 MB allocated)\n",
      "  2. rc_mlx5:   Host buffer → Network → Remote host buffer  \n",
      "  3. cuda_copy: Remote host buffer → Remote GPU VRAM\n",
      "\n",
      "This explains why GPU transfers achieve ~4 Gbps instead of ~83 Gbps:\n",
      "  - PCIe bandwidth to/from GPU becomes the bottleneck\n",
      "  - Two extra memory copies add latency\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Visualize host-staging during GPU memory transfer\n",
    "# This shows that GPU transfers use host memory bounce buffers\n",
    "\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def get_memory_stats():\n",
    "    \"\"\"Get current host memory usage in MB\"\"\"\n",
    "    result = subprocess.run(['free', '-m'], capture_output=True, text=True)\n",
    "    lines = result.stdout.strip().split('\\n')\n",
    "    mem_line = lines[1].split()\n",
    "    return {\n",
    "        'total': int(mem_line[1]),\n",
    "        'used': int(mem_line[2]),\n",
    "        'free': int(mem_line[3]),\n",
    "        'available': int(mem_line[6])\n",
    "    }\n",
    "\n",
    "def monitor_memory(duration_sec, interval=0.1):\n",
    "    \"\"\"Monitor memory usage over time\"\"\"\n",
    "    samples = []\n",
    "    start = time.time()\n",
    "    while time.time() - start < duration_sec:\n",
    "        stats = get_memory_stats()\n",
    "        stats['timestamp'] = time.time() - start\n",
    "        samples.append(stats)\n",
    "        time.sleep(interval)\n",
    "    return samples\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"HOST-STAGING DIAGNOSTIC\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check nvidia_peermem status\n",
    "peermem_result = subprocess.run(['lsmod'], capture_output=True, text=True)\n",
    "peermem_loaded = 'nvidia_peermem' in peermem_result.stdout\n",
    "\n",
    "print(f\"\\nnvidia_peermem loaded: {'YES ✓' if peermem_loaded else 'NO ✗'}\")\n",
    "if not peermem_loaded:\n",
    "    print(\"  → GPU transfers will use host memory bounce buffers\")\n",
    "    print(\"  → This is why we can observe host RAM usage during GPU transfers\")\n",
    "\n",
    "# Baseline memory\n",
    "baseline = get_memory_stats()\n",
    "print(f\"\\nBaseline host memory: {baseline['used']} MB used / {baseline['total']} MB total\")\n",
    "\n",
    "# Allocate GPU tensor\n",
    "tensor_size_mb = 512  # 512 MB test\n",
    "elements = (tensor_size_mb * 1024 * 1024) // 4  # float32 = 4 bytes\n",
    "side = int(elements ** 0.5)\n",
    "\n",
    "print(f\"\\nAllocating {tensor_size_mb} MB GPU tensor...\")\n",
    "gpu_tensor = torch.ones((side, side), dtype=torch.float32, device='cuda:0')\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "post_alloc = get_memory_stats()\n",
    "print(f\"After GPU alloc: {post_alloc['used']} MB used (delta: {post_alloc['used'] - baseline['used']:+d} MB)\")\n",
    "\n",
    "# Simulate transfer by copying to pinned host memory (mimics cuda_copy path)\n",
    "print(f\"\\nSimulating host-staged transfer (GPU → pinned host → GPU)...\")\n",
    "print(\"This demonstrates the bounce buffer path UCX uses without GPUDirect RDMA:\\n\")\n",
    "\n",
    "# Monitor during transfer\n",
    "print(\"  Step 1: GPU → Host (cuda_copy stage 1)\")\n",
    "pre_copy = get_memory_stats()\n",
    "host_tensor = gpu_tensor.cpu()  # This allocates host memory\n",
    "torch.cuda.synchronize()\n",
    "post_copy = get_memory_stats()\n",
    "host_delta = post_copy['used'] - pre_copy['used']\n",
    "print(f\"           Host memory delta: {host_delta:+d} MB\")\n",
    "print(f\"           → Bounce buffer allocated in host RAM\")\n",
    "\n",
    "print(\"\\n  Step 2: Host → GPU (cuda_copy stage 2)\")\n",
    "pre_back = get_memory_stats()\n",
    "gpu_tensor_2 = host_tensor.cuda()\n",
    "torch.cuda.synchronize()\n",
    "post_back = get_memory_stats()\n",
    "print(f\"           Host memory delta: {post_back['used'] - pre_back['used']:+d} MB\")\n",
    "\n",
    "# Cleanup\n",
    "del host_tensor, gpu_tensor, gpu_tensor_2\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "final = get_memory_stats()\n",
    "print(f\"\\nAfter cleanup: {final['used']} MB used (delta from baseline: {final['used'] - baseline['used']:+d} MB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 60)\n",
    "if host_delta > tensor_size_mb * 0.5:  # At least half the tensor size appeared in host RAM\n",
    "    print(f\"\"\"\n",
    "The {host_delta} MB increase in host memory during GPU→Host copy\n",
    "confirms that data passes through host RAM bounce buffers.\n",
    "\n",
    "During NIXL/UCX GPU transfers, this same path is used:\n",
    "  1. cuda_copy: GPU VRAM → Host bounce buffer (~{tensor_size_mb} MB allocated)\n",
    "  2. rc_mlx5:   Host buffer → Network → Remote host buffer  \n",
    "  3. cuda_copy: Remote host buffer → Remote GPU VRAM\n",
    "\n",
    "This explains why GPU transfers achieve ~4 Gbps instead of ~83 Gbps:\n",
    "  - PCIe bandwidth to/from GPU becomes the bottleneck\n",
    "  - Two extra memory copies add latency\n",
    "\"\"\")\n",
    "else:\n",
    "    print(f\"\"\"\n",
    "Host memory delta was only {host_delta} MB (expected ~{tensor_size_mb} MB).\n",
    "This could indicate:\n",
    "  - Memory was already pre-allocated\n",
    "  - System has unified memory architecture\n",
    "  - Measurement timing issue\n",
    "\n",
    "Run 'watch -n 0.5 free -m' in a terminal during transfers for real-time view.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual ASCII diagram of data flow\n",
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════════╗\n",
    "║                     DATA PATH COMPARISON                                     ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                                                                              ║\n",
    "║  WITH nvidia_peermem (GPUDirect RDMA) - NOT available on DGX Spark:         ║\n",
    "║  ─────────────────────────────────────────────────────────────────          ║\n",
    "║                                                                              ║\n",
    "║    ┌─────────┐                                      ┌─────────┐             ║\n",
    "║    │   GPU   │ ════════════ RDMA ════════════════► │   GPU   │             ║\n",
    "║    │  VRAM   │         ~80-90 Gbps                  │  VRAM   │             ║\n",
    "║    └─────────┘      (NIC reads GPU directly)        └─────────┘             ║\n",
    "║                                                                              ║\n",
    "║                                                                              ║\n",
    "║  WITHOUT nvidia_peermem (Host-Staged) - Current DGX Spark behavior:         ║\n",
    "║  ───────────────────────────────────────────────────────────────            ║\n",
    "║                                                                              ║\n",
    "║    ┌─────────┐   cuda_copy   ┌─────────┐   RDMA    ┌─────────┐   cuda_copy  ┌─────────┐\n",
    "║    │   GPU   │ ───────────► │  Host   │ ────────► │  Host   │ ───────────► │   GPU   │\n",
    "║    │  VRAM   │    ~15 GB/s   │ Bounce  │  ~83 Gbps │ Bounce  │   ~15 GB/s   │  VRAM   │\n",
    "║    └─────────┘    (PCIe)     │ Buffer  │           │ Buffer  │    (PCIe)    └─────────┘\n",
    "║                              └─────────┘           └─────────┘                        ║\n",
    "║                                                                              ║\n",
    "║    Bottleneck: PCIe transfers limit effective throughput to ~4 Gbps         ║\n",
    "║                                                                              ║\n",
    "╚══════════════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "Evidence that host-staging is active:\n",
    "  1. UCX logs show 'cuda_copy' transport being used\n",
    "  2. Host memory usage increases during GPU transfers (bounce buffers)\n",
    "  3. GPU transfer throughput (~4 Gbps) << CPU transfer throughput (~83 Gbps)\n",
    "  4. GDAKI warning: \"please load Nvidia peermem driver\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab90486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\['\n",
      "/tmp/ipykernel_948928/1912677491.py:13: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"ucx_info -d 2>/dev/null | grep -E '(md\\[|reg_mem|alloc)' | head -30\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UCX CUDA Transport Support ===\n",
      "#         memory types: host (access,reg_nonblock,reg,cache)\n",
      "#      Transport: self\n",
      "#         Device: memory\n",
      "#         memory types: host (access,reg_nonblock,reg,cache)\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#         memory types: host (access,alloc,cache)\n",
      "#      Transport: sysv\n",
      "#         Device: memory\n",
      "#         memory types: host (access,alloc,cache)\n",
      "#      Transport: posix\n",
      "#         Device: memory\n",
      "#           local memory handle is required for zcopy\n",
      "#           memory invalidation is supported\n",
      "#         memory types: host (access,reg_nonblock,reg,cache), rdma (alloc,cache)\n",
      "#      Transport: dc_mlx5\n",
      "#      Transport: rc_verbs\n",
      "#      Transport: rc_mlx5\n",
      "#      Transport: ud_verbs\n",
      "#      Transport: ud_mlx5\n",
      "#           local memory handle is required for zcopy\n",
      "#           memory invalidation is supported\n",
      "#         memory types: host (access,reg_nonblock,reg,cache)\n",
      "#      Transport: dc_mlx5\n",
      "#      Transport: rc_verbs\n",
      "#      Transport: rc_mlx5\n",
      "#      Transport: ud_verbs\n",
      "#      Transport: ud_mlx5\n",
      "#           local memory handle is required for zcopy\n",
      "#           memory invalidation is supported\n",
      "#         memory types: host (access,reg_nonblock,reg,cache)\n",
      "#      Transport: dc_mlx5\n",
      "#      Transport: rc_verbs\n",
      "#      Transport: rc_mlx5\n",
      "#      Transport: ud_verbs\n",
      "\n",
      "\n",
      "=== UCX Memory Domains ===\n",
      "#             allocate: unlimited\n",
      "#         memory types: host (access,alloc,cache)\n",
      "#             allocate: <= 62723240K\n",
      "#         memory types: host (access,alloc,cache)\n",
      "#             allocate: <= 43690\n",
      "#         memory types: host (access,reg_nonblock,reg,cache), rdma (alloc,cache)\n",
      "\n",
      "\n",
      "=== Key Observations ===\n",
      "\n",
      "Look for these patterns in the output above:\n",
      "\n",
      "1. CUDA transports available:\n",
      "   - cuda_copy: Stages GPU↔CPU via PCIe (SLOW for large transfers)\n",
      "   - cuda_ipc: GPU-to-GPU on same node via NVLink/PCIe (not applicable here)\n",
      "\n",
      "2. Memory domain capabilities (md[]):\n",
      "   - 'reg_mem: host' = Can only register CPU memory for RDMA\n",
      "   - 'reg_mem: cuda' = Can register GPU memory directly (GPUDirect RDMA)\n",
      "\n",
      "DGX Spark limitation: The RoCE adapters show 'reg_mem: host' only.\n",
      "GPU memory must be staged through CPU bounce buffers, adding latency\n",
      "and limiting throughput to PCIe bandwidth (~32 GB/s per direction).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Check UCX transport capabilities\n",
    "import subprocess\n",
    "\n",
    "print(\"=== UCX CUDA Transport Support ===\")\n",
    "result = subprocess.run(\n",
    "    \"ucx_info -d 2>/dev/null | grep -E '(Transport|cuda|memory)' | head -40\",\n",
    "    shell=True, capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout)\n",
    "\n",
    "print(\"\\n=== UCX Memory Domains ===\")\n",
    "result = subprocess.run(\n",
    "    \"ucx_info -d 2>/dev/null | grep -E '(md\\[|reg_mem|alloc)' | head -30\",\n",
    "    shell=True, capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout)\n",
    "\n",
    "print(\"\\n=== Key Observations ===\")\n",
    "print(\"\"\"\n",
    "Look for these patterns in the output above:\n",
    "\n",
    "1. CUDA transports available:\n",
    "   - cuda_copy: Stages GPU↔CPU via PCIe (SLOW for large transfers)\n",
    "   - cuda_ipc: GPU-to-GPU on same node via NVLink/PCIe (not applicable here)\n",
    "\n",
    "2. Memory domain capabilities (md[]):\n",
    "   - 'reg_mem: host' = Can only register CPU memory for RDMA\n",
    "   - 'reg_mem: cuda' = Can register GPU memory directly (GPUDirect RDMA)\n",
    "\n",
    "DGX Spark limitation: The RoCE adapters show 'reg_mem: host' only.\n",
    "GPU memory must be staged through CPU bounce buffers, adding latency\n",
    "and limiting throughput to PCIe bandwidth (~32 GB/s per direction).\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6bd07d",
   "metadata": {},
   "source": [
    "### 4.3.2 NIXL latency test (two-node)\n",
    "\n",
    "This measures per-transfer latency for small CPU buffers and includes Python overhead. Use it for relative comparisons, not absolute wire latency.\n",
    "\n",
    "**Why the dual-rail throughput scripts are not suitable for latency:**\n",
    "- They time one multi-gigabyte transfer, which reports bandwidth instead of per-transfer latency.\n",
    "- Large transfers use rendezvous and pipelining, so timing reflects sustained throughput, not one-way latency.\n",
    "- Latency measurement requires thousands of small transfers with per-iteration timing and percentile stats.\n",
    "\n",
    "**Measured results (dual-rail, CPU, 4 KB, 1000 iterations):**\n",
    "- Avg: 58.6 μs\n",
    "- P50: 11.1 μs\n",
    "- P95: 166.6 μs\n",
    "\n",
    "**Measured results (single-rail, CPU, 4 KB, 1000 iterations):**\n",
    "- Avg: 17.4 μs\n",
    "- P50: 16.2 μs\n",
    "- P95: 20.8 μs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate NIXL latency test scripts\n",
    "latency_target_script = '''#!/usr/bin/env python3\n",
    "# nixl_latency_target.py - Run on spark-01\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/usr/local/ucx/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/ucx/lib:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1,rocep1s0f1:1,enp1s0f0np0,enp1s0f1np1,lo\"\n",
    "os.environ[\"UCX_TLS\"] = \"rc_verbs,rc_mlx5,tcp,sockcm,cuda_copy\"\n",
    "os.environ[\"UCX_MAX_RNDV_LANES\"] = \"2\"\n",
    "os.environ[\"UCX_MAX_EAGER_LANES\"] = \"2\"\n",
    "os.environ[\"UCX_RNDV_THRESH\"] = \"0\"\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from nixl._api import nixl_agent, nixl_agent_config\n",
    "\n",
    "config = nixl_agent_config(\n",
    "    enable_prog_thread=True,\n",
    "    enable_listen_thread=True,\n",
    "    listen_port=5557,\n",
    "    backends=[\"UCX\"]\n",
    ")\n",
    "\n",
    "agent = nixl_agent(\"target\", config)\n",
    "print(\"NIXL agent created (latency target)\")\n",
    "\n",
    "# Small CPU buffer (4 KB)\n",
    "tensor = torch.ones((1024,), dtype=torch.float32, device=\"cpu\")\n",
    "print(f\"Target tensor: {tensor.shape}, {tensor.numel() * 4} bytes (CPU)\")\n",
    "\n",
    "agent.register_memory(tensor)\n",
    "target_descs = agent.get_xfer_descs([tensor])\n",
    "desc_str = agent.get_serialized_descs(target_descs)\n",
    "print(f\"Descriptor ready ({len(desc_str)} bytes)\")\n",
    "\n",
    "print(\"Waiting for initiator...\")\n",
    "while not agent.check_remote_metadata(\"initiator\"):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "agent.send_notif(\"initiator\", desc_str)\n",
    "print(\"Sent descriptors to initiator\")\n",
    "\n",
    "# Wait for completion signal\n",
    "while True:\n",
    "    notifs = agent.get_new_notifs()\n",
    "    if \"initiator\" in notifs:\n",
    "        for notif in notifs[\"initiator\"]:\n",
    "            if b\"done\" in notif:\n",
    "                print(\"Latency test completed\")\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(\"Target finished\")\n",
    "'''\n",
    "\n",
    "latency_initiator_script = f'''#!/usr/bin/env python3\n",
    "# nixl_latency_initiator.py - Run on spark-02\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/usr/local/ucx/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/ucx/lib:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1,rocep1s0f1:1,enp1s0f0np0,enp1s0f1np1,lo\"\n",
    "os.environ[\"UCX_TLS\"] = \"rc_verbs,rc_mlx5,tcp,sockcm\"\n",
    "os.environ[\"UCX_MAX_RNDV_LANES\"] = \"2\"\n",
    "os.environ[\"UCX_MAX_EAGER_LANES\"] = \"2\"\n",
    "os.environ[\"UCX_RNDV_THRESH\"] = \"0\"\n",
    "\n",
    "import time\n",
    "import statistics\n",
    "import torch\n",
    "from nixl._api import nixl_agent, nixl_agent_config\n",
    "\n",
    "TARGET_IP = \"{REMOTE_IP}\"\n",
    "TARGET_PORT = 5557\n",
    "ITERATIONS = 1000\n",
    "\n",
    "config = nixl_agent_config(\n",
    "    enable_prog_thread=True,\n",
    "    enable_listen_thread=True,\n",
    "    listen_port=0,\n",
    "    backends=[\"UCX\"]\n",
    ")\n",
    "\n",
    "agent = nixl_agent(\"initiator\", config)\n",
    "print(\"NIXL agent created (latency initiator)\")\n",
    "\n",
    "# Small CPU buffer (4 KB)\n",
    "local_tensor = torch.zeros((1024,), dtype=torch.float32, device=\"cpu\")\n",
    "agent.register_memory(local_tensor)\n",
    "\n",
    "print(f\"Connecting to target at {{TARGET_IP}}:{{TARGET_PORT}}\")\n",
    "agent.fetch_remote_metadata(\"target\", TARGET_IP, TARGET_PORT)\n",
    "agent.send_local_metadata(TARGET_IP, TARGET_PORT)\n",
    "\n",
    "print(\"Waiting for descriptors...\")\n",
    "notifs = agent.get_new_notifs()\n",
    "while \"target\" not in notifs or len(notifs[\"target\"]) == 0:\n",
    "    time.sleep(0.1)\n",
    "    notifs = agent.get_new_notifs()\n",
    "\n",
    "remote_descs = agent.deserialize_descs(notifs[\"target\"][0])\n",
    "local_descs = agent.get_xfer_descs([local_tensor])\n",
    "print(\"Received remote descriptors\")\n",
    "\n",
    "latencies_us = []\n",
    "for _ in range(ITERATIONS):\n",
    "    start_ns = time.perf_counter_ns()\n",
    "    xfer_handle = agent.initialize_xfer(\"READ\", local_descs, remote_descs, \"target\", \"done\")\n",
    "    agent.transfer(xfer_handle)\n",
    "    while agent.check_xfer_state(xfer_handle) != \"DONE\":\n",
    "        time.sleep(0.0001)\n",
    "    elapsed_us = (time.perf_counter_ns() - start_ns) / 1000\n",
    "    latencies_us.append(elapsed_us)\n",
    "\n",
    "avg_us = sum(latencies_us) / len(latencies_us)\n",
    "p50_us = statistics.median(latencies_us)\n",
    "p95_us = statistics.quantiles(latencies_us, n=20)[18]  # ~95th percentile\n",
    "print(f\"Latency (avg): {{avg_us:.1f}} μs\")\n",
    "print(f\"Latency (p50): {{p50_us:.1f}} μs\")\n",
    "print(f\"Latency (p95): {{p95_us:.1f}} μs\")\n",
    "\n",
    "agent.send_notif(\"target\", b\"done\")\n",
    "print(\"Initiator finished\")\n",
    "'''\n",
    "\n",
    "single_latency_target_script = '''#!/usr/bin/env python3\n",
    "# nixl_latency_target_single_rail.py - Run on spark-01\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/usr/local/ucx/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/ucx/lib:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1,enp1s0f0np0,lo\"\n",
    "os.environ[\"UCX_TLS\"] = \"rc_verbs,rc_mlx5,tcp,sockcm\"\n",
    "os.environ[\"UCX_MAX_RNDV_LANES\"] = \"1\"\n",
    "os.environ[\"UCX_MAX_EAGER_LANES\"] = \"1\"\n",
    "os.environ[\"UCX_RNDV_THRESH\"] = \"0\"\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from nixl._api import nixl_agent, nixl_agent_config\n",
    "\n",
    "config = nixl_agent_config(\n",
    "    enable_prog_thread=True,\n",
    "    enable_listen_thread=True,\n",
    "    listen_port=5558,\n",
    "    backends=[\"UCX\"]\n",
    ")\n",
    "\n",
    "agent = nixl_agent(\"target\", config)\n",
    "print(\"NIXL agent created (single-rail latency target)\")\n",
    "\n",
    "# Small CPU buffer (4 KB)\n",
    "tensor = torch.ones((1024,), dtype=torch.float32, device=\"cpu\")\n",
    "print(f\"Target tensor: {tensor.shape}, {tensor.numel() * 4} bytes (CPU)\")\n",
    "\n",
    "agent.register_memory(tensor)\n",
    "target_descs = agent.get_xfer_descs([tensor])\n",
    "desc_str = agent.get_serialized_descs(target_descs)\n",
    "print(f\"Descriptor ready ({len(desc_str)} bytes)\")\n",
    "\n",
    "print(\"Waiting for initiator...\")\n",
    "while not agent.check_remote_metadata(\"initiator\"):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "agent.send_notif(\"initiator\", desc_str)\n",
    "print(\"Sent descriptors to initiator\")\n",
    "\n",
    "# Wait for completion signal\n",
    "while True:\n",
    "    notifs = agent.get_new_notifs()\n",
    "    if \"initiator\" in notifs:\n",
    "        for notif in notifs[\"initiator\"]:\n",
    "            if b\"done\" in notif:\n",
    "                print(\"Latency test completed\")\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(\"Target finished\")\n",
    "'''\n",
    "\n",
    "single_latency_initiator_script = f'''#!/usr/bin/env python3\n",
    "# nixl_latency_initiator_single_rail.py - Run on spark-02\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/usr/local/ucx/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/ucx/lib:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1,enp1s0f0np0,lo\"\n",
    "os.environ[\"UCX_TLS\"] = \"rc_verbs,rc_mlx5,tcp,sockcm\"\n",
    "os.environ[\"UCX_MAX_RNDV_LANES\"] = \"1\"\n",
    "os.environ[\"UCX_MAX_EAGER_LANES\"] = \"1\"\n",
    "os.environ[\"UCX_RNDV_THRESH\"] = \"0\"\n",
    "\n",
    "import time\n",
    "import statistics\n",
    "import torch\n",
    "from nixl._api import nixl_agent, nixl_agent_config\n",
    "\n",
    "TARGET_IP = \"{REMOTE_IP}\"\n",
    "TARGET_PORT = 5558\n",
    "ITERATIONS = 1000\n",
    "\n",
    "config = nixl_agent_config(\n",
    "    enable_prog_thread=True,\n",
    "    enable_listen_thread=True,\n",
    "    listen_port=0,\n",
    "    backends=[\"UCX\"]\n",
    ")\n",
    "\n",
    "agent = nixl_agent(\"initiator\", config)\n",
    "print(\"NIXL agent created (single-rail latency initiator)\")\n",
    "\n",
    "# Small CPU buffer (4 KB)\n",
    "local_tensor = torch.zeros((1024,), dtype=torch.float32, device=\"cpu\")\n",
    "agent.register_memory(local_tensor)\n",
    "\n",
    "print(f\"Connecting to target at {{TARGET_IP}}:{{TARGET_PORT}}\")\n",
    "agent.fetch_remote_metadata(\"target\", TARGET_IP, TARGET_PORT)\n",
    "agent.send_local_metadata(TARGET_IP, TARGET_PORT)\n",
    "\n",
    "print(\"Waiting for descriptors...\")\n",
    "notifs = agent.get_new_notifs()\n",
    "while \"target\" not in notifs or len(notifs[\"target\"]) == 0:\n",
    "    time.sleep(0.1)\n",
    "    notifs = agent.get_new_notifs()\n",
    "\n",
    "remote_descs = agent.deserialize_descs(notifs[\"target\"][0])\n",
    "local_descs = agent.get_xfer_descs([local_tensor])\n",
    "print(\"Received remote descriptors\")\n",
    "\n",
    "latencies_us = []\n",
    "for _ in range(ITERATIONS):\n",
    "    start_ns = time.perf_counter_ns()\n",
    "    xfer_handle = agent.initialize_xfer(\"READ\", local_descs, remote_descs, \"target\", \"done\")\n",
    "    agent.transfer(xfer_handle)\n",
    "    while agent.check_xfer_state(xfer_handle) != \"DONE\":\n",
    "        time.sleep(0.0001)\n",
    "    elapsed_us = (time.perf_counter_ns() - start_ns) / 1000\n",
    "    latencies_us.append(elapsed_us)\n",
    "\n",
    "avg_us = sum(latencies_us) / len(latencies_us)\n",
    "p50_us = statistics.median(latencies_us)\n",
    "p95_us = statistics.quantiles(latencies_us, n=20)[18]  # ~95th percentile\n",
    "print(f\"Latency (avg): {{avg_us:.1f}} μs\")\n",
    "print(f\"Latency (p50): {{p50_us:.1f}} μs\")\n",
    "print(f\"Latency (p95): {{p95_us:.1f}} μs\")\n",
    "\n",
    "agent.send_notif(\"target\", b\"done\")\n",
    "print(\"Initiator finished\")\n",
    "'''\n",
    "\n",
    "print(\"=== Latency Target Script (Dual-Rail) ===\")\n",
    "print(\"Save to spark-01 as ~/nixl_latency_target.py and run:\")\n",
    "print(\"  .venv/bin/python3 ~/nixl_latency_target.py\")\n",
    "print()\n",
    "print(latency_target_script)\n",
    "print()\n",
    "print(\"=== Latency Initiator Script (Dual-Rail) ===\")\n",
    "print(\"Run on spark-02 AFTER target shows 'Waiting for initiator...':\")\n",
    "print(\"  .venv/bin/python3 ~/nixl_latency_initiator.py\")\n",
    "print()\n",
    "print(latency_initiator_script)\n",
    "print()\n",
    "print(\"=== Latency Target Script (Single-Rail) ===\")\n",
    "print(\"Save to spark-01 as ~/nixl_latency_target_single_rail.py and run:\")\n",
    "print(\"  .venv/bin/python3 ~/nixl_latency_target_single_rail.py\")\n",
    "print()\n",
    "print(single_latency_target_script)\n",
    "print()\n",
    "print(\"=== Latency Initiator Script (Single-Rail) ===\")\n",
    "print(\"Run on spark-02 AFTER target shows 'Waiting for initiator...':\")\n",
    "print(\"  .venv/bin/python3 ~/nixl_latency_initiator_single_rail.py\")\n",
    "print()\n",
    "print(single_latency_initiator_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a28a6",
   "metadata": {},
   "source": [
    "### 4.3.1 Dual-rail IP setup (second port)\n",
    "\n",
    "Before the dual-rail test, restore IPs on the second RoCE port on both nodes:\n",
    "\n",
    "- spark-01: add 192.168.100.12/24 to `enp1s0f1np1`\n",
    "- spark-02: add 192.168.100.13/24 to `enp1s0f1np1`\n",
    "\n",
    "After dual-rail testing, remove those secondary IPs before running single-rail tests to avoid UCX/GID confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540d0b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Performance Summary\n",
    "\n",
    "Compare bonding vs NIXL results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f501b2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Test Configuration                     Throughput         Latency\n",
      "======================================================================\n",
      "TCP Single Stream                       33.7 Gbps          100 μs\n",
      "TCP 4 Streams (bonded)                  93.0 Gbps          100 μs\n",
      "RDMA Single Link (ib_write_bw)          93.4 Gbps            2 μs\n",
      "NIXL Single Rail (CPU memory)           81.8 Gbps           17 μs\n",
      "NIXL Dual Rail (CPU memory)             93.4 Gbps           59 μs\n",
      "NIXL Single Rail (GPU memory)            3.5 Gbps           17 μs\n",
      "NIXL Dual Rail (GPU memory)              4.9 Gbps           59 μs\n",
      "======================================================================\n",
      "\n",
      "Key findings:\n",
      "- Raw RDMA (ib_write_bw): 93.4 Gbps (near 100G line rate)\n",
      "- TCP single stream:     33.7 Gbps (kernel overhead)\n",
      "- TCP 4 streams:         93.0 Gbps (bonded)\n",
      "- NIXL dual-rail latency (avg): 58.6 μs (p50 11.1 μs, p95 166.6 μs)\n",
      "- NIXL single-rail latency (avg): 17.4 μs (p50 16.2 μs, p95 20.8 μs)\n"
     ]
    }
   ],
   "source": [
    "# Performance comparison table\n",
    "## Updated from notebook outputs (Jan 2026)\n",
    "\n",
    "import math\n",
    "\n",
    "# Measured values from cell outputs\n",
    "rdma_single_link_gbps = 11678.83 * 8 / 1000  # ib_write_bw BW average (MB/sec)\n",
    "tcp_single_stream_gbps = 33.7                # iperf3 single stream output\n",
    "tcp_4_streams_gbps = 93.0                    # iperf3 -P 4 SUM output\n",
    "\n",
    "# NIXL values - using CPU device registration (update after running scripts)\n",
    "nixl_single_rail_gbps = 81.8                 # from NIXL single-rail run output\n",
    "nixl_dual_rail_gbps = 93.4                   # set after dual-rail run output\n",
    "\n",
    "# NIXL values - using GPU device registration (update after running scripts)\n",
    "nixl_single_rail_gpu_gbps = 3.5                 # from NIXL single-rail run output\n",
    "nixl_dual_rail_gpu_gbps = 4.9                   # set after dual-rail run output\n",
    "\n",
    "# NIXL latency values (CPU, 4 KB, 1000 iterations)\n",
    "nixl_latency_dual_avg_us = 58.6\n",
    "nixl_latency_dual_p50_us = 11.1\n",
    "nixl_latency_dual_p95_us = 166.6\n",
    "\n",
    "# Single-rail latency (CPU, 4 KB, 1000 iterations)\n",
    "nixl_latency_single_avg_us = 17.4\n",
    "nixl_latency_single_p50_us = 16.2\n",
    "nixl_latency_single_p95_us = 20.8\n",
    "\n",
    "comparison_data = {\n",
    "    \"TCP Single Stream\": {\"gbps\": tcp_single_stream_gbps, \"latency_us\": 100},\n",
    "    \"TCP 4 Streams (bonded)\": {\"gbps\": tcp_4_streams_gbps, \"latency_us\": 100},\n",
    "    \"RDMA Single Link (ib_write_bw)\": {\"gbps\": rdma_single_link_gbps, \"latency_us\": 2},\n",
    "    \"NIXL Single Rail (CPU memory)\": {\"gbps\": nixl_single_rail_gbps, \"latency_us\": nixl_latency_single_avg_us},\n",
    "    \"NIXL Dual Rail (CPU memory)\": {\"gbps\": nixl_dual_rail_gbps, \"latency_us\": nixl_latency_dual_avg_us},\n",
    "    \"NIXL Single Rail (GPU memory)\": {\"gbps\": nixl_single_rail_gpu_gbps, \"latency_us\": nixl_latency_single_avg_us},\n",
    "    \"NIXL Dual Rail (GPU memory)\": {\"gbps\": nixl_dual_rail_gpu_gbps, \"latency_us\": nixl_latency_dual_avg_us},\n",
    "}\n",
    "\n",
    "def format_latency(val):\n",
    "    if isinstance(val, (int, float)) and not math.isnan(val):\n",
    "        return f\"{val:>12.0f} μs\"\n",
    "    return \"        N/A\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Test Configuration':<32} {'Throughput':>16} {'Latency':>15}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for test, data in comparison_data.items():\n",
    "    gbps = data[\"gbps\"]\n",
    "    latency = data[\"latency_us\"]\n",
    "    gbps_str = f\"{gbps:>6.1f} Gbps\" if isinstance(gbps, (int, float)) else \"   N/A  \"\n",
    "    print(f\"{test:<32} {gbps_str:>16} {format_latency(latency)}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Key findings:\")\n",
    "print(f\"- Raw RDMA (ib_write_bw): {rdma_single_link_gbps:.1f} Gbps (near 100G line rate)\")\n",
    "print(f\"- TCP single stream:     {tcp_single_stream_gbps:.1f} Gbps (kernel overhead)\")\n",
    "print(f\"- TCP 4 streams:         {tcp_4_streams_gbps:.1f} Gbps (bonded)\")\n",
    "print(f\"- NIXL dual-rail latency (avg): {nixl_latency_dual_avg_us:.1f} μs (p50 {nixl_latency_dual_p50_us:.1f} μs, p95 {nixl_latency_dual_p95_us:.1f} μs)\")\n",
    "print(f\"- NIXL single-rail latency (avg): {nixl_latency_single_avg_us:.1f} μs (p50 {nixl_latency_single_p50_us:.1f} μs, p95 {nixl_latency_single_p95_us:.1f} μs)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec6471",
   "metadata": {},
   "source": [
    "### What the NIXL results indicate\n",
    "\n",
    "- **Single-rail NIXL (~81.8 Gbps)**: RDMA is working end-to-end, but throughput is lower than raw `ib_write_bw` because of NIXL metadata handling and Python overhead.\n",
    "- **Dual-rail NIXL (~93.4 Gbps)**: The second rail contributes, but scaling is limited by host-staging on DGX Spark (no GPUDirect RDMA) and CPU/memory overhead.\n",
    "- **Takeaway**: NIXL provides much higher throughput than TCP single streams and approaches raw RDMA on a single link, but dual-rail gains are constrained on this platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6288e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import math\n",
    "\n",
    "    tests = list(comparison_data.keys())\n",
    "    throughputs = [d[\"gbps\"] for d in comparison_data.values()]\n",
    "    latencies = [d[\"latency_us\"] for d in comparison_data.values()]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Throughput comparison\n",
    "    colors = ['#ff6b6b' if 'TCP' in t else '#4ecdc4' for t in tests]\n",
    "    bars1 = ax1.barh(tests, throughputs, color=colors)\n",
    "    ax1.set_xlabel('Throughput (Gbps)')\n",
    "    ax1.set_title('Throughput: Bonding vs NIXL')\n",
    "    ax1.axvline(x=100, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "    for bar, val in zip(bars1, throughputs):\n",
    "        ax1.text(val + 2, bar.get_y() + bar.get_height()/2, f'{val:.0f}',\n",
    "                va='center', fontsize=10)\n",
    "\n",
    "    # Latency comparison (log scale)\n",
    "    if any(isinstance(v, (int, float)) and math.isnan(v) for v in latencies):\n",
    "        ax2.text(0.5, 0.5, 'Latency chart skipped\\n(missing values)',\n",
    "                 transform=ax2.transAxes, ha='center', va='center', fontsize=10)\n",
    "        ax2.set_axis_off()\n",
    "    else:\n",
    "        bars2 = ax2.barh(tests, latencies, color=colors)\n",
    "        ax2.set_xlabel('Latency (μs) - Log Scale')\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_title('Latency: Bonding vs NIXL')\n",
    "\n",
    "        for bar, val in zip(bars2, latencies):\n",
    "            ax2.text(val * 1.2, bar.get_y() + bar.get_height()/2, f'{val:.0f}',\n",
    "                    va='center', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('bonding_vs_nixl_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\nChart saved to bonding_vs_nixl_comparison.png\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"matplotlib not installed. Install with: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b970469",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Key Findings\n",
    "\n",
    "### Why Bonding Underperforms\n",
    "\n",
    "```\n",
    "TCP/IP Path (Bonding):\n",
    "  Application → Socket API → Kernel TCP/IP Stack → Driver → NIC\n",
    "  \n",
    "RDMA Path (NIXL):\n",
    "  Application → Verbs API → NIC (direct memory access)\n",
    "```\n",
    "\n",
    "The kernel TCP/IP stack introduces:\n",
    "- **CPU overhead**: Context switches, buffer copies, interrupt handling\n",
    "- **Latency**: 50-200 μs vs 1-2 μs for RDMA\n",
    "- **Throughput ceiling**: ~35 Gbps per flow regardless of link speed\n",
    "\n",
    "### When to Use Each Approach\n",
    "\n",
    "| Workload | Recommended |\n",
    "|----------|-------------|\n",
    "| KV-cache transfer | NIXL |\n",
    "| Tensor shard movement | NIXL |\n",
    "| Disaggregated inference | NIXL |\n",
    "| Collective operations | NCCL (see [first tutorial](01_InfiniBand_Tutorial.ipynb)) |\n",
    "| SSH/management | Bonding |\n",
    "| NFS storage | Bonding |\n",
    "\n",
    "### Coexistence\n",
    "\n",
    "Bonding and NIXL can coexist:\n",
    "- Bond for IP traffic (uses kernel stack)\n",
    "- NIXL for RDMA (bypasses kernel entirely)\n",
    "\n",
    "RDMA verbs access `mlx5_0`/`mlx5_1` directly; traffic does not traverse `bond0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f2ce1f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Troubleshooting\n",
    "\n",
    "Common issues and solutions when working with bonding and NIXL.\n",
    "\n",
    "### UCX Version Mismatch Between Nodes\n",
    "\n",
    "**Symptom:** NIXL connection fails with `NIXL_ERR_NOT_FOUND`\n",
    "\n",
    "**Cause:** UCX requires matching versions on both endpoints. A node with UCX 1.16.0 cannot connect to a node with UCX 1.21.0.\n",
    "\n",
    "**Diagnosis:**\n",
    "```bash\n",
    "# Check UCX version on each node\n",
    "ucx_info -v\n",
    "# Look for the version line, e.g., \"# UCX version=1.16.0\"\n",
    "```\n",
    "\n",
    "**Fix:** Build matching UCX versions on both nodes from the same git tag.\n",
    "\n",
    "### P2P Interface IP Conflict\n",
    "\n",
    "**Symptom:** UCX connects but uses wrong interface, or connection times out despite correct IP addresses.\n",
    "\n",
    "**Cause:** DGX Spark has a P2P interface (`enP2p1s0f0np0`) that may have an IP address in the same subnet as the RoCE interfaces. UCX picks the first matching interface.\n",
    "\n",
    "**Diagnosis:**\n",
    "```bash\n",
    "# Check all interfaces for IPs in your subnet\n",
    "ip addr | grep \"192.168.100\"\n",
    "```\n",
    "\n",
    "**Fix:**\n",
    "```bash\n",
    "# Remove the conflicting IP\n",
    "sudo ip addr del 192.168.100.15/24 dev enP2p1s0f0np0\n",
    "\n",
    "# Or restrict UCX to the correct interface (set before importing NIXL)\n",
    "export UCX_NET_DEVICES=rocep1s0f0:1\n",
    "```\n",
    "\n",
    "### Interface Down\n",
    "\n",
    "**Symptom:** `ibdev2netdev` shows interface as `(Down)`\n",
    "\n",
    "**Diagnosis:**\n",
    "```bash\n",
    "ibdev2netdev\n",
    "# Expected: rocep1s0f0 port 1 ==> enp1s0f0np0 (Up)\n",
    "# Problem:  rocep1s0f1 port 1 ==> enp1s0f1np1 (Down)\n",
    "```\n",
    "\n",
    "**Fix:**\n",
    "```bash\n",
    "sudo ip link set enp1s0f1np1 up\n",
    "```\n",
    "\n",
    "### NIXL GPU Registration Fails\n",
    "\n",
    "**Error:** `ibv_reg_mr failed: Bad address` or `NIXL_ERR_BACKEND`\n",
    "\n",
    "**Cause:** DGX Spark does not support GPUDirect RDMA. The `nvidia-peermem` module fails to load due to the unified memory architecture.\n",
    "\n",
    "**Diagnosis:**\n",
    "```bash\n",
    "# Check if nvidia-peermem is loaded\n",
    "lsmod | grep nvidia_peermem\n",
    "\n",
    "# Try loading it\n",
    "sudo modprobe nvidia-peermem\n",
    "# May fail with: modprobe: ERROR: could not insert 'nvidia_peermem': Invalid argument\n",
    "```\n",
    "\n",
    "**Workaround:** Use CPU pinned memory fallback:\n",
    "```python\n",
    "try:\n",
    "    tensor = torch.ones((4096, 4096), dtype=torch.float32, device=\"cuda:0\")\n",
    "    agent.register_memory(tensor)\n",
    "except Exception as e:\n",
    "    print(f\"GPU registration failed: {e}\")\n",
    "    tensor = torch.ones((4096, 4096), dtype=torch.float32, device=\"cpu\")\n",
    "    tensor = tensor.pin_memory()\n",
    "    agent.register_memory(tensor)\n",
    "```\n",
    "\n",
    "### TCP Throughput Near Zero\n",
    "\n",
    "**Symptom:** `iperf3` shows very low throughput (< 1 Gbps) despite successful connection.\n",
    "\n",
    "**Cause:** MTU mismatch causes TCP congestion control to throttle. Default MTU (1500) is insufficient for RoCE links.\n",
    "\n",
    "**Diagnosis:**\n",
    "```bash\n",
    "# Check MTU on both endpoints\n",
    "cat /sys/class/net/bond0/mtu  # Should be 9000\n",
    "cat /sys/class/net/enp1s0f0np0/mtu\n",
    "\n",
    "# Look for Cwnd stuck at ~1.4 KB in iperf3 output\n",
    "```\n",
    "\n",
    "**Fix:**\n",
    "```bash\n",
    "sudo ip link set enp1s0f0np0 mtu 9000\n",
    "sudo ip link set enp1s0f1np1 mtu 9000\n",
    "sudo ip link set bond0 mtu 9000  # If bond exists\n",
    "```\n",
    "\n",
    "### NIXL Does Not Use Both Rails\n",
    "\n",
    "**Symptom:** NIXL throughput same on single-rail and dual-rail configurations.\n",
    "\n",
    "**Diagnosis:**\n",
    "```bash\n",
    "# Check UCX device detection\n",
    "ucx_info -d | grep mlx5\n",
    "```\n",
    "\n",
    "**Fix:**\n",
    "```bash\n",
    "# Explicitly set devices (set before importing NIXL)\n",
    "export UCX_NET_DEVICES=mlx5_0:1,mlx5_1:1\n",
    "export UCX_TLS=rc_verbs,rc_mlx5\n",
    "```\n",
    "\n",
    "### Bond Not Forming\n",
    "\n",
    "**Symptom:** `cat /proc/net/bonding/bond0` shows error or empty output.\n",
    "\n",
    "**Diagnosis:**\n",
    "```bash\n",
    "# Check if bonding module is loaded\n",
    "lsmod | grep bonding\n",
    "\n",
    "# Check for errors\n",
    "dmesg | grep -i bond\n",
    "```\n",
    "\n",
    "**Fix:**\n",
    "```bash\n",
    "sudo modprobe bonding\n",
    "\n",
    "# Verify bond status\n",
    "cat /proc/net/bonding/bond0\n",
    "```\n",
    "\n",
    "### Transfer Falls Back to TCP\n",
    "\n",
    "**Symptom:** NIXL debug output shows socket-based transport instead of RDMA.\n",
    "\n",
    "**Checks:**\n",
    "1. Verify RDMA devices are active: `ibstat`\n",
    "2. Check UCX installation includes RDMA: `ucx_info -v | grep verbs`\n",
    "3. Ensure `libibverbs` is installed: `dpkg -l | grep libibverbs`\n",
    "4. Verify GIDs point to physical interfaces: `show_gids | grep rocep`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277acb71",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands to remove bond (run manually if needed)\n",
    "print(\"To remove the bond interface:\")\n",
    "print(\"\"\"\n",
    "sudo ip link set bond0 down\n",
    "sudo ip link set enp1s0f0np0 nomaster\n",
    "sudo ip link set enp1s0f1np1 nomaster\n",
    "sudo ip link delete bond0\n",
    "\n",
    "# Restore individual interface IPs if needed\n",
    "sudo ip addr add 192.168.100.10/24 dev enp1s0f0np0\n",
    "sudo ip addr add 192.168.200.10/24 dev enp1s0f1np1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026df3b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- [RoCE Link Aggregation Tutorial (Markdown)](02_Multi_Rail_Tutorial.md)\n",
    "- [NCCL and RDMA Benchmarks (First Tutorial)](01_InfiniBand_Tutorial.ipynb)\n",
    "- [NIXL GitHub Repository](https://github.com/ai-dynamo/nixl)\n",
    "- [Linux Kernel Bonding Documentation](https://www.kernel.org/doc/Documentation/networking/bonding.txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
