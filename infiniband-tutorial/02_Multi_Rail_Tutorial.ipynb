{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decc65fe",
   "metadata": {},
   "source": [
    "# RoCE Link Aggregation: Bonding vs NIXL\n",
    "\n",
    "This notebook compares two approaches to using dual 100G RoCE links on DGX Spark:\n",
    "\n",
    "| Approach | Traffic Type | Expected Throughput | Latency |\n",
    "|----------|--------------|---------------------|----------|\n",
    "| Linux Bonding | TCP/IP | ~60-70 Gbps | 50-200 μs |\n",
    "| NIXL | Point-to-point RDMA | ~176 Gbps | 1-2 μs |\n",
    "\n",
    "**Goal**: Demonstrate why NIXL outperforms bonding for point-to-point inference data movement.\n",
    "\n",
    "For collective operations (all-reduce, all-gather), see the [first tutorial](01_InfiniBand_Tutorial.ipynb) which covers NCCL.\n",
    "\n",
    "**Prerequisites**:\n",
    "- Two DGX Spark systems connected via both RoCE ports\n",
    "- IP addresses configured on RoCE interfaces\n",
    "- `perftest` and `iperf3` installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d65bb",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15be26cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded\n",
      "Local IP: 192.168.100.11\n",
      "Remote IP: 192.168.100.10\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Configuration - Update these for your environment\n",
    "LOCAL_IP = \"192.168.100.11\"    # This node's RoCE IP\n",
    "REMOTE_IP = \"192.168.100.10\"   # Remote node's RoCE IP\n",
    "INTERFACE_1 = \"enp1s0f0np0\"    # First RoCE interface\n",
    "INTERFACE_2 = \"enp1s0f1np1\"    # Second RoCE interface\n",
    "\n",
    "def run_cmd(cmd, timeout=60):\n",
    "    \"\"\"Run a shell command and return output.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd, shell=True, capture_output=True, text=True, timeout=timeout\n",
    "        )\n",
    "        return result.stdout + result.stderr\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return \"Command timed out\"\n",
    "\n",
    "def parse_bandwidth(output, pattern):\n",
    "    \"\"\"Extract bandwidth value from command output.\"\"\"\n",
    "    match = re.search(pattern, output)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "print(\"Configuration loaded\")\n",
    "print(f\"Local IP: {LOCAL_IP}\")\n",
    "print(f\"Remote IP: {REMOTE_IP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a9463",
   "metadata": {},
   "source": [
    "## Part 1: Verify Network Interfaces\n",
    "\n",
    "Check that both RoCE interfaces are available and operational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1b4df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Network Interfaces ===\n",
      "3: enp1s0f0np0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9000 qdisc mq state UP mode DEFAULT group default qlen 1000\n",
      "    link/ether 30:c5:99:3e:6a:13 brd ff:ff:ff:ff:ff:ff\n",
      "\n",
      "4: enp1s0f1np1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9000 qdisc mq state UP mode DEFAULT group default qlen 1000\n",
      "    link/ether 30:c5:99:3e:6a:14 brd ff:ff:ff:ff:ff:ff\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check interface status\n",
    "print(\"=== Network Interfaces ===\")\n",
    "print(run_cmd(f\"ip link show {INTERFACE_1}\"))\n",
    "print(run_cmd(f\"ip link show {INTERFACE_2}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79e5e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RDMA Devices ===\n",
      "hca_id:\trocep1s0f0\n",
      "\ttransport:\t\t\tInfiniBand (0)\n",
      "\tfw_ver:\t\t\t\t28.45.4028\n",
      "\tnode_guid:\t\t\t30c5:9903:003e:6a13\n",
      "\tsys_image_guid:\t\t\t30c5:9903:003e:6a13\n",
      "\tvendor_id:\t\t\t0x02c9\n",
      "\tvendor_part_id:\t\t\t4129\n",
      "\thw_ver:\t\t\t\t0x0\n",
      "\tboard_id:\t\t\tNVD0000000087\n",
      "\tphys_port_cnt:\t\t\t1\n",
      "\t\tport:\t1\n",
      "\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n",
      "\t\t\tmax_mtu:\t\t4096 (5)\n",
      "\t\t\tactive_mtu:\t\t4096 (5)\n",
      "\t\t\tsm_lid:\t\t\t0\n",
      "\t\t\tport_lid:\t\t0\n",
      "\t\t\tport_lmc:\t\t0x00\n",
      "\t\t\tlink_layer:\t\tEthernet\n",
      "\n",
      "hca_id:\trocep1s0f1\n",
      "\ttransport:\t\t\tInfiniBand (0)\n",
      "\tfw_ver:\t\t\t\t28.45.4028\n",
      "\tnode_guid:\t\t\t30c5:9903:003e:6a14\n",
      "\tsys_image_guid:\t\t\t30c5:9903:003e:6a13\n",
      "\tvendor_id:\t\t\t0x02c9\n",
      "\tvendor_part_id:\t\t\t4129\n",
      "\thw_ver:\t\t\t\t0x0\n",
      "\tboard_id:\t\t\tNVD0000000087\n",
      "\tphys_port_cnt:\t\t\t1\n",
      "\t\tport:\t1\n",
      "\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n",
      "\t\t\tmax_mtu:\t\t4096 (5)\n",
      "\t\t\tactive_mtu:\t\t4096 (5)\n",
      "\t\t\tsm_lid:\t\t\t0\n",
      "\t\t\tport_lid:\t\t0\n",
      "\t\t\tport_lmc:\t\t0x00\n",
      "\t\t\tlink_layer:\t\tEthernet\n",
      "\n",
      "hca_id:\troceP2p1s0f0\n",
      "\ttransport:\t\t\tInfiniBand (0)\n",
      "\tfw_ver:\t\t\t\t28.45.4028\n",
      "\tnode_guid:\t\t\t30c5:9903:003e:6a17\n",
      "\tsys_image_guid:\t\t\t30c5:9903:003e:6a13\n",
      "\tvendor_id:\t\t\t0x02c9\n",
      "\tvendor_part_id:\t\t\t4129\n",
      "\thw_ver:\t\t\t\t0x0\n",
      "\tboard_id:\t\t\tNVD0000000087\n",
      "\tphys_port_cnt:\t\t\t1\n",
      "\t\tport:\t1\n",
      "\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n",
      "\t\t\tmax_mtu:\t\t4096 (5)\n",
      "\t\t\tactive_mtu:\t\t1024 (3)\n",
      "\t\t\tsm_lid:\t\t\t0\n",
      "\t\t\tport_lid:\t\t0\n",
      "\t\t\tport_lmc:\t\t0x00\n",
      "\t\t\tlink_layer:\t\tEthernet\n",
      "\n",
      "hca_id:\troceP2p1s0f1\n",
      "\ttransport:\t\t\tInfiniBand (0)\n",
      "\tfw_ver:\t\t\t\t28.45.4028\n",
      "\tnode_guid:\t\t\t30c5:9903:003e:6a18\n",
      "\tsys_image_guid:\t\t\t30c5:9903:003e:6a13\n",
      "\tvendor_id:\t\t\t0x02c9\n",
      "\tvendor_part_id:\t\t\t4129\n",
      "\thw_ver:\t\t\t\t0x0\n",
      "\tboard_id:\t\t\tNVD0000000087\n",
      "\tphys_port_cnt:\t\t\t1\n",
      "\t\tport:\t1\n",
      "\t\t\tstate:\t\t\tPORT_ACTIVE (4)\n",
      "\t\t\tmax_mtu:\t\t4096 (5)\n",
      "\t\t\tactive_mtu:\t\t1024 (3)\n",
      "\t\t\tsm_lid:\t\t\t0\n",
      "\t\t\tport_lid:\t\t0\n",
      "\t\t\tport_lmc:\t\t0x00\n",
      "\t\t\tlink_layer:\t\tEthernet\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check RDMA devices\n",
    "print(\"=== RDMA Devices ===\")\n",
    "print(run_cmd(\"ibv_devinfo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "061c3dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Connectivity Test ===\n",
      "PING 192.168.100.10 (192.168.100.10) 56(84) bytes of data.\n",
      "From 192.168.100.11 icmp_seq=1 Destination Host Unreachable\n",
      "From 192.168.100.11 icmp_seq=2 Destination Host Unreachable\n",
      "From 192.168.100.11 icmp_seq=3 Destination Host Unreachable\n",
      "\n",
      "--- 192.168.100.10 ping statistics ---\n",
      "3 packets transmitted, 0 received, +3 errors, 100% packet loss, time 2059ms\n",
      "pipe 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify connectivity to remote node\n",
    "print(\"=== Connectivity Test ===\")\n",
    "print(run_cmd(f\"ping -c 3 {REMOTE_IP}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ec304",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Baseline RDMA Performance (Single Link)\n",
    "\n",
    "Measure raw RDMA bandwidth on a single 100G link using `ib_write_bw`.\n",
    "\n",
    "### RoCE GID Index Selection\n",
    "\n",
    "RoCE requires specifying the correct GID (Global Identifier) index. GID index 0 is typically link-local (`fe80::`) and does not work for routed connections.\n",
    "\n",
    "Check available GIDs:\n",
    "```bash\n",
    "show_gids\n",
    "```\n",
    "\n",
    "For RoCEv2 with IPv4, use index 3 (the entry showing your IPv4 address with `v2`):\n",
    "| Index | Type | Use |\n",
    "|-------|------|-----|\n",
    "| 0-1 | fe80:: (link-local) | Does not work for RoCE |\n",
    "| 2 | IPv4-mapped, RoCEv1 | Legacy, may not work |\n",
    "| 3 | IPv4-mapped, RoCEv2 | **Use this** |\n",
    "\n",
    "**Run on remote node first:**\n",
    "```bash\n",
    "ib_write_bw -d rocep1s0f0 -x 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c210fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RDMA Bandwidth (Single Link - rocep1s0f0) ===\n",
      "NOTE: Start server on remote node: ib_write_bw -d rocep1s0f0 -x 3\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "                    RDMA_Write BW Test\n",
      " Dual-port       : OFF\t\tDevice         : rocep1s0f0\n",
      " Number of qps   : 1\t\tTransport type : IB\n",
      " Connection type : RC\t\tUsing SRQ      : OFF\n",
      " PCIe relax order: ON\n",
      " ibv_wr* API     : ON\n",
      " TX depth        : 128\n",
      " CQ Moderation   : 1\n",
      " Mtu             : 4096[B]\n",
      " Link type       : Ethernet\n",
      " GID index       : 3\n",
      " Max inline data : 0[B]\n",
      " rdma_cm QPs\t : OFF\n",
      " Data ex. method : Ethernet\n",
      "---------------------------------------------------------------------------------------\n",
      " local address: LID 0000 QPN 0x02e4 PSN 0x58e43e RKey 0x182f00 VAddr 0x00e58409ead000\n",
      " GID: 00:00:00:00:00:00:00:00:00:00:255:255:192:168:100:11\n",
      " remote address: LID 0000 QPN 0x02ad PSN 0x83aed RKey 0x183700 VAddr 0x00fa5cbf676000\n",
      " GID: 00:00:00:00:00:00:00:00:00:00:255:255:192:168:100:10\n",
      "---------------------------------------------------------------------------------------\n",
      " #bytes     #iterations    BW peak[MB/sec]    BW average[MB/sec]   MsgRate[Mpps]\n",
      " 65536      5000             11680.07            11678.83\t\t   0.186861\n",
      "---------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Single-link RDMA bandwidth test\n",
    "# Requires server running on remote: ib_write_bw -d rocep1s0f0 -x 3\n",
    "\n",
    "# GID index 3 = RoCEv2 with IPv4 address (required for RoCE connections)\n",
    "GID_INDEX = 3\n",
    "\n",
    "print(\"=== RDMA Bandwidth (Single Link - rocep1s0f0) ===\")\n",
    "print(f\"NOTE: Start server on remote node: ib_write_bw -d rocep1s0f0 -x {GID_INDEX}\")\n",
    "print()\n",
    "\n",
    "output = run_cmd(f\"ib_write_bw -d rocep1s0f0 -x {GID_INDEX} {REMOTE_IP}\")\n",
    "print(output)\n",
    "\n",
    "# Parse result\n",
    "bw = parse_bandwidth(output, r\"(\\d+\\.?\\d*)\\s+MB/sec\")\n",
    "if bw:\n",
    "    print(f\"\\n>>> Single Link RDMA: {bw:.0f} MB/s ({bw * 8 / 1000:.1f} Gbps)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6910a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Linux Bonding Performance (TCP/IP)\n",
    "\n",
    "Bonding aggregates TCP traffic but **does not work with RDMA**.\n",
    "\n",
    "### Critical Limitation: RDMA and Bonding Are Mutually Exclusive\n",
    "\n",
    "When interfaces are enslaved to a bond:\n",
    "- **TCP/IP works** through the bond interface (kernel stack)\n",
    "- **RDMA fails** because verbs bypass the kernel and cannot traverse bond0\n",
    "\n",
    "The `show_gids` output shows this: when bonded, GID entries associate with `bond0` instead of the physical interface, breaking RDMA connectivity.\n",
    "\n",
    "**Testing sequence for this tutorial:**\n",
    "1. Test RDMA first (Part 2) with unbonded interfaces\n",
    "2. Create bond and test TCP (Part 3)\n",
    "3. Remove bond before testing NIXL (Part 4)\n",
    "\n",
    "### Bond Mode Selection\n",
    "\n",
    "Linux bonding supports several modes. For direct-connect (no switch), only modes 0 and 2 are practical:\n",
    "\n",
    "| Mode | Name | Hash Basis | Best For |\n",
    "|------|------|------------|----------|\n",
    "| 0 | balance-rr | Per-packet round-robin | Maximum single-flow throughput (causes reordering) |\n",
    "| 1 | active-backup | None (failover only) | High availability, not performance |\n",
    "| 2 | balance-xor | IP + port hash | Multiple flows, preserves packet order |\n",
    "| 4 | 802.3ad | LACP negotiation | Requires switch support |\n",
    "\n",
    "**Why balance-xor (mode 2) for this tutorial:**\n",
    "- Each TCP connection hashes to one interface consistently\n",
    "- No out-of-order packets (unlike balance-rr)\n",
    "- Multiple parallel streams distribute across both links\n",
    "- Single streams limited to one link (~35 Gbps) but without reordering overhead\n",
    "\n",
    "**Trade-off:** balance-rr can achieve higher single-stream throughput by spreading packets across links, but causes TCP reordering which triggers congestion control. balance-xor sacrifices single-stream aggregation for predictable behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bdcf61",
   "metadata": {},
   "source": [
    "### 3.0 Configure Jumbo Frames (MTU 9000)\n",
    "\n",
    "RoCE links require jumbo frames for optimal TCP performance. The default MTU of 1500 bytes causes excessive packet fragmentation and triggers TCP congestion control, resulting in near-zero throughput.\n",
    "\n",
    "**Symptoms of MTU mismatch:**\n",
    "- Cwnd (congestion window) stuck at ~1.4 KB\n",
    "- High retransmit counts\n",
    "- Near-zero throughput despite successful connection\n",
    "\n",
    "**Set MTU on both nodes:**\n",
    "```bash\n",
    "# On spark-01 (192.168.100.10)\n",
    "sudo ip link set enp1s0f0np0 mtu 9000\n",
    "sudo ip link set enp1s0f1np1 mtu 9000\n",
    "\n",
    "# On spark-02 (192.168.100.11)\n",
    "sudo ip link set enp1s0f0np0 mtu 9000\n",
    "sudo ip link set enp1s0f1np1 mtu 9000\n",
    "sudo ip link set bond0 mtu 9000  # Only if bond exists\n",
    "```\n",
    "\n",
    "**Verify on both nodes:**\n",
    "```bash\n",
    "cat /sys/class/net/enp1s0f0np0/mtu  # Should show 9000\n",
    "cat /sys/class/net/enp1s0f1np1/mtu  # Should show 9000\n",
    "```\n",
    "\n",
    "Both endpoints must have matching MTU. A mismatch causes fragmentation and triggers TCP congestion control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4918fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bond interface exists on THIS NODE (spark-02):\n",
      "Ethernet Channel Bonding Driver: v6.14.0-1015-nvidia\n",
      "\n",
      "Bonding Mode: load balancing (xor)\n",
      "Transmit Hash Policy: layer3+4 (1)\n",
      "MII Status: up\n",
      "MII Polling Interval (ms): 100\n",
      "Up Delay (ms): 0\n",
      "Down Delay (ms): 0\n",
      "Peer Notification Delay (ms): 0\n",
      "\n",
      "Slave Interface: enp1s0f0np0\n",
      "MII Status: up\n",
      "Speed: 100000 Mbps\n",
      "Duplex: full\n",
      "Link Failure Count: 0\n",
      "Permanent HW addr: 30:c5:99:3e:6a:13\n",
      "Slave queue ID: 0\n",
      "\n",
      "Slave Interface: enp1s0f1np1\n",
      "MII Status: up\n",
      "Speed: 100000 Mbps\n",
      "Duplex: full\n",
      "Link Failure Count: 0\n",
      "Permanent HW addr: 30:c5:99:3e:6a:14\n",
      "Slave queue ID: 0\n",
      "\n",
      "\n",
      "======================================================================\n",
      "⚠️  IMPORTANT: Also verify bond on spark-01 (192.168.100.10)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Bond setup commands for BOTH nodes:\n",
      "======================================================================\n",
      "\n",
      "--- ON SPARK-01 (192.168.100.10): ---\n",
      "\n",
      "sudo modprobe bonding\n",
      "sudo ip link add bond0 type bond mode balance-xor\n",
      "sudo ip link set bond0 type bond miimon 100\n",
      "sudo ip link set bond0 type bond xmit_hash_policy layer3+4\n",
      "\n",
      "sudo ip link set enp1s0f0np0 down\n",
      "sudo ip link set enp1s0f0np0 master bond0\n",
      "sudo ip link set enp1s0f0np0 up\n",
      "\n",
      "sudo ip link set enp1s0f1np1 down\n",
      "sudo ip link set enp1s0f1np1 master bond0\n",
      "sudo ip link set enp1s0f1np1 up\n",
      "\n",
      "sudo ip addr add 192.168.100.10/24 dev bond0\n",
      "sudo ip link set bond0 up\n",
      "\n",
      "--- ON SPARK-02 (192.168.100.11) - THIS NODE: ---\n",
      "\n",
      "sudo modprobe bonding\n",
      "sudo ip link add bond0 type bond mode balance-xor\n",
      "sudo ip link set bond0 type bond miimon 100\n",
      "sudo ip link set bond0 type bond xmit_hash_policy layer3+4\n",
      "\n",
      "sudo ip link set enp1s0f0np0 down\n",
      "sudo ip link set enp1s0f0np0 master bond0\n",
      "sudo ip link set enp1s0f0np0 up\n",
      "\n",
      "sudo ip link set enp1s0f1np1 down\n",
      "sudo ip link set enp1s0f1np1 master bond0\n",
      "sudo ip link set enp1s0f1np1 up\n",
      "\n",
      "sudo ip addr add 192.168.100.11/24 dev bond0\n",
      "sudo ip link set bond0 up\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if bond already exists on this node\n",
    "bond_status = run_cmd(\"cat /proc/net/bonding/bond0 2>/dev/null\")\n",
    "\n",
    "if \"Bonding Mode\" in bond_status:\n",
    "    print(\"Bond interface exists on THIS NODE (spark-02):\")\n",
    "    print(bond_status)\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"⚠️  IMPORTANT: Also verify bond on spark-01 (192.168.100.10)\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"No bond interface found on THIS NODE.\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Bond setup commands for BOTH nodes:\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"--- ON SPARK-01 (192.168.100.10): ---\")\n",
    "print(f\"\"\"\n",
    "sudo modprobe bonding\n",
    "sudo ip link add bond0 type bond mode balance-xor\n",
    "sudo ip link set bond0 type bond miimon 100\n",
    "sudo ip link set bond0 type bond xmit_hash_policy layer3+4\n",
    "\n",
    "sudo ip link set {INTERFACE_1} down\n",
    "sudo ip link set {INTERFACE_1} master bond0\n",
    "sudo ip link set {INTERFACE_1} up\n",
    "\n",
    "sudo ip link set {INTERFACE_2} down\n",
    "sudo ip link set {INTERFACE_2} master bond0\n",
    "sudo ip link set {INTERFACE_2} up\n",
    "\n",
    "sudo ip addr add 192.168.100.10/24 dev bond0\n",
    "sudo ip link set bond0 up\n",
    "\"\"\")\n",
    "print(\"--- ON SPARK-02 (192.168.100.11) - THIS NODE: ---\")\n",
    "print(f\"\"\"\n",
    "sudo modprobe bonding\n",
    "sudo ip link add bond0 type bond mode balance-xor\n",
    "sudo ip link set bond0 type bond miimon 100\n",
    "sudo ip link set bond0 type bond xmit_hash_policy layer3+4\n",
    "\n",
    "sudo ip link set {INTERFACE_1} down\n",
    "sudo ip link set {INTERFACE_1} master bond0\n",
    "sudo ip link set {INTERFACE_1} up\n",
    "\n",
    "sudo ip link set {INTERFACE_2} down\n",
    "sudo ip link set {INTERFACE_2} master bond0\n",
    "sudo ip link set {INTERFACE_2} up\n",
    "\n",
    "sudo ip addr add {LOCAL_IP}/24 dev bond0\n",
    "sudo ip link set bond0 up\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17be587",
   "metadata": {},
   "source": [
    "### 3.2 Test Bonded TCP Performance\n",
    "\n",
    "**Before running iperf3, verify connectivity:**\n",
    "- Ensure bond0 is up on spark-01 with IP 192.168.100.10\n",
    "- Check: `ip addr show bond0` on spark-01\n",
    "- Verify ping works from current node to 192.168.100.10\n",
    "\n",
    "**Run on remote node (spark-01):**\n",
    "```bash\n",
    "iperf3 -s -B 192.168.100.10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "030f509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TCP Bandwidth (Single Stream) ===\n",
      "NOTE: Start server on remote: iperf3 -s -B 192.168.100.10\n",
      "\n",
      "Connecting to host 192.168.100.10, port 5201\n",
      "[  5] local 192.168.100.11 port 58550 connected to 192.168.100.10 port 5201\n",
      "[ ID] Interval           Transfer     Bitrate         Retr  Cwnd\n",
      "[  5]   0.00-1.00   sec  4.82 GBytes  41.3 Gbits/sec  1652    819 KBytes       \n",
      "[  5]   1.00-2.00   sec  3.08 GBytes  26.5 Gbits/sec  406    693 KBytes       \n",
      "[  5]   2.00-3.00   sec  5.03 GBytes  43.2 Gbits/sec  1919    874 KBytes       \n",
      "[  5]   3.00-4.00   sec  4.72 GBytes  40.5 Gbits/sec  503    817 KBytes       \n",
      "[  5]   4.00-5.00   sec  3.51 GBytes  30.2 Gbits/sec  909    843 KBytes       \n",
      "[  5]   5.00-6.00   sec  2.87 GBytes  24.7 Gbits/sec  287    812 KBytes       \n",
      "[  5]   6.00-7.00   sec  3.49 GBytes  30.0 Gbits/sec  659    779 KBytes       \n",
      "[  5]   7.00-8.00   sec  4.62 GBytes  39.7 Gbits/sec  2222    997 KBytes       \n",
      "[  5]   8.00-9.00   sec  3.83 GBytes  32.9 Gbits/sec  699    717 KBytes       \n",
      "[  5]   9.00-10.00  sec  3.27 GBytes  28.0 Gbits/sec  449    622 KBytes       \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "[ ID] Interval           Transfer     Bitrate         Retr\n",
      "[  5]   0.00-10.00  sec  39.2 GBytes  33.7 Gbits/sec  9705             sender\n",
      "[  5]   0.00-10.00  sec  39.2 GBytes  33.7 Gbits/sec                  receiver\n",
      "\n",
      "iperf Done.\n",
      "\n",
      "\n",
      ">>> TCP Single Stream: 33.7 Gbps\n"
     ]
    }
   ],
   "source": [
    "# iperf3 single stream over bond\n",
    "print(\"=== TCP Bandwidth (Single Stream) ===\")\n",
    "print(\"NOTE: Start server on remote: iperf3 -s -B\", REMOTE_IP)\n",
    "print()\n",
    "\n",
    "output = run_cmd(f\"iperf3 -c {REMOTE_IP} -t 10\")\n",
    "print(output)\n",
    "\n",
    "# Parse sender bandwidth\n",
    "bw = parse_bandwidth(output, r\"sender\\s+.*?(\\d+\\.?\\d*)\\s+Gbits/sec\")\n",
    "if bw:\n",
    "    print(f\"\\n>>> TCP Single Stream: {bw:.1f} Gbps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bbf0f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TCP Bandwidth (4 Parallel Streams) ===\n",
      "\n",
      "Connecting to host 192.168.100.10, port 5201\n",
      "[  5] local 192.168.100.11 port 32998 connected to 192.168.100.10 port 5201\n",
      "[  7] local 192.168.100.11 port 33002 connected to 192.168.100.10 port 5201\n",
      "[  9] local 192.168.100.11 port 33004 connected to 192.168.100.10 port 5201\n",
      "[ 11] local 192.168.100.11 port 33018 connected to 192.168.100.10 port 5201\n",
      "[ ID] Interval           Transfer     Bitrate         Retr  Cwnd\n",
      "[  5]   0.00-1.00   sec  2.55 GBytes  21.8 Gbits/sec  623    909 KBytes       \n",
      "[  7]   0.00-1.00   sec  2.82 GBytes  24.2 Gbits/sec  1332   1.11 MBytes       \n",
      "[  9]   0.00-1.00   sec  2.80 GBytes  24.0 Gbits/sec  868    683 KBytes       \n",
      "[ 11]   0.00-1.00   sec  2.76 GBytes  23.7 Gbits/sec  360    621 KBytes       \n",
      "[SUM]   0.00-1.00   sec  10.9 GBytes  93.7 Gbits/sec  3183             \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "[  5]   1.00-2.00   sec  2.71 GBytes  23.3 Gbits/sec  578    865 KBytes       \n",
      "[  7]   1.00-2.00   sec  2.74 GBytes  23.5 Gbits/sec    0   1.25 MBytes       \n",
      "[  9]   1.00-2.00   sec  2.87 GBytes  24.6 Gbits/sec  256    700 KBytes       \n",
      "[ 11]   1.00-2.00   sec  2.61 GBytes  22.4 Gbits/sec  312    730 KBytes       \n",
      "[SUM]   1.00-2.00   sec  10.9 GBytes  93.8 Gbits/sec  1146             \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "[  5]   2.00-3.00   sec  2.75 GBytes  23.7 Gbits/sec  290    986 KBytes       \n",
      "[  7]   2.00-3.00   sec  2.75 GBytes  23.6 Gbits/sec    0   1.31 MBytes       \n",
      "[  9]   2.00-3.00   sec  2.59 GBytes  22.2 Gbits/sec  857    831 KBytes       \n",
      "[ 11]   2.00-3.00   sec  2.50 GBytes  21.5 Gbits/sec  292    940 KBytes       \n",
      "[SUM]   2.00-3.00   sec  10.6 GBytes  91.0 Gbits/sec  1439             \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "[  5]   3.00-4.00   sec  2.81 GBytes  24.1 Gbits/sec  540    820 KBytes       \n",
      "[  7]   3.00-4.00   sec  2.74 GBytes  23.5 Gbits/sec    0   1.34 MBytes       \n",
      "[  9]   3.00-4.00   sec  2.63 GBytes  22.6 Gbits/sec  525    673 KBytes       \n",
      "[ 11]   3.00-4.00   sec  2.81 GBytes  24.1 Gbits/sec  535    898 KBytes       \n",
      "[SUM]   3.00-4.00   sec  11.0 GBytes  94.4 Gbits/sec  1600             \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "[  5]   4.00-5.00   sec  3.00 GBytes  25.8 Gbits/sec  467    885 KBytes       \n",
      "[  7]   4.00-5.00   sec  2.72 GBytes  23.4 Gbits/sec    0   1.37 MBytes       \n",
      "[  9]   4.00-5.00   sec  2.49 GBytes  21.4 Gbits/sec  621    819 KBytes       \n",
      "[ 11]   4.00-5.00   sec  2.79 GBytes  24.0 Gbits/sec  529   1011 KBytes       \n",
      "[SUM]   4.00-5.00   sec  11.0 GBytes  94.5 Gbits/sec  1617             \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "[  5]   5.00-6.00   sec  2.57 GBytes  22.1 Gbits/sec  600    926 KBytes       \n",
      "[  7]   5.00-6.00   sec  2.74 GBytes  23.6 Gbits/sec    0   1.39 MBytes       \n",
      "[  9]   5.00-6.00   sec  2.71 GBytes  23.3 Gbits/sec  329   1.10 MBytes       \n",
      "[ 11]   5.00-6.00   sec  2.52 GBytes  21.7 Gbits/sec  556    817 KBytes       \n",
      "[SUM]   5.00-6.00   sec  10.6 GBytes  90.7 Gbits/sec  1485             \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "[  5]   6.00-7.00   sec  2.79 GBytes  23.9 Gbits/sec  654    833 KBytes       \n",
      "[  7]   6.00-7.00   sec  2.72 GBytes  23.3 Gbits/sec    0   1.42 MBytes       \n",
      "[  9]   6.00-7.00   sec  2.59 GBytes  22.3 Gbits/sec  371    851 KBytes       \n",
      "[ 11]   6.00-7.00   sec  2.80 GBytes  24.0 Gbits/sec  611    752 KBytes       \n",
      "[SUM]   6.00-7.00   sec  10.9 GBytes  93.6 Gbits/sec  1636             \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "[  5]   7.00-8.00   sec  2.64 GBytes  22.6 Gbits/sec  481   1.03 MBytes       \n",
      "[  7]   7.00-8.00   sec  2.73 GBytes  23.5 Gbits/sec    0   1.47 MBytes       \n",
      "[  9]   7.00-8.00   sec  2.70 GBytes  23.2 Gbits/sec  531    918 KBytes       \n",
      "[ 11]   7.00-8.00   sec  2.67 GBytes  23.0 Gbits/sec  397    850 KBytes       \n",
      "[SUM]   7.00-8.00   sec  10.7 GBytes  92.3 Gbits/sec  1409             \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "[  5]   8.00-9.00   sec  2.66 GBytes  22.9 Gbits/sec  459    904 KBytes       \n",
      "[  7]   8.00-9.00   sec  2.69 GBytes  23.1 Gbits/sec  195   1.09 MBytes       \n",
      "[  9]   8.00-9.00   sec  2.83 GBytes  24.3 Gbits/sec  558    796 KBytes       \n",
      "[ 11]   8.00-9.00   sec  2.59 GBytes  22.3 Gbits/sec  539    935 KBytes       \n",
      "[SUM]   8.00-9.00   sec  10.8 GBytes  92.6 Gbits/sec  1751             \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "[  5]   9.00-10.00  sec  2.64 GBytes  22.6 Gbits/sec  515    810 KBytes       \n",
      "[  7]   9.00-10.00  sec  2.79 GBytes  23.9 Gbits/sec   42   1.14 MBytes       \n",
      "[  9]   9.00-10.00  sec  2.66 GBytes  22.8 Gbits/sec  485    636 KBytes       \n",
      "[ 11]   9.00-10.00  sec  2.76 GBytes  23.7 Gbits/sec  458    806 KBytes       \n",
      "[SUM]   9.00-10.00  sec  10.8 GBytes  93.1 Gbits/sec  1500             \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "[ ID] Interval           Transfer     Bitrate         Retr\n",
      "[  5]   0.00-10.00  sec  27.1 GBytes  23.3 Gbits/sec  5207             sender\n",
      "[  5]   0.00-10.00  sec  27.1 GBytes  23.3 Gbits/sec                  receiver\n",
      "[  7]   0.00-10.00  sec  27.4 GBytes  23.6 Gbits/sec  1569             sender\n",
      "[  7]   0.00-10.00  sec  27.4 GBytes  23.6 Gbits/sec                  receiver\n",
      "[  9]   0.00-10.00  sec  26.9 GBytes  23.1 Gbits/sec  5401             sender\n",
      "[  9]   0.00-10.00  sec  26.9 GBytes  23.1 Gbits/sec                  receiver\n",
      "[ 11]   0.00-10.00  sec  26.8 GBytes  23.0 Gbits/sec  4589             sender\n",
      "[ 11]   0.00-10.00  sec  26.8 GBytes  23.0 Gbits/sec                  receiver\n",
      "[SUM]   0.00-10.00  sec   108 GBytes  93.0 Gbits/sec  16766             sender\n",
      "[SUM]   0.00-10.00  sec   108 GBytes  93.0 Gbits/sec                  receiver\n",
      "\n",
      "iperf Done.\n",
      "\n",
      "\n",
      ">>> TCP 4 Streams: 93.0 Gbps\n"
     ]
    }
   ],
   "source": [
    "# iperf3 multiple streams over bond\n",
    "print(\"=== TCP Bandwidth (4 Parallel Streams) ===\")\n",
    "print()\n",
    "\n",
    "output = run_cmd(f\"iperf3 -c {REMOTE_IP} -t 10 -P 4\")\n",
    "print(output)\n",
    "\n",
    "# Parse sender bandwidth (SUM line)\n",
    "bw = parse_bandwidth(output, r\"\\[SUM\\].*sender\\s+.*?(\\d+\\.?\\d*)\\s+Gbits/sec\")\n",
    "if not bw:\n",
    "    bw = parse_bandwidth(output, r\"SUM.*?(\\d+\\.?\\d*)\\s+Gbits/sec.*sender\")\n",
    "if bw:\n",
    "    print(f\"\\n>>> TCP 4 Streams: {bw:.1f} Gbps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0905f2e",
   "metadata": {},
   "source": [
    "### 3.3 Results Summary: TCP vs RDMA\n",
    "\n",
    "**Measured results:**\n",
    "\n",
    "| Test | Throughput | Notes |\n",
    "|------|------------|-------|\n",
    "| RDMA single link (`ib_write_bw`) | 11,679 MB/s (93.4 Gbps) | Kernel bypass, near line rate |\n",
    "| TCP single stream over bond (`iperf3`) | 33.7 Gbps | Kernel TCP/IP stack overhead |\n",
    "| TCP 4 parallel streams over bond (`iperf3 -P 4`) | 93.0 Gbps | Utilizes both bonded links |\n",
    "\n",
    "**Key observations:**\n",
    "- RDMA achieves 2.8x the throughput of single-stream TCP over the same link\n",
    "- TCP bonding with 4 parallel streams matches RDMA single-link performance\n",
    "- Single TCP stream limited to ~34 Gbps despite 200 Gbps aggregate link capacity\n",
    "\n",
    "### Why TCP Underperforms\n",
    "\n",
    "The TCP/IP stack introduces overhead at every layer:\n",
    "- **System calls**: Each send/recv crosses user-kernel boundary\n",
    "- **Buffer copies**: Data copied between user space and kernel buffers\n",
    "- **Protocol processing**: TCP segmentation, checksums, congestion control\n",
    "- **Interrupt handling**: Each packet generates CPU interrupts\n",
    "\n",
    "RDMA bypasses all of this. The NIC reads/writes directly to application memory.\n",
    "\n",
    "### Bonding Limitations\n",
    "\n",
    "Balance-xor bonding requires multiple TCP connections to utilize both links:\n",
    "\n",
    "| Configuration | Single Stream | Multiple Streams |\n",
    "|---------------|---------------|------------------|\n",
    "| Direct interface (no bond) | 34 Gbps | 34 Gbps per stream |\n",
    "| balance-xor bond | 34 Gbps (one link) | 93 Gbps (4 streams distributed) |\n",
    "| RDMA (no bond possible) | 93 Gbps | 186 Gbps (dual-rail) |\n",
    "\n",
    "**Implication for ML workloads:** Large tensor transfers are single logical connections. TCP bonding peaks at 34 Gbps for single streams, requiring application-level parallelism to utilize both links. RDMA achieves 93 Gbps per link with a single connection, making NIXL and NCCL essential for high-bandwidth inference data movement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f1aa1",
   "metadata": {},
   "source": [
    "### 3.3 Monitor Bond Traffic Distribution\n",
    "\n",
    "During active transfers, verify traffic flows through both interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eba4c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Interface Statistics ===\n",
      "\n",
      "enp1s0f0np0:\n",
      "    RX:   bytes  packets errors dropped  missed   mcast           \n",
      "       28155917   411642      0       0       0    1483 \n",
      "    TX:   bytes  packets errors dropped carrier collsns           \n",
      "    30196466759 19946201      0       8       0       0 \n",
      "\n",
      "\n",
      "enp1s0f1np1:\n",
      "    RX:    bytes   packets errors dropped  missed   mcast           \n",
      "       109760955   1637992      0       0       0     742 \n",
      "    TX:    bytes   packets errors dropped carrier collsns           \n",
      "    166126447731 109769273      0       3       0       0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check per-interface statistics\n",
    "print(\"=== Interface Statistics ===\")\n",
    "print(f\"\\n{INTERFACE_1}:\")\n",
    "print(run_cmd(f\"ip -s link show {INTERFACE_1} | grep -A 2 'RX\\\\|TX'\"))\n",
    "print(f\"\\n{INTERFACE_2}:\")\n",
    "print(run_cmd(f\"ip -s link show {INTERFACE_2} | grep -A 2 'RX\\\\|TX'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dbeeaa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: NIXL Point-to-Point Transfers\n",
    "\n",
    "NIXL provides direct RDMA transfers for point-to-point workloads (KV-cache, tensor shards).\n",
    "\n",
    "### 4.0 Remove Bond Interface (Required)\n",
    "\n",
    "RDMA memory registration fails when network interfaces are enslaved to a bond. The verbs API requires direct access to the physical device, but bonded interfaces associate with `bond0` instead of the underlying hardware.\n",
    "\n",
    "**Why bond must be removed:**\n",
    "- When interfaces join a bond, the kernel reassigns their identity\n",
    "- GID entries point to `bond0` instead of `rocep1s0f0`/`rocep1s0f1`\n",
    "- RDMA operations fail because `bond0` has no verbs capability\n",
    "- NIXL `register_memory()` returns empty descriptors or raises exceptions\n",
    "\n",
    "**Remove bond on both nodes before proceeding:**\n",
    "\n",
    "```bash\n",
    "# Check if bond exists\n",
    "cat /proc/net/bonding/bond0 2>/dev/null\n",
    "\n",
    "# Remove bond\n",
    "sudo ip link set bond0 down\n",
    "sudo ip link set enp1s0f0np0 nomaster\n",
    "sudo ip link set enp1s0f1np1 nomaster\n",
    "sudo ip link delete bond0\n",
    "\n",
    "# Bring interfaces back up\n",
    "sudo ip link set enp1s0f0np0 up\n",
    "sudo ip link set enp1s0f1np1 up\n",
    "\n",
    "# Restore IP addresses\n",
    "# spark-01: sudo ip addr add 192.168.100.10/24 dev enp1s0f0np0\n",
    "# spark-02: sudo ip addr add 192.168.100.11/24 dev enp1s0f0np0\n",
    "```\n",
    "\n",
    "**Verify RDMA devices are accessible:**\n",
    "```bash\n",
    "ibdev2netdev\n",
    "# Should show: rocep1s0f0 port 1 ==> enp1s0f0np0 (Up)\n",
    "#             rocep1s0f1 port 1 ==> enp1s0f1np1 (Up)\n",
    "```\n",
    "\n",
    "### 4.1 Verify NIXL Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "480539c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIXL is installed\n",
      "\n",
      "=== UCX Device Detection ===\n",
      "#      Transport: self\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: tcp\n",
      "#      Transport: sysv\n",
      "#      Transport: posix\n",
      "#      Transport: dc_mlx5\n",
      "#      Transport: rc_verbs\n",
      "#      Transport: rc_mlx5\n",
      "#      Transport: ud_verbs\n",
      "#      Transport: ud_mlx5\n",
      "#      Transport: dc_mlx5\n",
      "#      Transport: rc_verbs\n",
      "#      Transport: rc_mlx5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check NIXL installation\n",
    "try:\n",
    "    from nixl._api import nixl_agent, nixl_agent_config\n",
    "    print(\"NIXL is installed\")\n",
    "    \n",
    "    # Check UCX devices\n",
    "    print(\"\\n=== UCX Device Detection ===\")\n",
    "    print(run_cmd(\"ucx_info -d 2>/dev/null | grep -E 'mlx5|Transport' | head -20\"))\n",
    "except ImportError:\n",
    "    print(\"NIXL not installed. Install with:\")\n",
    "    print(\"  pip install nixl[cu12]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25146255",
   "metadata": {},
   "source": [
    "### 4.2 NIXL Local Memory Registration Test\n",
    "\n",
    "Test NIXL memory registration and descriptor creation (single-node validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5d46b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-26 23:43:26 NIXL INFO    _api.py:363 Backend UCX was instantiated\n",
      "2026-01-26 23:43:26 NIXL INFO    _api.py:253 Initialized NIXL agent: test_agent\n",
      "NIXL agent created successfully\n",
      "\n",
      "Attempting GPU memory registration...\n",
      "GPU registration error: NIXL_ERR_BACKEND\n",
      "Falling back to CPU memory\n",
      "[1769492606.288817] [spark-02:1379163:0]           ib_md.c:296  UCX  ERROR ibv_reg_mr(address=0x32ee00000, length=4194304, access=0x10000f) failed: Bad address\n",
      "\n",
      "Using CPU memory...\n",
      "[1769492606.288830] [spark-02:1379163:0]          ucp_mm.c:81   UCX  ERROR failed to register address 0x32ee00000 (host) length 4194304 on md[6]=rocep1s0f0: Input/output error (md supports: host)\n",
      "Allocated CPU tensor: torch.Size([1024, 1024]), 4.2 MB\n",
      "Error: NIXL_ERR_BACKEND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0126 23:43:26.288835 1379163 nixl_agent.cpp:479] registerMem: registration failed for the specified or all potential backends\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1379163/587084076.py\", line 51, in <module>\n",
      "    reg_descs = agent.register_memory(tensor)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nvidia/src/github.com/elizabetht/spark/.venv/lib/python3.12/site-packages/nixl_cu12/_api.py\", line 386, in register_memory\n",
      "    self.agent.registerMem(reg_descs, handle_list)\n",
      "nixl_cu12._bindings.nixlBackendError: NIXL_ERR_BACKEND\n",
      "E0126 23:43:26.289369 1379163 nixl_agent.cpp:479] registerMem: registration failed for the specified or all potential backends\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1769492606.289357] [spark-02:1379163:0]           ib_md.c:296  UCX  ERROR ibv_reg_mr(address=0x32ee00000, length=4194304, access=0x10000f) failed: Bad address\n",
      "[1769492606.289366] [spark-02:1379163:0]          ucp_mm.c:81   UCX  ERROR failed to register address 0x32ee00000 (host) length 4194304 on md[6]=rocep1s0f0: Input/output error (md supports: host)\n"
     ]
    }
   ],
   "source": [
    "# NIXL memory registration test (local validation)\n",
    "try:\n",
    "    import torch\n",
    "    from nixl._api import nixl_agent, nixl_agent_config\n",
    "    \n",
    "    # Create NIXL agent\n",
    "    config = nixl_agent_config(\n",
    "        enable_prog_thread=True,\n",
    "        backends=[\"UCX\"]\n",
    "    )\n",
    "    \n",
    "    agent = nixl_agent(\"test_agent\", config)\n",
    "    print(\"NIXL agent created successfully\")\n",
    "    \n",
    "    # Try GPU first, fallback to CPU if GPU registration fails\n",
    "    mem_type = \"CPU\"\n",
    "    tensor = None\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"\\nAttempting GPU memory registration...\")\n",
    "        try:\n",
    "            # Pin GPU memory for better RDMA compatibility\n",
    "            device = torch.device(\"cuda:0\")\n",
    "            tensor = torch.ones((1024, 1024), dtype=torch.float32, device=device)\n",
    "            mem_type = \"GPU\"\n",
    "            \n",
    "            # Attempt registration\n",
    "            reg_descs = agent.register_memory(tensor)\n",
    "            if not reg_descs:\n",
    "                print(\"GPU memory registration failed, falling back to CPU\")\n",
    "                tensor = None\n",
    "                mem_type = \"CPU\"\n",
    "            else:\n",
    "                print(\"GPU memory registration: SUCCESS\")\n",
    "        except Exception as e:\n",
    "            print(f\"GPU registration error: {e}\")\n",
    "            print(\"Falling back to CPU memory\")\n",
    "            tensor = None\n",
    "            mem_type = \"CPU\"\n",
    "    \n",
    "    # Use CPU memory if GPU failed or unavailable\n",
    "    if tensor is None:\n",
    "        print(\"\\nUsing CPU memory...\")\n",
    "        tensor = torch.ones((1024, 1024), dtype=torch.float32)\n",
    "        mem_type = \"CPU\"\n",
    "    \n",
    "    print(f\"Allocated {mem_type} tensor: {tensor.shape}, {tensor.numel() * 4 / 1e6:.1f} MB\")\n",
    "    \n",
    "    # Register memory with NIXL (if not already registered)\n",
    "    if mem_type == \"CPU\":\n",
    "        reg_descs = agent.register_memory(tensor)\n",
    "    \n",
    "    if reg_descs:\n",
    "        print(f\"{mem_type} memory registration: SUCCESS\")\n",
    "        \n",
    "        # Get transfer descriptors\n",
    "        xfer_descs = agent.get_xfer_descs([tensor])\n",
    "        desc_str = agent.get_serialized_descs(xfer_descs)\n",
    "        print(f\"Descriptor size: {len(desc_str)} bytes\")\n",
    "        print(\"Descriptor serialization: SUCCESS\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Status: NIXL agent functional with CPU memory\")\n",
    "        print(\"=\" * 60)\n",
    "    else:\n",
    "        print(f\"{mem_type} memory registration: FAILED\")\n",
    "        print(\"\\nNote: GPU registration may fail due to:\")\n",
    "        print(\"  - UCX not compiled with CUDA support (check: ucx_info -d)\")\n",
    "        print(\"  - GPU memory not accessible via RDMA\")\n",
    "        print(\"  - InfiniBand/RoCE adapters not configured for GPUDirect RDMA\")\n",
    "        print(\"\\nFor production NIXL with GPU:\")\n",
    "        print(\"  1. Verify UCX built with --with-cuda\")\n",
    "        print(\"  2. Check GPU peer memory support\")\n",
    "        print(\"  3. CPU memory works for this tutorial demo\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"NIXL not available: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a909c",
   "metadata": {},
   "source": [
    "### 4.3 NIXL Two-Node Transfer Test\n",
    "\n",
    "For a full RDMA transfer test, run the target script on the remote node and the initiator script locally.\n",
    "\n",
    "**On remote node (spark-02), run target:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5786bc4",
   "metadata": {},
   "source": [
    "### 4.2.1 GPU Memory Registration Status\n",
    "\n",
    "**nvidia-peermem module status:** The `nvidia-peermem` kernel module exists on DGX Spark but fails to load with \"Invalid argument\". This is a known issue with certain kernel/driver combinations.\n",
    "\n",
    "**Current workaround:** UCX with CUDA support can use GPU memory via `cuda_copy` and `cuda_ipc` transports. These transports bounce through CPU but still provide GPU-to-GPU transfer capability.\n",
    "\n",
    "**Performance impact:**\n",
    "- Without nvidia-peermem (GPUDirect RDMA): Uses staging through host memory\n",
    "- With nvidia-peermem: NIC can directly access GPU memory (1.5-2x faster for large transfers)\n",
    "\n",
    "**To check module status:**\n",
    "\n",
    "```bash\n",
    "# Check if module exists\n",
    "modinfo nvidia-peermem\n",
    "\n",
    "# Try to load (will fail on DGX Spark)\n",
    "sudo modprobe nvidia-peermem\n",
    "\n",
    "# Check UCX GPU support (should work regardless)\n",
    "ucx_info -d | grep -i cuda\n",
    "```\n",
    "\n",
    "For this tutorial, we proceed without nvidia-peermem. NIXL will use CPU memory for RDMA transfers, which still demonstrates dual-rail aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db85c994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Target Node Script ===\n",
      "Save to spark-01 as ~/target_node.py and run:\n",
      "  .venv/bin/python3 ~/target_node.py\n",
      "\n",
      "NOTE: If 'Address already in use' error, kill existing process:\n",
      "  pkill -f target_node.py\n",
      "\n",
      "#!/usr/bin/env python3\n",
      "# target_node.py - Run on spark-01\n",
      "\n",
      "import os\n",
      "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1\"\n",
      "\n",
      "import time\n",
      "import torch\n",
      "from nixl._api import nixl_agent, nixl_agent_config\n",
      "\n",
      "config = nixl_agent_config(\n",
      "    enable_prog_thread=True,\n",
      "    enable_listen_thread=True,\n",
      "    listen_port=5555,\n",
      "    backends=[\"UCX\"]\n",
      ")\n",
      "\n",
      "agent = nixl_agent(\"target\", config)\n",
      "print(\"NIXL agent created\")\n",
      "\n",
      "# CPU memory (GPU RDMA requires nvidia_peermem which won't load on DGX Spark)\n",
      "tensor = torch.ones((4096, 4096), dtype=torch.float32, device=\"cpu\")\n",
      "print(f\"Target tensor: {tensor.shape}, {tensor.numel() * 4 / 1e6:.1f} MB (CPU)\")\n",
      "\n",
      "agent.register_memory(tensor)\n",
      "print(\"Memory registered\")\n",
      "\n",
      "target_descs = agent.get_xfer_descs([tensor])\n",
      "desc_str = agent.get_serialized_descs(target_descs)\n",
      "print(f\"Descriptor ready ({len(desc_str)} bytes)\")\n",
      "\n",
      "print(\"Waiting for initiator...\")\n",
      "while not agent.check_remote_metadata(\"initiator\"):\n",
      "    time.sleep(0.1)\n",
      "\n",
      "agent.send_notif(\"initiator\", desc_str)\n",
      "print(\"Sent descriptors to initiator\")\n",
      "\n",
      "print(\"Waiting for transfer completion...\")\n",
      "while True:\n",
      "    notifs = agent.get_new_notifs()\n",
      "    if \"initiator\" in notifs:\n",
      "        for notif in notifs[\"initiator\"]:\n",
      "            if b\"done\" in notif:\n",
      "                print(\"Transfer completed!\")\n",
      "                break\n",
      "        else:\n",
      "            continue\n",
      "        break\n",
      "    time.sleep(0.1)\n",
      "\n",
      "print(\"Target finished\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Target node script (run on remote node)\n",
    "target_script = '''#!/usr/bin/env python3\n",
    "# target_node.py - Run on spark-01\n",
    "\n",
    "import os\n",
    "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1\"\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from nixl._api import nixl_agent, nixl_agent_config\n",
    "\n",
    "config = nixl_agent_config(\n",
    "    enable_prog_thread=True,\n",
    "    enable_listen_thread=True,\n",
    "    listen_port=5555,\n",
    "    backends=[\"UCX\"]\n",
    ")\n",
    "\n",
    "agent = nixl_agent(\"target\", config)\n",
    "print(\"NIXL agent created\")\n",
    "\n",
    "# CPU memory (GPU RDMA requires nvidia_peermem which won't load on DGX Spark)\n",
    "tensor = torch.ones((4096, 4096), dtype=torch.float32, device=\"cpu\")\n",
    "print(f\"Target tensor: {tensor.shape}, {tensor.numel() * 4 / 1e6:.1f} MB (CPU)\")\n",
    "\n",
    "agent.register_memory(tensor)\n",
    "print(\"Memory registered\")\n",
    "\n",
    "target_descs = agent.get_xfer_descs([tensor])\n",
    "desc_str = agent.get_serialized_descs(target_descs)\n",
    "print(f\"Descriptor ready ({len(desc_str)} bytes)\")\n",
    "\n",
    "print(\"Waiting for initiator...\")\n",
    "while not agent.check_remote_metadata(\"initiator\"):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "agent.send_notif(\"initiator\", desc_str)\n",
    "print(\"Sent descriptors to initiator\")\n",
    "\n",
    "print(\"Waiting for transfer completion...\")\n",
    "while True:\n",
    "    notifs = agent.get_new_notifs()\n",
    "    if \"initiator\" in notifs:\n",
    "        for notif in notifs[\"initiator\"]:\n",
    "            if b\"done\" in notif:\n",
    "                print(\"Transfer completed!\")\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(\"Target finished\")\n",
    "'''\n",
    "\n",
    "print(\"=== Target Node Script ===\")\n",
    "print(\"Save to spark-01 as ~/target_node.py and run:\")\n",
    "print(\"  .venv/bin/python3 ~/target_node.py\")\n",
    "print()\n",
    "print(\"NOTE: If 'Address already in use' error, kill existing process:\")\n",
    "print(\"  pkill -f target_node.py\")\n",
    "print()\n",
    "print(target_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c7addee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initiator Node Script ===\n",
      "Run on spark-02 AFTER target shows 'Waiting for initiator...':\n",
      "  .venv/bin/python3 ~/initiator_node.py\n",
      "\n",
      "#!/usr/bin/env python3\n",
      "# initiator_node.py - Run on spark-02\n",
      "\n",
      "import os\n",
      "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1\"\n",
      "\n",
      "import time\n",
      "import torch\n",
      "from nixl._api import nixl_agent, nixl_agent_config\n",
      "\n",
      "TARGET_IP = \"192.168.100.10\"\n",
      "TARGET_PORT = 5555\n",
      "\n",
      "config = nixl_agent_config(\n",
      "    enable_prog_thread=True,\n",
      "    enable_listen_thread=True,\n",
      "    listen_port=0,\n",
      "    backends=[\"UCX\"]\n",
      ")\n",
      "\n",
      "agent = nixl_agent(\"initiator\", config)\n",
      "print(\"NIXL agent created\")\n",
      "\n",
      "# CPU memory (GPU RDMA requires nvidia_peermem which won't load on DGX Spark)\n",
      "local_tensor = torch.zeros((4096, 4096), dtype=torch.float32, device=\"cpu\")\n",
      "print(f\"Local tensor: {local_tensor.shape}, {local_tensor.numel() * 4 / 1e6:.1f} MB (CPU)\")\n",
      "\n",
      "agent.register_memory(local_tensor)\n",
      "print(\"Memory registered\")\n",
      "\n",
      "print(f\"Connecting to target at {TARGET_IP}:{TARGET_PORT}\")\n",
      "agent.fetch_remote_metadata(\"target\", TARGET_IP, TARGET_PORT)\n",
      "agent.send_local_metadata(TARGET_IP, TARGET_PORT)\n",
      "\n",
      "print(\"Waiting for descriptors...\")\n",
      "notifs = agent.get_new_notifs()\n",
      "while \"target\" not in notifs or len(notifs[\"target\"]) == 0:\n",
      "    time.sleep(0.1)\n",
      "    notifs = agent.get_new_notifs()\n",
      "\n",
      "remote_descs = agent.deserialize_descs(notifs[\"target\"][0])\n",
      "local_descs = agent.get_xfer_descs([local_tensor])\n",
      "print(\"Received remote descriptors\")\n",
      "\n",
      "print(\"Starting RDMA READ (64 MB)...\")\n",
      "start_time = time.perf_counter()\n",
      "\n",
      "xfer_handle = agent.initialize_xfer(\"READ\", local_descs, remote_descs, \"target\", \"done\")\n",
      "agent.transfer(xfer_handle)\n",
      "\n",
      "while agent.check_xfer_state(xfer_handle) != \"DONE\":\n",
      "    time.sleep(0.001)\n",
      "\n",
      "elapsed = time.perf_counter() - start_time\n",
      "size_mb = local_tensor.numel() * 4 / 1e6\n",
      "throughput_gbps = (size_mb * 8) / (elapsed * 1000)\n",
      "\n",
      "print(f\"Transfer complete: {size_mb:.1f} MB in {elapsed*1000:.2f} ms\")\n",
      "print(f\"Throughput: {throughput_gbps:.1f} Gbps\")\n",
      "\n",
      "expected = torch.ones((4096, 4096), dtype=torch.float32, device=\"cpu\")\n",
      "if torch.allclose(local_tensor, expected):\n",
      "    print(\"Data verification: PASSED\")\n",
      "else:\n",
      "    print(\"Data verification: FAILED\")\n",
      "\n",
      "print(\"Initiator finished\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initiator node script (run locally after target is ready)\n",
    "initiator_script = f'''#!/usr/bin/env python3\n",
    "# initiator_node.py - Run on spark-02\n",
    "\n",
    "import os\n",
    "os.environ[\"UCX_NET_DEVICES\"] = \"rocep1s0f0:1\"\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from nixl._api import nixl_agent, nixl_agent_config\n",
    "\n",
    "TARGET_IP = \"{REMOTE_IP}\"\n",
    "TARGET_PORT = 5555\n",
    "\n",
    "config = nixl_agent_config(\n",
    "    enable_prog_thread=True,\n",
    "    enable_listen_thread=True,\n",
    "    listen_port=0,\n",
    "    backends=[\"UCX\"]\n",
    ")\n",
    "\n",
    "agent = nixl_agent(\"initiator\", config)\n",
    "print(\"NIXL agent created\")\n",
    "\n",
    "# CPU memory (GPU RDMA requires nvidia_peermem which won't load on DGX Spark)\n",
    "local_tensor = torch.zeros((4096, 4096), dtype=torch.float32, device=\"cpu\")\n",
    "print(f\"Local tensor: {{local_tensor.shape}}, {{local_tensor.numel() * 4 / 1e6:.1f}} MB (CPU)\")\n",
    "\n",
    "agent.register_memory(local_tensor)\n",
    "print(\"Memory registered\")\n",
    "\n",
    "print(f\"Connecting to target at {{TARGET_IP}}:{{TARGET_PORT}}\")\n",
    "agent.fetch_remote_metadata(\"target\", TARGET_IP, TARGET_PORT)\n",
    "agent.send_local_metadata(TARGET_IP, TARGET_PORT)\n",
    "\n",
    "print(\"Waiting for descriptors...\")\n",
    "notifs = agent.get_new_notifs()\n",
    "while \"target\" not in notifs or len(notifs[\"target\"]) == 0:\n",
    "    time.sleep(0.1)\n",
    "    notifs = agent.get_new_notifs()\n",
    "\n",
    "remote_descs = agent.deserialize_descs(notifs[\"target\"][0])\n",
    "local_descs = agent.get_xfer_descs([local_tensor])\n",
    "print(\"Received remote descriptors\")\n",
    "\n",
    "print(\"Starting RDMA READ (64 MB)...\")\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "xfer_handle = agent.initialize_xfer(\"READ\", local_descs, remote_descs, \"target\", \"done\")\n",
    "agent.transfer(xfer_handle)\n",
    "\n",
    "while agent.check_xfer_state(xfer_handle) != \"DONE\":\n",
    "    time.sleep(0.001)\n",
    "\n",
    "elapsed = time.perf_counter() - start_time\n",
    "size_mb = local_tensor.numel() * 4 / 1e6\n",
    "throughput_gbps = (size_mb * 8) / (elapsed * 1000)\n",
    "\n",
    "print(f\"Transfer complete: {{size_mb:.1f}} MB in {{elapsed*1000:.2f}} ms\")\n",
    "print(f\"Throughput: {{throughput_gbps:.1f}} Gbps\")\n",
    "\n",
    "expected = torch.ones((4096, 4096), dtype=torch.float32, device=\"cpu\")\n",
    "if torch.allclose(local_tensor, expected):\n",
    "    print(\"Data verification: PASSED\")\n",
    "else:\n",
    "    print(\"Data verification: FAILED\")\n",
    "\n",
    "print(\"Initiator finished\")\n",
    "'''\n",
    "\n",
    "print(\"=== Initiator Node Script ===\")\n",
    "print(\"Run on spark-02 AFTER target shows 'Waiting for initiator...':\")\n",
    "print(\"  .venv/bin/python3 ~/initiator_node.py\")\n",
    "print()\n",
    "print(initiator_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f18b33",
   "metadata": {},
   "source": [
    "### 4.4 NIXL Multi-Rail Configuration\n",
    "\n",
    "Configure UCX to use both RoCE devices for maximum throughput.print(\"  Terminal 2: ib_write_bw -d rocep1s0f1 -p 18516\")print(\"  Terminal 1: ib_write_bw -d rocep1s0f0 -p 18515\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be61a7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'threading' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# UCX multi-rail environment variables\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m t1 = \u001b[43mthreading\u001b[49m.Thread(target=run_ib_test, args=(\u001b[33m\"\u001b[39m\u001b[33mrocep1s0f0\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m18515\u001b[39m, REMOTE_IP))\n\u001b[32m      3\u001b[39m t2 = threading.Thread(target=run_ib_test, args=(\u001b[33m\"\u001b[39m\u001b[33mrocep1s0f1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m18516\u001b[39m, REMOTE_IP))\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSet these environment variables before running NIXL scripts:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'threading' is not defined"
     ]
    }
   ],
   "source": [
    "# UCX multi-rail environment variables\n",
    "t1 = threading.Thread(target=run_ib_test, args=(\"rocep1s0f0\", 18515, REMOTE_IP))\n",
    "t2 = threading.Thread(target=run_ib_test, args=(\"rocep1s0f1\", 18516, REMOTE_IP))\n",
    "print(\"Set these environment variables before running NIXL scripts:\")\n",
    "print()\n",
    "print(\"# Use both RoCE devices\")\n",
    "print(\"export UCX_NET_DEVICES=mlx5_0:1,mlx5_1:1\")\n",
    "print()\n",
    "print(\"# Select RDMA transports\")\n",
    "print(\"export UCX_TLS=rc_verbs,rc_mlx5\")\n",
    "print()\n",
    "print(\"# Verify configuration\")\n",
    "print(\"ucx_info -d | grep -E 'mlx5|Transport'\")\n",
    "print()\n",
    "print(\"With multi-rail enabled, large transfers automatically\")\n",
    "print(\"stripe across both devices for ~176 Gbps aggregate throughput.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540d0b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Performance Summary\n",
    "\n",
    "Compare bonding vs NIXL results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f501b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison table\n",
    "# Measured results from DGX Spark testing (January 2026)\n",
    "\n",
    "comparison_data = {\n",
    "    \"TCP Single Stream\": {\"gbps\": 35, \"latency_us\": 100},\n",
    "    \"TCP 4 Streams (bonded)\": {\"gbps\": 93, \"latency_us\": 100},\n",
    "    \"RDMA Single Link (ib_write_bw)\": {\"gbps\": 93, \"latency_us\": 2},\n",
    "    \"NIXL Single Rail (CPU memory)\": {\"gbps\": 81.8, \"latency_us\": 2},\n",
    "}\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(f\"{'Test Configuration':<30} {'Throughput':>15} {'Latency':>15}\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "for test, data in comparison_data.items():\n",
    "    gbps = data[\"gbps\"]\n",
    "    latency = data[\"latency_us\"]\n",
    "    print(f\"{test:<30} {gbps:>12.1f} Gbps {latency:>12.0f} μs\")\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print()\n",
    "print(\"Key findings:\")\n",
    "print(\"- Raw RDMA (ib_write_bw): 93 Gbps (near 100G line rate)\")\n",
    "print(\"- NIXL with CPU memory:  81.8 Gbps (88% of raw RDMA)\")\n",
    "print(\"- TCP single stream:     35 Gbps (kernel overhead)\")\n",
    "print()\n",
    "print(\"NIXL achieves 2.3x single-stream TCP throughput.\")\n",
    "print()\n",
    "print(\"Note: NIXL overhead vs raw RDMA is due to metadata handling,\")\n",
    "print(\"transfer setup, and Python API overhead. Production workloads\")\n",
    "print(\"with larger transfers and GPU memory would see higher efficiency.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6288e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    tests = list(comparison_data.keys())\n",
    "    throughputs = [d[\"gbps\"] for d in comparison_data.values()]\n",
    "    latencies = [d[\"latency_us\"] for d in comparison_data.values()]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Throughput comparison\n",
    "    colors = ['#ff6b6b' if 'TCP' in t else '#4ecdc4' for t in tests]\n",
    "    bars1 = ax1.barh(tests, throughputs, color=colors)\n",
    "    ax1.set_xlabel('Throughput (Gbps)')\n",
    "    ax1.set_title('Throughput: Bonding vs NIXL')\n",
    "    ax1.axvline(x=100, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "    for bar, val in zip(bars1, throughputs):\n",
    "        ax1.text(val + 2, bar.get_y() + bar.get_height()/2, f'{val:.0f}',\n",
    "                va='center', fontsize=10)\n",
    "\n",
    "    # Latency comparison (log scale)\n",
    "    bars2 = ax2.barh(tests, latencies, color=colors)\n",
    "    ax2.set_xlabel('Latency (μs) - Log Scale')\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.set_title('Latency: Bonding vs NIXL')\n",
    "\n",
    "    for bar, val in zip(bars2, latencies):\n",
    "        ax2.text(val * 1.2, bar.get_y() + bar.get_height()/2, f'{val:.0f}',\n",
    "                va='center', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('bonding_vs_nixl_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\nChart saved to bonding_vs_nixl_comparison.png\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"matplotlib not installed. Install with: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b970469",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Key Findings\n",
    "\n",
    "### Why Bonding Underperforms\n",
    "\n",
    "```\n",
    "TCP/IP Path (Bonding):\n",
    "  Application → Socket API → Kernel TCP/IP Stack → Driver → NIC\n",
    "  \n",
    "RDMA Path (NIXL):\n",
    "  Application → Verbs API → NIC (direct memory access)\n",
    "```\n",
    "\n",
    "The kernel TCP/IP stack introduces:\n",
    "- **CPU overhead**: Context switches, buffer copies, interrupt handling\n",
    "- **Latency**: 50-200 μs vs 1-2 μs for RDMA\n",
    "- **Throughput ceiling**: ~35 Gbps per flow regardless of link speed\n",
    "\n",
    "### When to Use Each Approach\n",
    "\n",
    "| Workload | Recommended |\n",
    "|----------|-------------|\n",
    "| KV-cache transfer | NIXL |\n",
    "| Tensor shard movement | NIXL |\n",
    "| Disaggregated inference | NIXL |\n",
    "| Collective operations | NCCL (see [first tutorial](01_InfiniBand_Tutorial.ipynb)) |\n",
    "| SSH/management | Bonding |\n",
    "| NFS storage | Bonding |\n",
    "\n",
    "### Coexistence\n",
    "\n",
    "Bonding and NIXL can coexist:\n",
    "- Bond for IP traffic (uses kernel stack)\n",
    "- NIXL for RDMA (bypasses kernel entirely)\n",
    "\n",
    "RDMA verbs access `mlx5_0`/`mlx5_1` directly; traffic does not traverse `bond0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b3c64f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Cleanup\n",
    "\n",
    "Remove the bond interface if no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands to remove bond (run manually if needed)\n",
    "print(\"To remove the bond interface:\")\n",
    "print(\"\"\"\n",
    "sudo ip link set bond0 down\n",
    "sudo ip link set enp1s0f0np0 nomaster\n",
    "sudo ip link set enp1s0f1np1 nomaster\n",
    "sudo ip link delete bond0\n",
    "\n",
    "# Restore individual interface IPs if needed\n",
    "sudo ip addr add 192.168.100.10/24 dev enp1s0f0np0\n",
    "sudo ip addr add 192.168.200.10/24 dev enp1s0f1np1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026df3b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- [RoCE Link Aggregation Tutorial (Markdown)](02_Multi_Rail_Tutorial.md)\n",
    "- [NCCL and RDMA Benchmarks (First Tutorial)](01_InfiniBand_Tutorial.ipynb)\n",
    "- [NIXL GitHub Repository](https://github.com/ai-dynamo/nixl)\n",
    "- [Linux Kernel Bonding Documentation](https://www.kernel.org/doc/Documentation/networking/bonding.txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
