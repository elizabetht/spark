{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c09428",
   "metadata": {},
   "source": [
    "# NIXL Single-Rail vs Dual-Rail Benchmarks\n",
    "\n",
    "This tutorial benchmarks RDMA performance using NIXL (NVIDIA Inference Xfer Library) to compare single-rail versus dual-rail RoCE configurations.\n",
    "\n",
    "**Hardware Configuration:**\n",
    "- Two DGX Spark nodes with dual 100G RoCE links\n",
    "- Interfaces: `rocep1s0f0` (link 1) and `rocep1s0f1` (link 2)\n",
    "- Direct-connect topology (no switch)\n",
    "\n",
    "**Test Matrix:**\n",
    "\n",
    "| Test | Rails | Expected Throughput | Purpose |\n",
    "|------|-------|---------------------|---------|\n",
    "| Single-Rail DRAM | 1x 100G | ~96 Gbps | Baseline |\n",
    "| Dual-Rail DRAM | 2x 100G | ~176 Gbps | Multi-rail aggregation |\n",
    "| Single-Rail VRAM | 1x 100G | ~96 Gbps | GPUDirect baseline |\n",
    "| Dual-Rail VRAM | 2x 100G | ~180 Gbps | GPUDirect + multi-rail |\n",
    "\n",
    "**Prerequisites:**\n",
    "- Completed [02_Multi_Rail_Tutorial.ipynb](02_Multi_Rail_Tutorial.ipynb) for network setup\n",
    "- UCX 1.20+ with CUDA support\n",
    "- NIXL installed with nixlbench built\n",
    "- ETCD for worker coordination\n",
    "\n",
    "---\n",
    "\n",
    "## Installing Dependencies\n",
    "\n",
    "### 1. UCX (Unified Communication X)\n",
    "\n",
    "UCX provides the transport layer for RDMA operations. Build with CUDA and RDMA support:\n",
    "\n",
    "```bash\n",
    "# Clone and build UCX\n",
    "git clone https://github.com/openucx/ucx.git\n",
    "cd ucx\n",
    "./autogen.sh\n",
    "./configure --prefix=/usr/local/ucx \\\n",
    "  --with-cuda=/usr/local/cuda \\\n",
    "  --with-rdmacm \\\n",
    "  --with-verbs \\\n",
    "  --enable-mt\n",
    "make -j$(nproc)\n",
    "sudo make install\n",
    "\n",
    "# Add to library path\n",
    "echo 'export LD_LIBRARY_PATH=/usr/local/ucx/lib:$LD_LIBRARY_PATH' >> ~/.bashrc\n",
    "echo 'export PATH=/usr/local/ucx/bin:$PATH' >> ~/.bashrc\n",
    "source ~/.bashrc\n",
    "```\n",
    "\n",
    "### 2. NIXL (NVIDIA Inference Xfer Library)\n",
    "\n",
    "```bash\n",
    "# Clone NIXL\n",
    "git clone https://github.com/ai-dynamo/nixl.git\n",
    "cd nixl\n",
    "\n",
    "# Build NIXL library\n",
    "meson setup build --prefix=/usr/local/nixl\n",
    "cd build && ninja && sudo ninja install\n",
    "\n",
    "# Build nixlbench\n",
    "cd ../benchmark/nixlbench\n",
    "meson setup build -Dnixl_path=/usr/local/nixl --prefix=/usr/local/nixlbench\n",
    "cd build && ninja && sudo ninja install\n",
    "```\n",
    "\n",
    "### 3. ETCD (Coordination Service)\n",
    "\n",
    "Option A: Docker (recommended, used in this notebook):\n",
    "```bash\n",
    "# Pull ETCD image (started automatically by the notebook)\n",
    "docker pull quay.io/coreos/etcd:v3.5.0\n",
    "```\n",
    "\n",
    "Option B: System package:\n",
    "```bash\n",
    "sudo apt install etcd-server\n",
    "# Note: Default config binds to localhost only; docker method handles network binding\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009905ab",
   "metadata": {},
   "source": [
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ca20f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local IP:  192.168.100.11\n",
      "Remote IP: 192.168.100.10\n",
      "Device 1:  rocep1s0f0\n",
      "Device 2:  rocep1s0f1\n",
      "\n",
      "=== RDMA Devices ===\n",
      "    device          \t   node GUID\n",
      "    ------          \t----------------\n",
      "    rocep1s0f0      \t30c59903003e6a13\n",
      "    rocep1s0f1      \t30c59903003e6a14\n",
      "    roceP2p1s0f0    \t30c59903003e6a17\n",
      "    roceP2p1s0f1    \t30c59903003e6a18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def run_cmd(cmd, timeout=120):\n",
    "    \"\"\"Run a shell command and return output.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)\n",
    "        return result.stdout + result.stderr\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return \"Command timed out\"\n",
    "\n",
    "# Network configuration (update for your environment)\n",
    "LOCAL_IP = \"192.168.100.11\"   # This node (initiator)\n",
    "REMOTE_IP = \"192.168.100.10\"  # Target node\n",
    "\n",
    "# RDMA device names (check with `ibv_devices`)\n",
    "DEVICE_1 = \"rocep1s0f0\"  # First RoCE device\n",
    "DEVICE_2 = \"rocep1s0f1\"  # Second RoCE device\n",
    "\n",
    "# Path to nixlbench (update if installed elsewhere)\n",
    "NIXLBENCH = \"/usr/local/nixlbench/bin/nixlbench\"\n",
    "\n",
    "print(f\"Local IP:  {LOCAL_IP}\")\n",
    "print(f\"Remote IP: {REMOTE_IP}\")\n",
    "print(f\"Device 1:  {DEVICE_1}\")\n",
    "print(f\"Device 2:  {DEVICE_2}\")\n",
    "\n",
    "# Verify RDMA devices\n",
    "print(\"\\n=== RDMA Devices ===\")\n",
    "print(run_cmd(\"ibv_devices\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37396850",
   "metadata": {},
   "source": [
    "## Part 2: How NIXL Multi-Rail Works\n",
    "\n",
    "NIXL uses UCX (Unified Communication X) as its transport layer. UCX automatically discovers available RDMA devices and load-balances traffic across them.\n",
    "\n",
    "**Single-Rail vs Dual-Rail:**\n",
    "\n",
    "| Configuration | UCX Behavior | Maximum Throughput |\n",
    "|---------------|--------------|-------------------|\n",
    "| `--device_list rocep1s0f0` | Uses only specified device | ~96 Gbps (1x 100G) |\n",
    "| `--device_list rocep1s0f0,rocep1s0f1` | Load-balances across both | ~176 Gbps (2x 100G) |\n",
    "| No device_list | UCX auto-selects all available | ~176 Gbps (2x 100G) |\n",
    "\n",
    "**Architecture:**\n",
    "- Workers register with ETCD for coordination\n",
    "- UCX initializes transport endpoints on specified devices\n",
    "- Multi-rail striping distributes data across links automatically\n",
    "- Progress threads improve throughput by overlapping transfers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72fcaa0",
   "metadata": {},
   "source": [
    "### Start ETCD Server\n",
    "\n",
    "NIXL requires ETCD for worker coordination. ETCD runs on spark-02 (this node) and both benchmark instances connect to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3cb95ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETCD endpoint: http://192.168.100.11:2379\n",
      "ETCD listening on 192.168.100.11:2379 - OK\n",
      "ETCD version: {\"etcdserver\":\"3.5.0\",\"etcdcluster\":\"3.5.0\"}\n",
      "\n",
      "=== Clearing ETCD state ===\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# ETCD server setup (runs locally on spark-02)\n",
    "# Must listen on all interfaces so spark-01 can connect\n",
    "\n",
    "# ETCD endpoint for benchmarks (local)\n",
    "ETCD_IP = LOCAL_IP\n",
    "print(f\"ETCD endpoint: http://{ETCD_IP}:2379\")\n",
    "\n",
    "# Check if ETCD is accessible from the network (not just localhost)\n",
    "import socket\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "sock.settimeout(2)\n",
    "try:\n",
    "    sock.connect((LOCAL_IP, 2379))\n",
    "    sock.close()\n",
    "    etcd_ok = True\n",
    "    print(f\"ETCD listening on {LOCAL_IP}:2379 - OK\")\n",
    "except:\n",
    "    etcd_ok = False\n",
    "    print(f\"ETCD NOT listening on {LOCAL_IP}:2379\")\n",
    "\n",
    "if not etcd_ok:\n",
    "    print()\n",
    "    print(\"Starting docker ETCD container...\")\n",
    "    \n",
    "    # Stop system etcd if running (it binds to localhost only)\n",
    "    run_cmd(\"sudo systemctl stop etcd 2>/dev/null\")\n",
    "    \n",
    "    # Remove any existing container and start fresh\n",
    "    run_cmd(\"sudo docker rm -f nixl-etcd 2>/dev/null\")\n",
    "    start_result = run_cmd(\"sudo docker run -d --name nixl-etcd --network host quay.io/coreos/etcd:v3.5.0 /usr/local/bin/etcd --data-dir=/etcd-data --listen-client-urls=http://0.0.0.0:2379 --advertise-client-urls=http://0.0.0.0:2379\")\n",
    "    print(start_result.strip())\n",
    "    \n",
    "    # Wait for startup\n",
    "    import time\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Verify\n",
    "    try:\n",
    "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        sock.settimeout(2)\n",
    "        sock.connect((LOCAL_IP, 2379))\n",
    "        sock.close()\n",
    "        print(f\"ETCD started and listening on {LOCAL_IP}:2379\")\n",
    "    except:\n",
    "        print(\"ERROR: ETCD failed to start. Check: sudo docker logs nixl-etcd\")\n",
    "\n",
    "# Check version\n",
    "etcd_check = run_cmd(f\"curl -s http://{LOCAL_IP}:2379/version 2>/dev/null\")\n",
    "if \"etcdserver\" in etcd_check:\n",
    "    print(f\"ETCD version: {etcd_check.strip()}\")\n",
    "    \n",
    "    # Clear stale ETCD state\n",
    "    print()\n",
    "    print(\"=== Clearing ETCD state ===\")\n",
    "    clear_result = run_cmd('sudo docker exec nixl-etcd etcdctl del \"xferbench\" --prefix 2>/dev/null || echo \"Cleared\"')\n",
    "    print(clear_result.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3fb228",
   "metadata": {},
   "source": [
    "### Verify nixlbench Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c643a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nixlbench found at /usr/local/nixlbench/bin/nixlbench\n",
      "\n",
      "=== nixlbench Options ===\n",
      "NIXL Benchmark Tool\n",
      "Usage:\n",
      "  nixlbench [OPTION...]\n",
      "\n",
      "      --help                    Print usage\n",
      "      --config_file arg         Config file (default: none) (default: \"\")\n",
      "      --benchmark_group arg     Name of benchmark group. Use different \n",
      "                                names to run multiple benchmarks in \n",
      "                                parallel (Default: default) (default: \n",
      "                                default)\n",
      "      --runtime_type arg        Runtime type to use for communication \n",
      "                                [ETCD] (default: ETCD)\n",
      "      --worker_type arg         Type of worker [nixl, nvshmem] (default: \n",
      "                                nixl)\n",
      "      --backend arg             Name of NIXL backend [UCX, GDS, GDS_MT, \n",
      "                                POSIX, GPUNETIO, Mooncake, HF3FS, OBJ, \n",
      "                                GUSLI] (only used with nixl worker) \n",
      "                                (default: UCX)\n",
      "      --initiator_seg_type arg  Type of memory segment for initiator [DRAM, \n",
      "                                VRAM]. Note: Storage backends always use \n",
      "                                DRAM locally. (default: DRAM)\n",
      "      --target_seg_type arg     Type of memory segment for target [DRAM, \n",
      "                                VRAM]. Note: Storage backends determine \n",
      "                                remote type automatically. (default: DRAM)\n",
      "      --scheme arg              Scheme: pairwise, maytoone, onetomany, tp \n",
      "                                (default: pairwise)\n",
      "      --mode arg                MODE: SG (Single GPU per proc), MG (Multi \n",
      "                                GPU per proc) [default: SG] (default: SG)\n",
      "      --op_type arg             Op type: READ, WRITE (default: WRITE)\n",
      "      --check_consistency       Enable Consistency Check\n",
      "      --total_buffer_size arg   Total buffer size across device for each \n",
      "                                process (Default: 80 GiB) (default: \n",
      "                                8589934592)\n",
      "      --start_block_size arg    Max size of block (Default: 4 KiB) \n",
      "                                (default: 4096)\n",
      "      --max_block_size arg      Max size of block (Default: 64 MiB) \n",
      "                                (default: 67108864)\n",
      "      --start_batch_size arg    Starting size of batch (Default: 1) \n",
      "                                (default: 1)\n",
      "      --max_batch_size arg      Max size of batch (starts from 1) (default: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if nixlbench is available\n",
    "if os.path.exists(NIXLBENCH):\n",
    "    print(f\"nixlbench found at {NIXLBENCH}\")\n",
    "    print()\n",
    "    print(\"=== nixlbench Options ===\")\n",
    "    print(run_cmd(f\"{NIXLBENCH} --help 2>&1 | head -40\"))\n",
    "else:\n",
    "    print(f\"nixlbench not found at {NIXLBENCH}\")\n",
    "    print()\n",
    "    print(\"Build instructions:\")\n",
    "    print(\"  cd /path/to/nixl/benchmark/nixlbench\")\n",
    "    print(\"  meson setup build -Dnixl_path=/usr/local/nixl --prefix=/usr/local/nixlbench\")\n",
    "    print(\"  cd build && ninja && sudo ninja install\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6b83c",
   "metadata": {},
   "source": [
    "## Part 3: Single-Rail DRAM Benchmark (Baseline)\n",
    "\n",
    "Test CPU memory transfer over a single 100G link to establish baseline performance.\n",
    "\n",
    "**Coordination:** Both nodes must run nixlbench within 60 seconds of each other. ETCD on spark-02 handles rank assignment.\n",
    "\n",
    "**On spark-01 (run second, after starting the cell below on spark-02):**\n",
    "```bash\n",
    "/usr/local/nixlbench/bin/nixlbench --etcd_endpoints http://192.168.100.11:2379 \\\n",
    "  --backend UCX \\\n",
    "  --device_list rocep1s0f0 \\\n",
    "  --initiator_seg_type DRAM \\\n",
    "  --target_seg_type DRAM \\\n",
    "  --total_buffer_size 4294967296 \\\n",
    "  --start_block_size 65536 \\\n",
    "  --max_block_size 67108864 \\\n",
    "  --num_iter 1000 \\\n",
    "  --warmup_iter 100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4915a93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Single-Rail DRAM (Baseline) ===\n",
      "Device: rocep1s0f0 only (--device_list limits to one device)\n",
      "Expected: ~96 Gbps (single 100G link)\n",
      "\n",
      "Before: rocep1s0f0 RDMA TX=1,226,565,897,140 bytes, rocep1s0f1 RDMA TX=438,530,827,352 bytes\n",
      "\n",
      "NOTE: Run this cell first, then run spark-01 command to see results\n",
      "\n",
      "Running benchmark...\n",
      "WARNING: Adjusting num_iter to 1008 to allow equal distribution to 1 threads\n",
      "WARNING: Adjusting warmup_iter to 112 to allow equal distribution to 1 threads\n",
      "Connecting to ETCD at http://192.168.100.11:2379\n",
      "ETCD Runtime: Registered as rank 0 item 1 of 2\n",
      "Init nixl worker, dev rocep1s0f0 rank 0, type initiator, hostname spark-02\n",
      "[1770147796.894697] [spark-02:1217553:0]      ucp_worker.c:2315 UCX  WARN  invalid configuration: RC_GDA_NUM_CHANNELS=4\n",
      "[1770147796.941429] [spark-02:1217553:0]      ucp_worker.c:2315 UCX  WARN  invalid configuration: RC_GDA_NUM_CHANNELS=4\n",
      "Waiting for all processes to start... (expecting 2 total: 1 initiators and 1 targets)\n",
      "All processes are ready to proceed\n",
      "****************************************************************************************************************************************************************\n",
      "NIXLBench Configuration\n",
      "****************************************************************************************************************************************************************\n",
      "Runtime (--runtime_type=[etcd])                             : ETCD\n",
      "ETCD Endpoint                                               : http://192.168.100.11:2379\n",
      "Worker type (--worker_type=[nixl,nvshmem])                  : nixl\n",
      "Backend (--backend=[UCX,GDS,GDS_MT,POSIX,Mooncake,HF3FS,OBJ]): UCX\n",
      "Enable pt (--enable_pt=[0,1])                               : 0\n",
      "Progress threads (--progress_threads=N)                     : 0\n",
      "Device list (--device_list=dev1,dev2,...)                   : rocep1s0f0\n",
      "Enable VMM (--enable_vmm=[0,1])                             : 0\n",
      "Initiator seg type (--initiator_seg_type=[DRAM,VRAM])       : DRAM\n",
      "Target seg type (--target_seg_type=[DRAM,VRAM])             : DRAM\n",
      "Scheme (--scheme=[pairwise,manytoone,onetomany,tp])         : pairwise\n",
      "Mode (--mode=[SG,MG])                                       : SG\n",
      "Op type (--op_type=[READ,WRITE])                            : WRITE\n",
      "Check consistency (--check_consistency=[0,1])               : 0\n",
      "Total buffer size (--total_buffer_size=N)                   : 4294967296\n",
      "Num initiator dev (--num_initiator_dev=N)                   : 1\n",
      "Num target dev (--num_target_dev=N)                         : 1\n",
      "Start block size (--start_block_size=N)                     : 65536\n",
      "Max block size (--max_block_size=N)                         : 67108864\n",
      "Start batch size (--start_batch_size=N)                     : 1\n",
      "Max batch size (--max_batch_size=N)                         : 1\n",
      "Num iter (--num_iter=N)                                     : 1008\n",
      "Warmup iter (--warmup_iter=N)                               : 112\n",
      "Large block iter factor (--large_blk_iter_ftr=N)            : 16\n",
      "Num threads (--num_threads=N)                               : 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Block Size (B)      Batch Size     B/W (GB/Sec)   Avg Lat. (us)  Avg Prep (us)  P99 Prep (us)  Avg Post (us)  P99 Post (us)  Avg Tx (us)    P99 Tx (us)    \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "65536               1              6.804727       9.6            15.0           15.0           0.3            1.0            9.3            10.0           \n",
      "131072              1              7.695298       17.0           6.0            6.0            0.4            1.0            16.6           17.0           \n",
      "262144              1              9.269993       28.3           6.0            6.0            0.4            1.0            27.8           29.0           \n",
      "524288              1              10.266976      51.1           17.0           17.0           0.4            1.0            50.6           51.0           \n",
      "1048576             1              11.091501      94.5           16.0           16.0           0.2            1.0            94.3           95.0           \n",
      "2097152             1              11.288498      185.8          12.0           12.0           0.4            10.0           185.1          187.0          \n",
      "4194304             1              11.375485      368.7          6.0            6.0            0.6            6.0            367.9          371.0          \n",
      "8388608             1              11.468551      731.4          19.0           19.0           0.8            16.0           730.3          731.0          \n",
      "16777216            1              11.528343      1455.3         6.0            6.0            0.6            6.0            1454.5         1461.0         \n",
      "33554432            1              11.554051      2904.1         16.0           16.0           0.5            15.0           2903.3         2904.0         \n",
      "67108864            1              11.563310      5803.6         17.0           17.0           0.5            14.0           5802.7         5804.0         \n",
      "\n",
      "\n",
      "=== Link Utilization Verification (RDMA counters) ===\n",
      "rocep1s0f0: 12.18 GB transmitted via RDMA\n",
      "rocep1s0f1: 0.00 GB transmitted via RDMA\n",
      "Total: 12.18 GB\n",
      "\n",
      "✓ SINGLE-RAIL CONFIRMED: Only rocep1s0f0 was used\n",
      "  All data traversed a single 100G link.\n"
     ]
    }
   ],
   "source": [
    "# Single-Rail DRAM benchmark (initiator side)\n",
    "# Uses only rocep1s0f0 (one 100G link)\n",
    "\n",
    "# Size conversions (nixlbench requires bytes, not human-readable)\n",
    "# 4GiB = 4294967296, 64KiB = 65536, 64MiB = 67108864\n",
    "\n",
    "def get_rdma_stats(device):\n",
    "    \"\"\"Get RDMA port transmit bytes (RDMA bypasses kernel network stack).\"\"\"\n",
    "    cmd = f\"cat /sys/class/infiniband/{device}/ports/1/counters/port_xmit_data 2>/dev/null\"\n",
    "    stats = run_cmd(cmd)\n",
    "    if stats.strip().isdigit():\n",
    "        # Counter is in 4-byte words, multiply by 4 for bytes\n",
    "        return int(stats.strip()) * 4\n",
    "    return 0\n",
    "\n",
    "print(\"=== Test 1: Single-Rail DRAM (Baseline) ===\")\n",
    "print(f\"Device: {DEVICE_1} only (--device_list limits to one device)\")\n",
    "print(f\"Expected: ~96 Gbps (single 100G link)\")\n",
    "print()\n",
    "\n",
    "# Get RDMA stats before\n",
    "tx1_before = get_rdma_stats(DEVICE_1)\n",
    "tx2_before = get_rdma_stats(DEVICE_2)\n",
    "print(f\"Before: {DEVICE_1} RDMA TX={tx1_before:,} bytes, {DEVICE_2} RDMA TX={tx2_before:,} bytes\")\n",
    "\n",
    "single_rail_dram_cmd = f\"\"\"{NIXLBENCH} \\\n",
    "  --etcd_endpoints http://{ETCD_IP}:2379 \\\n",
    "  --backend UCX \\\n",
    "  --device_list {DEVICE_1} \\\n",
    "  --initiator_seg_type DRAM \\\n",
    "  --target_seg_type DRAM \\\n",
    "  --total_buffer_size 4294967296 \\\n",
    "  --start_block_size 65536 \\\n",
    "  --max_block_size 67108864 \\\n",
    "  --num_iter 1000 \\\n",
    "  --warmup_iter 100\"\"\"\n",
    "\n",
    "print()\n",
    "print(\"NOTE: Run this cell first, then run spark-01 command to see results\")\n",
    "print()\n",
    "\n",
    "# Execute the benchmark\n",
    "print(\"Running benchmark...\")\n",
    "result = run_cmd(single_rail_dram_cmd, timeout=300)\n",
    "print(result)\n",
    "\n",
    "# Get RDMA stats after\n",
    "tx1_after = get_rdma_stats(DEVICE_1)\n",
    "tx2_after = get_rdma_stats(DEVICE_2)\n",
    "\n",
    "# Calculate bytes transferred on each link\n",
    "tx1_diff = tx1_after - tx1_before\n",
    "tx2_diff = tx2_after - tx2_before\n",
    "\n",
    "print()\n",
    "print(\"=== Link Utilization Verification (RDMA counters) ===\")\n",
    "print(f\"{DEVICE_1}: {tx1_diff/1e9:.2f} GB transmitted via RDMA\")\n",
    "print(f\"{DEVICE_2}: {tx2_diff/1e9:.2f} GB transmitted via RDMA\")\n",
    "print(f\"Total: {(tx1_diff + tx2_diff)/1e9:.2f} GB\")\n",
    "print()\n",
    "# Note: Single-rail and dual-rail tests transfer the SAME total bytes (determined by\n",
    "# buffer_size * iterations). The difference is distribution:\n",
    "#   - Single-rail: 100% of bytes on one link (~X GB on link 1, ~0 on link 2)\n",
    "#   - Dual-rail: ~50% on each link (~X/2 GB each), achieving higher throughput\n",
    "# The speedup comes from parallel transfers, not more data.\n",
    "if tx1_diff > 1e9 and tx2_diff < 1e8:\n",
    "    print(\"✓ SINGLE-RAIL CONFIRMED: Only\", DEVICE_1, \"was used\")\n",
    "    print(\"  All data traversed a single 100G link.\")\n",
    "elif tx1_diff > 1e9 and tx2_diff > 1e9:\n",
    "    print(\"⚠ Both links used (unexpected for single-rail test)\")\n",
    "else:\n",
    "    print(\"Note: RDMA counters may not be available. Check throughput in benchmark output above.\")\n",
    "\n",
    "single_rail_dram_result = result + f\"\\n{DEVICE_1}: {tx1_diff/1e9:.2f} GB\\n{DEVICE_2}: {tx2_diff/1e9:.2f} GB\"\n",
    "# Store result for Part 8 summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a20a0",
   "metadata": {},
   "source": [
    "## Part 4: Dual-Rail DRAM Benchmark\n",
    "\n",
    "Test CPU memory transfer over both 100G links. UCX automatically load-balances traffic.\n",
    "\n",
    "**On spark-01 (run second, after starting the cell below on spark-02):**\n",
    "```bash\n",
    "/usr/local/nixlbench/bin/nixlbench --etcd_endpoints http://192.168.100.11:2379 \\\n",
    "  --backend UCX \\\n",
    "  --initiator_seg_type DRAM \\\n",
    "  --target_seg_type DRAM \\\n",
    "  --total_buffer_size 4294967296 \\\n",
    "  --start_block_size 65536 \\\n",
    "  --max_block_size 67108864 \\\n",
    "  --num_iter 1000 \\\n",
    "  --warmup_iter 100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9004fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 2: Dual-Rail DRAM ===\n",
      "Expected: ~176 Gbps (2x 100G links)\n",
      "\n",
      "Before: rocep1s0f0 RDMA TX=1,193,298,274,412 bytes, rocep1s0f1 RDMA TX=419,917,778,456 bytes\n",
      "\n",
      "NOTE: Run this cell first, then run spark-01 command to see results\n",
      "\n",
      "Running benchmark...\n",
      "WARNING: Adjusting num_iter to 1008 to allow equal distribution to 1 threads\n",
      "WARNING: Adjusting warmup_iter to 112 to allow equal distribution to 1 threads\n",
      "Connecting to ETCD at http://192.168.100.11:2379\n",
      "ETCD Runtime: Registered as rank 0 item 1 of 2\n",
      "Init nixl worker, dev all rank 0, type initiator, hostname spark-02\n",
      "[1770144748.460958] [spark-02:1216443:0]      ucp_worker.c:2315 UCX  WARN  invalid configuration: RC_GDA_NUM_CHANNELS=4\n",
      "[1770144748.665270] [spark-02:1216443:0]      ucp_worker.c:2315 UCX  WARN  invalid configuration: RC_GDA_NUM_CHANNELS=4\n",
      "Waiting for all processes to start... (expecting 2 total: 1 initiators and 1 targets)\n",
      "All processes are ready to proceed\n",
      "****************************************************************************************************************************************************************\n",
      "NIXLBench Configuration\n",
      "****************************************************************************************************************************************************************\n",
      "Runtime (--runtime_type=[etcd])                             : ETCD\n",
      "ETCD Endpoint                                               : http://192.168.100.11:2379\n",
      "Worker type (--worker_type=[nixl,nvshmem])                  : nixl\n",
      "Backend (--backend=[UCX,GDS,GDS_MT,POSIX,Mooncake,HF3FS,OBJ]): UCX\n",
      "Enable pt (--enable_pt=[0,1])                               : 0\n",
      "Progress threads (--progress_threads=N)                     : 0\n",
      "Device list (--device_list=dev1,dev2,...)                   : all\n",
      "Enable VMM (--enable_vmm=[0,1])                             : 0\n",
      "Initiator seg type (--initiator_seg_type=[DRAM,VRAM])       : DRAM\n",
      "Target seg type (--target_seg_type=[DRAM,VRAM])             : DRAM\n",
      "Scheme (--scheme=[pairwise,manytoone,onetomany,tp])         : pairwise\n",
      "Mode (--mode=[SG,MG])                                       : SG\n",
      "Op type (--op_type=[READ,WRITE])                            : WRITE\n",
      "Check consistency (--check_consistency=[0,1])               : 0\n",
      "Total buffer size (--total_buffer_size=N)                   : 4294967296\n",
      "Num initiator dev (--num_initiator_dev=N)                   : 1\n",
      "Num target dev (--num_target_dev=N)                         : 1\n",
      "Start block size (--start_block_size=N)                     : 65536\n",
      "Max block size (--max_block_size=N)                         : 67108864\n",
      "Start batch size (--start_batch_size=N)                     : 1\n",
      "Max batch size (--max_batch_size=N)                         : 1\n",
      "Num iter (--num_iter=N)                                     : 1008\n",
      "Warmup iter (--warmup_iter=N)                               : 112\n",
      "Large block iter factor (--large_blk_iter_ftr=N)            : 16\n",
      "Num threads (--num_threads=N)                               : 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Block Size (B)      Batch Size     B/W (GB/Sec)   Avg Lat. (us)  Avg Prep (us)  P99 Prep (us)  Avg Post (us)  P99 Post (us)  Avg Tx (us)    P99 Tx (us)    \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "65536               1              6.560760       10.0           15.0           15.0           0.6            1.0            9.4            10.0           \n",
      "131072              1              8.798653       14.9           17.0           17.0           0.6            1.0            14.3           15.0           \n",
      "262144              1              10.328375      25.4           6.0            6.0            0.6            1.0            24.8           26.0           \n",
      "524288              1              11.561128      45.3           17.0           17.0           0.6            1.0            44.7           46.0           \n",
      "1048576             1              12.472442      84.1           16.0           16.0           0.4            1.0            83.7           85.0           \n",
      "2097152             1              12.781327      164.1          16.0           16.0           0.6            15.0           163.2          164.0          \n",
      "4194304             1              12.932711      324.3          17.0           17.0           1.0            20.0           322.9          324.0          \n",
      "8388608             1              13.062169      642.2          7.0            7.0            0.7            6.0            641.4          648.0          \n",
      "16777216            1              13.122497      1278.5         18.0           18.0           0.9            17.0           1277.2         1283.0         \n",
      "33554432            1              13.159830      2549.8         17.0           17.0           0.6            16.0           2548.8         2550.0         \n",
      "67108864            1              13.173730      5094.1         17.0           17.0           0.7            15.0           5093.1         5095.0         \n",
      "\n",
      "\n",
      "=== Link Utilization Verification (RDMA counters) ===\n",
      "rocep1s0f0: 6.09 GB transmitted via RDMA\n",
      "rocep1s0f1: 6.09 GB transmitted via RDMA\n",
      "Total: 12.18 GB\n",
      "\n",
      "✓ DUAL-RAIL CONFIRMED: Both links transferred significant data\n",
      "  Data split: 50% / 50% across links\n"
     ]
    }
   ],
   "source": [
    "# Dual-Rail DRAM benchmark (initiator side)\n",
    "# Omit --device_list to let UCX auto-select all available RoCE devices\n",
    "# \n",
    "# KEY DIFFERENCE from Single-Rail:\n",
    "#   Single-Rail: --device_list rocep1s0f0  (limits to ONE device)\n",
    "#   Dual-Rail:   No --device_list          (UCX uses ALL available)\n",
    "\n",
    "def get_rdma_stats(device):\n",
    "    \"\"\"Get RDMA port transmit bytes (RDMA bypasses kernel network stack).\"\"\"\n",
    "    # Map network device to InfiniBand device name\n",
    "    ib_device = device.replace(\"roce\", \"roce\")  # rocep1s0f0 -> rocep1s0f0\n",
    "    # Try reading from InfiniBand counters\n",
    "    cmd = f\"cat /sys/class/infiniband/{device}/ports/1/counters/port_xmit_data 2>/dev/null\"\n",
    "    stats = run_cmd(cmd)\n",
    "    if stats.strip().isdigit():\n",
    "        # Counter is in 4-byte words, multiply by 4 for bytes\n",
    "        return int(stats.strip()) * 4\n",
    "    return 0\n",
    "\n",
    "# Capture baseline stats\n",
    "print(\"=== Test 2: Dual-Rail DRAM ===\")\n",
    "print(f\"Expected: ~176 Gbps (2x 100G links)\")\n",
    "print()\n",
    "\n",
    "# Get RDMA stats before\n",
    "tx1_before = get_rdma_stats(DEVICE_1)\n",
    "tx2_before = get_rdma_stats(DEVICE_2)\n",
    "print(f\"Before: {DEVICE_1} RDMA TX={tx1_before:,} bytes, {DEVICE_2} RDMA TX={tx2_before:,} bytes\")\n",
    "\n",
    "dual_rail_dram_cmd = f\"\"\"{NIXLBENCH} \\\n",
    "  --etcd_endpoints http://{ETCD_IP}:2379 \\\n",
    "  --backend UCX \\\n",
    "  --initiator_seg_type DRAM \\\n",
    "  --target_seg_type DRAM \\\n",
    "  --total_buffer_size 4294967296 \\\n",
    "  --start_block_size 65536 \\\n",
    "  --max_block_size 67108864 \\\n",
    "  --num_iter 1000 \\\n",
    "  --warmup_iter 100\"\"\"\n",
    "\n",
    "print()\n",
    "print(\"NOTE: Run this cell first, then run spark-01 command to see results\")\n",
    "print()\n",
    "\n",
    "# Execute the benchmark\n",
    "print(\"Running benchmark...\")\n",
    "result = run_cmd(dual_rail_dram_cmd, timeout=300)\n",
    "print(result)\n",
    "\n",
    "# Get RDMA stats after\n",
    "tx1_after = get_rdma_stats(DEVICE_1)\n",
    "tx2_after = get_rdma_stats(DEVICE_2)\n",
    "\n",
    "# Calculate bytes transferred on each link\n",
    "tx1_diff = tx1_after - tx1_before\n",
    "tx2_diff = tx2_after - tx2_before\n",
    "\n",
    "print()\n",
    "print(\"=== Link Utilization Verification (RDMA counters) ===\")\n",
    "print(f\"{DEVICE_1}: {tx1_diff/1e9:.2f} GB transmitted via RDMA\")\n",
    "print(f\"{DEVICE_2}: {tx2_diff/1e9:.2f} GB transmitted via RDMA\")\n",
    "print(f\"Total: {(tx1_diff + tx2_diff)/1e9:.2f} GB\")\n",
    "print()\n",
    "# Note: Total bytes transferred is similar to single-rail (same buffer_size * iterations).\n",
    "# The difference: data is now SPLIT across two links, so each link carries ~50%.\n",
    "# This parallel transfer is why dual-rail achieves ~2x throughput, not because it\n",
    "# moves more data, but because it moves the same data twice as fast.\n",
    "if tx1_diff > 1e9 and tx2_diff > 1e9:\n",
    "    print(\"✓ DUAL-RAIL CONFIRMED: Both links transferred significant data\")\n",
    "    print(f\"  Data split: {tx1_diff/(tx1_diff+tx2_diff)*100:.0f}% / {tx2_diff/(tx1_diff+tx2_diff)*100:.0f}% across links\")\n",
    "elif tx1_diff > 1e9 or tx2_diff > 1e9:\n",
    "    print(\"⚠ SINGLE-RAIL: Only one link was used\")\n",
    "else:\n",
    "    print(\"Note: RDMA counters may not be available. Check throughput in benchmark output above.\")\n",
    "\n",
    "dual_rail_dram_result = result + f\"\\n{DEVICE_1}: {tx1_diff/1e9:.2f} GB\\n{DEVICE_2}: {tx2_diff/1e9:.2f} GB\"\n",
    "# Store result for Part 8 summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb780bd",
   "metadata": {},
   "source": [
    "## Part 5: Single-Rail VRAM Benchmark (GPUDirect Baseline)\n",
    "\n",
    "Test GPU memory transfer over a single link using GPUDirect RDMA. This bypasses CPU entirely.\n",
    "\n",
    "**On spark-01 (run second, after starting the cell below on spark-02):**\n",
    "```bash\n",
    "/usr/local/nixlbench/bin/nixlbench --etcd_endpoints http://192.168.100.11:2379 \\\n",
    "  --backend UCX \\\n",
    "  --device_list rocep1s0f0 \\\n",
    "  --initiator_seg_type VRAM \\\n",
    "  --target_seg_type VRAM \\\n",
    "  --total_buffer_size 2147483648 \\\n",
    "  --start_block_size 65536 \\\n",
    "  --max_block_size 33554432 \\\n",
    "  --num_iter 1000 \\\n",
    "  --warmup_iter 100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d6347c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 3: Single-Rail VRAM (GPUDirect Baseline) ===\n",
      "Device: rocep1s0f0 only (--device_list limits to one device)\n",
      "Expected: ~96 Gbps (single 100G link, GPUDirect)\n",
      "\n",
      "GPUDirect RDMA: NIC reads/writes GPU memory directly, no CPU copies\n",
      "\n",
      "Before: rocep1s0f0 RDMA TX=1,199,387,391,872 bytes, rocep1s0f1 RDMA TX=426,006,158,936 bytes\n",
      "\n",
      "NOTE: Run this cell first, then run spark-01 command to see results\n",
      "\n",
      "Running benchmark...\n",
      "WARNING: Adjusting num_iter to 1008 to allow equal distribution to 1 threads\n",
      "WARNING: Adjusting warmup_iter to 112 to allow equal distribution to 1 threads\n",
      "Connecting to ETCD at http://192.168.100.11:2379\n",
      "ETCD Runtime: Registered as rank 0 item 1 of 2\n",
      "Init nixl worker, dev rocep1s0f0 rank 0, type initiator, hostname spark-02\n",
      "[1770145106.103720] [spark-02:1216709:0]      ucp_worker.c:2315 UCX  WARN  invalid configuration: RC_GDA_NUM_CHANNELS=4\n",
      "[1770145106.153681] [spark-02:1216709:0]      ucp_worker.c:2315 UCX  WARN  invalid configuration: RC_GDA_NUM_CHANNELS=4\n",
      "Waiting for all processes to start... (expecting 2 total: 1 initiators and 1 targets)\n",
      "All processes are ready to proceed\n",
      "****************************************************************************************************************************************************************\n",
      "NIXLBench Configuration\n",
      "****************************************************************************************************************************************************************\n",
      "Runtime (--runtime_type=[etcd])                             : ETCD\n",
      "ETCD Endpoint                                               : http://192.168.100.11:2379\n",
      "Worker type (--worker_type=[nixl,nvshmem])                  : nixl\n",
      "Backend (--backend=[UCX,GDS,GDS_MT,POSIX,Mooncake,HF3FS,OBJ]): UCX\n",
      "Enable pt (--enable_pt=[0,1])                               : 0\n",
      "Progress threads (--progress_threads=N)                     : 0\n",
      "Device list (--device_list=dev1,dev2,...)                   : rocep1s0f0\n",
      "Enable VMM (--enable_vmm=[0,1])                             : 0\n",
      "Initiator seg type (--initiator_seg_type=[DRAM,VRAM])       : VRAM\n",
      "Target seg type (--target_seg_type=[DRAM,VRAM])             : VRAM\n",
      "Scheme (--scheme=[pairwise,manytoone,onetomany,tp])         : pairwise\n",
      "Mode (--mode=[SG,MG])                                       : SG\n",
      "Op type (--op_type=[READ,WRITE])                            : WRITE\n",
      "Check consistency (--check_consistency=[0,1])               : 0\n",
      "Total buffer size (--total_buffer_size=N)                   : 2147483648\n",
      "Num initiator dev (--num_initiator_dev=N)                   : 1\n",
      "Num target dev (--num_target_dev=N)                         : 1\n",
      "Start block size (--start_block_size=N)                     : 65536\n",
      "Max block size (--max_block_size=N)                         : 33554432\n",
      "Start batch size (--start_batch_size=N)                     : 1\n",
      "Max batch size (--max_batch_size=N)                         : 1\n",
      "Num iter (--num_iter=N)                                     : 1008\n",
      "Warmup iter (--warmup_iter=N)                               : 112\n",
      "Large block iter factor (--large_blk_iter_ftr=N)            : 16\n",
      "Num threads (--num_threads=N)                               : 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Block Size (B)      Batch Size     B/W (GB/Sec)   Avg Lat. (us)  Avg Prep (us)  P99 Prep (us)  Avg Post (us)  P99 Post (us)  Avg Tx (us)    P99 Tx (us)    \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "65536               1              0.400915       163.5          16.0           16.0           144.2          161.0          19.3           80.0           \n",
      "131072              1              0.399808       327.8          15.0           15.0           309.6          1010.0         18.3           51.0           \n",
      "262144              1              0.323183       811.1          14.0           14.0           751.9          1989.0         59.2           135.0          \n",
      "524288              1              0.424651       1234.6         16.0           16.0           1069.7         1269.0         164.9          263.0          \n",
      "1048576             1              0.398107       2633.9         17.0           17.0           2288.7         3227.0         345.2          5964.0         \n",
      "2097152             1              0.374005       5607.3         8.0            8.0            5574.7         5813.0         32.4           1913.0         \n",
      "4194304             1              0.421615       9948.2         23.0           23.0           9768.7         14749.0        179.1          9119.0         \n",
      "8388608             1              0.605174       13861.5        16.0           16.0           12613.3        14576.0        1247.9         2751.0         \n",
      "16777216            1              0.601681       27883.9        17.0           17.0           24449.7        28753.0        3433.8         26222.0        \n",
      "33554432            1              0.443649       75632.9        15.0           15.0           52262.2        78912.0        23370.3        96151.0        \n",
      "\n",
      "\n",
      "=== Link Utilization Verification (RDMA counters) ===\n",
      "rocep1s0f0: 7.32 GB transmitted via RDMA (GPUDirect)\n",
      "rocep1s0f1: 0.00 GB transmitted via RDMA (GPUDirect)\n",
      "Total: 7.32 GB\n",
      "\n",
      "✓ SINGLE-RAIL CONFIRMED: Only rocep1s0f0 was used\n",
      "  All GPU data traversed a single 100G link via GPUDirect.\n"
     ]
    }
   ],
   "source": [
    "# Single-Rail VRAM benchmark with GPUDirect RDMA\n",
    "# 2GiB = 2147483648, 64KiB = 65536, 32MiB = 33554432\n",
    "\n",
    "print(\"=== Test 3: Single-Rail VRAM (GPUDirect Baseline) ===\")\n",
    "print(f\"Device: {DEVICE_1} only (--device_list limits to one device)\")\n",
    "print(f\"Expected: ~96 Gbps (single 100G link, GPUDirect)\")\n",
    "print()\n",
    "print(\"GPUDirect RDMA: NIC reads/writes GPU memory directly, no CPU copies\")\n",
    "print()\n",
    "\n",
    "# Get RDMA stats before\n",
    "tx1_before = get_rdma_stats(DEVICE_1)\n",
    "tx2_before = get_rdma_stats(DEVICE_2)\n",
    "print(f\"Before: {DEVICE_1} RDMA TX={tx1_before:,} bytes, {DEVICE_2} RDMA TX={tx2_before:,} bytes\")\n",
    "\n",
    "single_rail_vram_cmd = f\"\"\"{NIXLBENCH} \\\n",
    "  --etcd_endpoints http://{ETCD_IP}:2379 \\\n",
    "  --backend UCX \\\n",
    "  --device_list {DEVICE_1} \\\n",
    "  --initiator_seg_type VRAM \\\n",
    "  --target_seg_type VRAM \\\n",
    "  --total_buffer_size 2147483648 \\\n",
    "  --start_block_size 65536 \\\n",
    "  --max_block_size 33554432 \\\n",
    "  --num_iter 1000 \\\n",
    "  --warmup_iter 100\"\"\"\n",
    "\n",
    "print()\n",
    "print(\"NOTE: Run this cell first, then run spark-01 command to see results\")\n",
    "print()\n",
    "\n",
    "# Execute the benchmark\n",
    "print(\"Running benchmark...\")\n",
    "result = run_cmd(single_rail_vram_cmd, timeout=300)\n",
    "print(result)\n",
    "\n",
    "# Get RDMA stats after\n",
    "tx1_after = get_rdma_stats(DEVICE_1)\n",
    "tx2_after = get_rdma_stats(DEVICE_2)\n",
    "\n",
    "# Calculate bytes transferred on each link\n",
    "tx1_diff = tx1_after - tx1_before\n",
    "tx2_diff = tx2_after - tx2_before\n",
    "\n",
    "print()\n",
    "print(\"=== Link Utilization Verification (RDMA counters) ===\")\n",
    "print(f\"{DEVICE_1}: {tx1_diff/1e9:.2f} GB transmitted via RDMA (GPUDirect)\")\n",
    "print(f\"{DEVICE_2}: {tx2_diff/1e9:.2f} GB transmitted via RDMA (GPUDirect)\")\n",
    "print(f\"Total: {(tx1_diff + tx2_diff)/1e9:.2f} GB\")\n",
    "print()\n",
    "# Note: Single-rail and dual-rail transfer the SAME total bytes. The difference:\n",
    "#   - Single-rail: 100% through one link (limited to ~96 Gbps)\n",
    "#   - Dual-rail: ~50% each link (achieves ~180 Gbps aggregate)\n",
    "# GPUDirect means the NIC reads/writes GPU memory directly. The RDMA counters\n",
    "# measure the same data whether it originates from DRAM or VRAM.\n",
    "if tx1_diff > 1e9 and tx2_diff < 1e8:\n",
    "    print(\"✓ SINGLE-RAIL CONFIRMED: Only\", DEVICE_1, \"was used\")\n",
    "    print(\"  All GPU data traversed a single 100G link via GPUDirect.\")\n",
    "elif tx1_diff > 1e9 and tx2_diff > 1e9:\n",
    "    print(\"⚠ Both links used (unexpected for single-rail test)\")\n",
    "else:\n",
    "    print(\"Note: RDMA counters may not be available. Check throughput in benchmark output above.\")\n",
    "\n",
    "single_rail_vram_result = result + f\"\\n{DEVICE_1}: {tx1_diff/1e9:.2f} GB\\n{DEVICE_2}: {tx2_diff/1e9:.2f} GB\"\n",
    "# Store result for Part 8 summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1525a6",
   "metadata": {},
   "source": [
    "## Part 6: Dual-Rail VRAM Benchmark (GPUDirect Multi-Rail)\n",
    "\n",
    "Test GPU memory transfer over both 100G links with GPUDirect RDMA.\n",
    "\n",
    "**Note on DGX Spark:** This test typically shows only one link being used despite dual-rail configuration. Possible explanations:\n",
    "\n",
    "1. **Bounce buffer bottleneck**: On DGX Spark, GPU memory transfers require staging through host memory (`cuda_copy`). This ~4 Gbps bottleneck is far below a single 100G link's capacity, so UCX sees no benefit in striping across two links.\n",
    "\n",
    "2. **Memory registration topology**: GPU memory may only be efficiently accessible from one NIC due to PCIe/NVLink topology. UCX selects the optimal path rather than forcing suboptimal multi-rail.\n",
    "\n",
    "3. **Transport selection**: UCX may determine that `cuda_copy` + single RDMA link is faster than coordinating two links when the GPU-to-host copy dominates transfer time.\n",
    "\n",
    "This confirms that dual-rail provides no benefit for GPU memory on architectures without true GPUDirect RDMA support.\n",
    "\n",
    "**On spark-01 (run second, after starting the cell below on spark-02):**\n",
    "```bash\n",
    "UCX_TLS=rc,cuda_copy,cuda_ipc UCX_NET_DEVICES=all \\\n",
    "UCX_MAX_RNDV_LANES=2 UCX_MAX_EAGER_LANES=2 \\\n",
    "/usr/local/nixlbench/bin/nixlbench --etcd_endpoints http://192.168.100.11:2379 \\\n",
    "  --backend UCX \\\n",
    "  --initiator_seg_type VRAM \\\n",
    "  --target_seg_type VRAM \\\n",
    "  --total_buffer_size 2147483648 \\\n",
    "  --start_block_size 65536 \\\n",
    "  --max_block_size 33554432 \\\n",
    "  --num_iter 1000 \\\n",
    "  --warmup_iter 100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcafdab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 4: Dual-Rail VRAM (GPUDirect Multi-Rail) ===\n",
      "Expected: ~180 Gbps (2x 100G links, GPUDirect)\n",
      "\n",
      "GPUDirect RDMA: NIC reads/writes GPU memory directly, no CPU copies\n",
      "\n",
      "Before: rocep1s0f0 RDMA TX=1,206,711,816,176 bytes, rocep1s0f1 RDMA TX=426,006,158,936 bytes\n",
      "\n",
      "NOTE: Run this cell first, then run spark-01 command to see results\n",
      "\n",
      "Running benchmark...\n",
      "WARNING: Adjusting num_iter to 1008 to allow equal distribution to 1 threads\n",
      "WARNING: Adjusting warmup_iter to 112 to allow equal distribution to 1 threads\n",
      "Connecting to ETCD at http://192.168.100.11:2379\n",
      "ETCD Runtime: Registered as rank 0 item 1 of 2\n",
      "Init nixl worker, dev all rank 0, type initiator, hostname spark-02\n",
      "[1770145610.760262] [spark-02:1216869:0]      ucp_worker.c:2315 UCX  WARN  invalid configuration: RC_GDA_NUM_CHANNELS=4\n",
      "[1770145610.829346] [spark-02:1216869:0]      ucp_worker.c:2315 UCX  WARN  invalid configuration: RC_GDA_NUM_CHANNELS=4\n",
      "Waiting for all processes to start... (expecting 2 total: 1 initiators and 1 targets)\n",
      "All processes are ready to proceed\n",
      "****************************************************************************************************************************************************************\n",
      "NIXLBench Configuration\n",
      "****************************************************************************************************************************************************************\n",
      "Runtime (--runtime_type=[etcd])                             : ETCD\n",
      "ETCD Endpoint                                               : http://192.168.100.11:2379\n",
      "Worker type (--worker_type=[nixl,nvshmem])                  : nixl\n",
      "Backend (--backend=[UCX,GDS,GDS_MT,POSIX,Mooncake,HF3FS,OBJ]): UCX\n",
      "Enable pt (--enable_pt=[0,1])                               : 0\n",
      "Progress threads (--progress_threads=N)                     : 0\n",
      "Device list (--device_list=dev1,dev2,...)                   : all\n",
      "Enable VMM (--enable_vmm=[0,1])                             : 0\n",
      "Initiator seg type (--initiator_seg_type=[DRAM,VRAM])       : VRAM\n",
      "Target seg type (--target_seg_type=[DRAM,VRAM])             : VRAM\n",
      "Scheme (--scheme=[pairwise,manytoone,onetomany,tp])         : pairwise\n",
      "Mode (--mode=[SG,MG])                                       : SG\n",
      "Op type (--op_type=[READ,WRITE])                            : WRITE\n",
      "Check consistency (--check_consistency=[0,1])               : 0\n",
      "Total buffer size (--total_buffer_size=N)                   : 2147483648\n",
      "Num initiator dev (--num_initiator_dev=N)                   : 1\n",
      "Num target dev (--num_target_dev=N)                         : 1\n",
      "Start block size (--start_block_size=N)                     : 65536\n",
      "Max block size (--max_block_size=N)                         : 33554432\n",
      "Start batch size (--start_batch_size=N)                     : 1\n",
      "Max batch size (--max_batch_size=N)                         : 1\n",
      "Num iter (--num_iter=N)                                     : 1008\n",
      "Warmup iter (--warmup_iter=N)                               : 112\n",
      "Large block iter factor (--large_blk_iter_ftr=N)            : 16\n",
      "Num threads (--num_threads=N)                               : 1\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Block Size (B)      Batch Size     B/W (GB/Sec)   Avg Lat. (us)  Avg Prep (us)  P99 Prep (us)  Avg Post (us)  P99 Post (us)  Avg Tx (us)    P99 Tx (us)    \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "65536               1              0.431645       151.8          7.0            7.0            126.1          155.0          25.7           109.0          \n",
      "131072              1              0.463236       282.9          14.0           14.0           235.5          249.0          47.4           139.0          \n",
      "262144              1              0.446988       586.5          15.0           15.0           388.5          626.0          198.0          1888.0         \n",
      "524288              1              0.437064       1199.6         8.0            8.0            958.3          1176.0         241.3          3553.0         \n",
      "1048576             1              0.452907       2315.2         16.0           16.0           1921.5         2649.0         393.7          6077.0         \n",
      "2097152             1              0.257849       8133.3         18.0           18.0           4629.0         6966.0         3503.9         58638.0        \n",
      "4194304             1              0.580719       7222.6         14.0           14.0           6422.6         6861.0         799.7          2861.0         \n",
      "8388608             1              0.460928       18199.4        13.0           13.0           12624.2        19018.0        5574.8         69672.0        \n",
      "16777216            1              0.574341       29211.3        14.0           14.0           24039.0        28825.0        5172.0         31102.0        \n",
      "33554432            1              0.434086       77299.0        17.0           17.0           76626.8        90061.0        671.8          22105.0        \n",
      "\n",
      "\n",
      "=== Link Utilization Verification (RDMA counters) ===\n",
      "rocep1s0f0: 7.33 GB transmitted via RDMA (GPUDirect)\n",
      "rocep1s0f1: 0.00 GB transmitted via RDMA (GPUDirect)\n",
      "Total: 7.33 GB\n",
      "\n",
      "⚠ SINGLE-RAIL: Only one link was used\n"
     ]
    }
   ],
   "source": [
    "# Dual-Rail VRAM benchmark with GPUDirect RDMA\n",
    "# Omit --device_list to let UCX auto-select all available RoCE devices\n",
    "#\n",
    "# UCX environment variables for multi-rail GPUDirect:\n",
    "#   UCX_TLS=rc,cuda_copy,cuda_ipc - Enable RC transport with CUDA memory support\n",
    "#   UCX_NET_DEVICES=all - Use all available network devices\n",
    "#   UCX_MAX_RNDV_LANES=2 - Use 2 lanes for rendezvous (large transfers)\n",
    "#   UCX_MAX_EAGER_LANES=2 - Use 2 lanes for eager (small transfers)\n",
    "\n",
    "print(\"=== Test 4: Dual-Rail VRAM (GPUDirect Multi-Rail) ===\")\n",
    "print(f\"Expected: ~180 Gbps (2x 100G links, GPUDirect)\")\n",
    "print()\n",
    "print(\"GPUDirect RDMA: NIC reads/writes GPU memory directly, no CPU copies\")\n",
    "print()\n",
    "\n",
    "# Get RDMA stats before\n",
    "tx1_before = get_rdma_stats(DEVICE_1)\n",
    "tx2_before = get_rdma_stats(DEVICE_2)\n",
    "print(f\"Before: {DEVICE_1} RDMA TX={tx1_before:,} bytes, {DEVICE_2} RDMA TX={tx2_before:,} bytes\")\n",
    "\n",
    "# Set UCX environment for multi-rail GPUDirect\n",
    "ucx_env = \"UCX_TLS=rc,cuda_copy,cuda_ipc UCX_NET_DEVICES=all UCX_MAX_RNDV_LANES=2 UCX_MAX_EAGER_LANES=2\"\n",
    "\n",
    "dual_rail_vram_cmd = f\"\"\"{ucx_env} {NIXLBENCH} \\\n",
    "  --etcd_endpoints http://{ETCD_IP}:2379 \\\n",
    "  --backend UCX \\\n",
    "  --initiator_seg_type VRAM \\\n",
    "  --target_seg_type VRAM \\\n",
    "  --total_buffer_size 2147483648 \\\n",
    "  --start_block_size 65536 \\\n",
    "  --max_block_size 33554432 \\\n",
    "  --num_iter 1000 \\\n",
    "  --warmup_iter 100\"\"\"\n",
    "\n",
    "print()\n",
    "print(\"NOTE: Run this cell first, then run spark-01 command to see results\")\n",
    "print()\n",
    "\n",
    "# Execute the benchmark\n",
    "print(\"Running benchmark...\")\n",
    "result = run_cmd(dual_rail_vram_cmd, timeout=300)\n",
    "print(result)\n",
    "\n",
    "# Get RDMA stats after\n",
    "tx1_after = get_rdma_stats(DEVICE_1)\n",
    "tx2_after = get_rdma_stats(DEVICE_2)\n",
    "\n",
    "# Calculate bytes transferred on each link\n",
    "tx1_diff = tx1_after - tx1_before\n",
    "tx2_diff = tx2_after - tx2_before\n",
    "\n",
    "print()\n",
    "print(\"=== Link Utilization Verification (RDMA counters) ===\")\n",
    "print(f\"{DEVICE_1}: {tx1_diff/1e9:.2f} GB transmitted via RDMA (GPUDirect)\")\n",
    "print(f\"{DEVICE_2}: {tx2_diff/1e9:.2f} GB transmitted via RDMA (GPUDirect)\")\n",
    "print(f\"Total: {(tx1_diff + tx2_diff)/1e9:.2f} GB\")\n",
    "print()\n",
    "# Note: Total bytes is similar to single-rail VRAM test. The speedup comes from parallelism:\n",
    "# UCX stripes data across both NICs, each reading from GPU memory via GPUDirect.\n",
    "# Same data volume, but transferred in half the time.\n",
    "if tx1_diff > 1e9 and tx2_diff > 1e9:\n",
    "    print(\"✓ DUAL-RAIL CONFIRMED: Both links transferred significant data\")\n",
    "    print(f\"  Data split: {tx1_diff/(tx1_diff+tx2_diff)*100:.0f}% / {tx2_diff/(tx1_diff+tx2_diff)*100:.0f}% across links\")\n",
    "    print(\"  Both NICs read GPU memory directly via GPUDirect RDMA.\")\n",
    "elif tx1_diff > 1e9 or tx2_diff > 1e9:\n",
    "    print(\"⚠ SINGLE-RAIL: Only one link was used\")\n",
    "else:\n",
    "    print(\"Note: RDMA counters may not be available. Check throughput in benchmark output above.\")\n",
    "\n",
    "dual_rail_vram_result = result + f\"\\n{DEVICE_1}: {tx1_diff/1e9:.2f} GB\\n{DEVICE_2}: {tx2_diff/1e9:.2f} GB\"\n",
    "# Store result for Part 8 summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f6e72",
   "metadata": {},
   "source": [
    "## Part 7: Multi-Threaded Tests (Progress Threads)\n",
    "\n",
    "NIXL supports progress threads to overlap transfer operations. This improves throughput for production workloads.\n",
    "\n",
    "**On spark-01 (run second, after starting the cell below on spark-02):**\n",
    "```bash\n",
    "/usr/local/nixlbench/bin/nixlbench --etcd_endpoints http://192.168.100.11:2379 \\\n",
    "  --backend UCX \\\n",
    "  --initiator_seg_type DRAM \\\n",
    "  --target_seg_type DRAM \\\n",
    "  --total_buffer_size 4294967296 \\\n",
    "  --start_block_size 65536 \\\n",
    "  --max_block_size 67108864 \\\n",
    "  --num_threads 4 \\\n",
    "  --enable_pt \\\n",
    "  --progress_threads 2 \\\n",
    "  --num_iter 1000 \\\n",
    "  --warmup_iter 100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear ETCD state before running Test 5\n",
    "# Required if previous test timed out or failed, leaving stale worker registrations\n",
    "# ETCD stores worker rank assignments; stale entries cause \"Rank X >= global size\" errors\n",
    "\n",
    "print(\"Clearing ETCD state...\")\n",
    "clear_result = run_cmd('docker exec nixl-etcd etcdctl del \"xferbench\" --prefix')\n",
    "print(f\"Cleared: {clear_result.strip() or 'OK'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0dc04da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 5: Dual-Rail DRAM with Progress Threads ===\n",
      "Devices: rocep1s0f0,rocep1s0f1\n",
      "Threads: 4 workers, 2 progress threads\n",
      "Expected: ~176+ Gbps (saturated dual links)\n",
      "\n",
      "Before: rocep1s0f0 RDMA TX=1,238,743,298,548 bytes, rocep1s0f1 RDMA TX=438,530,827,352 bytes\n",
      "\n",
      "NOTE: Run this cell first, then run spark-01 command to see results\n",
      "\n",
      "Running benchmark...\n",
      "Command timed out\n",
      "\n",
      "=== Link Utilization Verification (RDMA counters) ===\n",
      "rocep1s0f0: 3.71 GB transmitted via RDMA\n",
      "rocep1s0f1: 3.71 GB transmitted via RDMA\n",
      "Total: 7.42 GB\n",
      "\n",
      "✓ DUAL-RAIL CONFIRMED: Both links transferred significant data\n",
      "  Data split: 50% / 50% across links\n",
      "  Progress threads enabled for overlapped communication.\n"
     ]
    }
   ],
   "source": [
    "# Multi-threaded dual-rail benchmark with progress threads\n",
    "# Progress threads overlap communication with computation for better throughput\n",
    "\n",
    "print(\"=== Test 5: Dual-Rail DRAM with Progress Threads ===\")\n",
    "print(f\"Devices: {DEVICE_1},{DEVICE_2}\")\n",
    "print(f\"Threads: 4 workers, 2 progress threads\")\n",
    "print(f\"Expected: ~176+ Gbps (saturated dual links)\")\n",
    "print()\n",
    "\n",
    "# Get RDMA stats before\n",
    "tx1_before = get_rdma_stats(DEVICE_1)\n",
    "tx2_before = get_rdma_stats(DEVICE_2)\n",
    "print(f\"Before: {DEVICE_1} RDMA TX={tx1_before:,} bytes, {DEVICE_2} RDMA TX={tx2_before:,} bytes\")\n",
    "\n",
    "dual_rail_mt_cmd = f\"\"\"{NIXLBENCH} \\\n",
    "  --etcd_endpoints http://{ETCD_IP}:2379 \\\n",
    "  --backend UCX \\\n",
    "  --initiator_seg_type DRAM \\\n",
    "  --target_seg_type DRAM \\\n",
    "  --total_buffer_size 4294967296 \\\n",
    "  --start_block_size 65536 \\\n",
    "  --max_block_size 67108864 \\\n",
    "  --num_threads 4 \\\n",
    "  --enable_pt \\\n",
    "  --progress_threads 2 \\\n",
    "  --num_iter 1000 \\\n",
    "  --warmup_iter 100\"\"\"\n",
    "\n",
    "print()\n",
    "print(\"NOTE: Run this cell first, then run spark-01 command to see results\")\n",
    "print()\n",
    "\n",
    "# Execute the benchmark\n",
    "print(\"Running benchmark...\")\n",
    "result = run_cmd(dual_rail_mt_cmd, timeout=300)\n",
    "print(result)\n",
    "\n",
    "# Get RDMA stats after\n",
    "tx1_after = get_rdma_stats(DEVICE_1)\n",
    "tx2_after = get_rdma_stats(DEVICE_2)\n",
    "\n",
    "# Calculate bytes transferred on each link\n",
    "tx1_diff = tx1_after - tx1_before\n",
    "tx2_diff = tx2_after - tx2_before\n",
    "\n",
    "print()\n",
    "print(\"=== Link Utilization Verification (RDMA counters) ===\")\n",
    "print(f\"{DEVICE_1}: {tx1_diff/1e9:.2f} GB transmitted via RDMA\")\n",
    "print(f\"{DEVICE_2}: {tx2_diff/1e9:.2f} GB transmitted via RDMA\")\n",
    "print(f\"Total: {(tx1_diff + tx2_diff)/1e9:.2f} GB\")\n",
    "print()\n",
    "# Note: Total bytes is similar to dual-rail DRAM test. Progress threads improve\n",
    "# throughput by overlapping communication with computation, not by transferring more data.\n",
    "# With 4 worker threads and 2 progress threads, the benchmark can better saturate both links.\n",
    "if tx1_diff > 1e9 and tx2_diff > 1e9:\n",
    "    print(\"✓ DUAL-RAIL CONFIRMED: Both links transferred significant data\")\n",
    "    print(f\"  Data split: {tx1_diff/(tx1_diff+tx2_diff)*100:.0f}% / {tx2_diff/(tx1_diff+tx2_diff)*100:.0f}% across links\")\n",
    "    print(\"  Progress threads enabled for overlapped communication.\")\n",
    "elif tx1_diff > 1e9 or tx2_diff > 1e9:\n",
    "    print(\"⚠ SINGLE-RAIL: Only one link was used\")\n",
    "else:\n",
    "    print(\"Note: RDMA counters may not be available. Check throughput in benchmark output above.\")\n",
    "\n",
    "dual_rail_mt_result = result + f\"\\n{DEVICE_1}: {tx1_diff/1e9:.2f} GB\\n{DEVICE_2}: {tx2_diff/1e9:.2f} GB\"\n",
    "# Store result for Part 8 summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa747d",
   "metadata": {},
   "source": [
    "## Part 8: Results Summary\n",
    "\n",
    "Run the cell below after completing all benchmark tests to capture and display results.\n",
    "\n",
    "The cell parses the benchmark outputs stored in kernel variables from each test execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0f637e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "NIXL Benchmark Results Summary\n",
      "==========================================================================================\n",
      "\n",
      "Test                      Rails  Memory BW (Gbps)    Latency (μs)   Link 1 (GB)  Link 2 (GB) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "1. Single-Rail DRAM       1      DRAM   92.5         5803.6         12.18        ---         \n",
      "2. Dual-Rail DRAM         2      DRAM   105.4        5094.1         6.09         6.09        \n",
      "3. Single-Rail VRAM       1      VRAM   3.5          75632.9        7.32         ---         \n",
      "4. Dual-Rail VRAM         2      VRAM   3.5          77299.0        7.33         ---         \n",
      "5. Dual-Rail MT           2      DRAM   ---          ---            3.71         3.71        \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "Notes:\n",
      "  - BW (Gbps): Peak bandwidth at largest block size (67MB for DRAM, 32MB for VRAM)\n",
      "  - Latency: Average latency at largest block size\n",
      "  - Link 1/2: RDMA bytes transmitted per link (verifies single vs dual rail)\n",
      "\n",
      "Expected Results:\n",
      "  - Single-Rail: ~92 Gbps (limited by single 100G link)\n",
      "  - Dual-Rail: ~176 Gbps (aggregated across two 100G links)\n",
      "  - Link utilization: Single-rail uses one link; Dual-rail splits ~50/50\n"
     ]
    }
   ],
   "source": [
    "# Parse benchmark results from notebook cell outputs (no need to re-run benchmarks)\n",
    "import json\n",
    "import re\n",
    "\n",
    "def parse_nixlbench_output(output):\n",
    "    \"\"\"Extract peak bandwidth and latency from nixlbench output.\"\"\"\n",
    "    results = {\n",
    "        'bandwidth_gbps': None,\n",
    "        'latency_us': None,\n",
    "        'block_size': None\n",
    "    }\n",
    "    \n",
    "    # Find all bandwidth/latency lines (skip header)\n",
    "    # Format: Block Size, Batch Size, B/W (GB/Sec), Avg Lat. (us), ...\n",
    "    pattern = r'(\\d+)\\s+1\\s+([\\d.]+)\\s+([\\d.]+)'\n",
    "    matches = re.findall(pattern, output)\n",
    "    \n",
    "    if matches:\n",
    "        # Get the largest block size result (best bandwidth)\n",
    "        last_match = matches[-1]\n",
    "        block_size = int(last_match[0])\n",
    "        bw_gbsec = float(last_match[1])\n",
    "        latency_us = float(last_match[2])\n",
    "        \n",
    "        # Convert GB/sec to Gbps (multiply by 8)\n",
    "        results['bandwidth_gbps'] = bw_gbsec * 8\n",
    "        results['latency_us'] = latency_us\n",
    "        results['block_size'] = block_size\n",
    "    \n",
    "    return results\n",
    "\n",
    "def parse_link_utilization(output):\n",
    "    \"\"\"Extract RDMA bytes transferred per link.\"\"\"\n",
    "    link1_gb = 0.0\n",
    "    link2_gb = 0.0\n",
    "    \n",
    "    # Pattern: rocep1s0f0: X.XX GB transmitted\n",
    "    match1 = re.search(r'rocep1s0f0:\\s+([\\d.]+)\\s+GB', output)\n",
    "    match2 = re.search(r'rocep1s0f1:\\s+([\\d.]+)\\s+GB', output)\n",
    "    \n",
    "    if match1:\n",
    "        link1_gb = float(match1.group(1))\n",
    "    if match2:\n",
    "        link2_gb = float(match2.group(1))\n",
    "    \n",
    "    return link1_gb, link2_gb\n",
    "\n",
    "def get_cell_outputs_from_notebook(notebook_path):\n",
    "    \"\"\"Read cell outputs directly from the notebook file.\"\"\"\n",
    "    with open(notebook_path, 'r') as f:\n",
    "        nb = json.load(f)\n",
    "    \n",
    "    outputs = {}\n",
    "    for cell in nb.get('cells', []):\n",
    "        if cell.get('cell_type') == 'code':\n",
    "            cell_output = ''\n",
    "            \n",
    "            for output in cell.get('outputs', []):\n",
    "                if output.get('output_type') == 'stream':\n",
    "                    cell_output += ''.join(output.get('text', []))\n",
    "            \n",
    "            # Only match cells that actually ran benchmarks\n",
    "            # Require either benchmark data table OR \"Running benchmark\" (for timed out tests)\n",
    "            if 'B/W (GB/Sec)' not in cell_output and 'Running benchmark' not in cell_output:\n",
    "                continue\n",
    "            \n",
    "            # Identify which test this cell ran based on output\n",
    "            if 'Test 1: Single-Rail DRAM' in cell_output:\n",
    "                outputs['single_rail_dram'] = cell_output\n",
    "            elif 'Test 2: Dual-Rail DRAM' in cell_output:\n",
    "                outputs['dual_rail_dram'] = cell_output\n",
    "            elif 'Test 3: Single-Rail VRAM' in cell_output:\n",
    "                outputs['single_rail_vram'] = cell_output\n",
    "            elif 'Test 4: Dual-Rail VRAM' in cell_output:\n",
    "                outputs['dual_rail_vram'] = cell_output\n",
    "            elif 'Test 5:' in cell_output:\n",
    "                outputs['dual_rail_mt'] = cell_output\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "# Read outputs from the notebook file itself\n",
    "import os\n",
    "notebook_path = os.path.join(os.getcwd(), 'infiniband-tutorial', '03_NixlBench.ipynb')\n",
    "if not os.path.exists(notebook_path):\n",
    "    # Try current directory\n",
    "    notebook_path = '03_NixlBench.ipynb'\n",
    "if not os.path.exists(notebook_path):\n",
    "    # Try absolute path\n",
    "    notebook_path = '/home/nvidia/src/github.com/elizabetht/spark/infiniband-tutorial/03_NixlBench.ipynb'\n",
    "\n",
    "cell_outputs = get_cell_outputs_from_notebook(notebook_path)\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"NIXL Benchmark Results Summary\")\n",
    "print(\"=\" * 90)\n",
    "print()\n",
    "\n",
    "# Display table header\n",
    "print(f\"{'Test':<25} {'Rails':<6} {'Memory':<6} {'BW (Gbps)':<12} {'Latency (μs)':<14} {'Link 1 (GB)':<12} {'Link 2 (GB)':<12}\")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "# Define test configurations\n",
    "tests = [\n",
    "    ('1. Single-Rail DRAM', 1, 'DRAM', 'single_rail_dram'),\n",
    "    ('2. Dual-Rail DRAM', 2, 'DRAM', 'dual_rail_dram'),\n",
    "    ('3. Single-Rail VRAM', 1, 'VRAM', 'single_rail_vram'),\n",
    "    ('4. Dual-Rail VRAM', 2, 'VRAM', 'dual_rail_vram'),\n",
    "    ('5. Dual-Rail MT', 2, 'DRAM', 'dual_rail_mt'),\n",
    "]\n",
    "\n",
    "# Parse and display results\n",
    "for test_name, rails, memory, key in tests:\n",
    "    output = cell_outputs.get(key, '')\n",
    "    if output:\n",
    "        parsed = parse_nixlbench_output(output)\n",
    "        link1, link2 = parse_link_utilization(output)\n",
    "        \n",
    "        bw = f\"{parsed['bandwidth_gbps']:.1f}\" if parsed['bandwidth_gbps'] else \"---\"\n",
    "        lat = f\"{parsed['latency_us']:.1f}\" if parsed['latency_us'] else \"---\"\n",
    "        l1 = f\"{link1:.2f}\" if link1 > 0 else \"---\"\n",
    "        l2 = f\"{link2:.2f}\" if link2 > 0 else \"---\"\n",
    "        \n",
    "        print(f\"{test_name:<25} {rails:<6} {memory:<6} {bw:<12} {lat:<14} {l1:<12} {l2:<12}\")\n",
    "    else:\n",
    "        print(f\"{test_name:<25} {rails:<6} {memory:<6} {'(not run)':<12} {'(not run)':<14} {'---':<12} {'---':<12}\")\n",
    "\n",
    "print(\"-\" * 95)\n",
    "print()\n",
    "print(\"Notes:\")\n",
    "print(\"  - BW (Gbps): Peak bandwidth at largest block size (67MB for DRAM, 32MB for VRAM)\")\n",
    "print(\"  - Latency: Average latency at largest block size\")\n",
    "print(\"  - Link 1/2: RDMA bytes transmitted per link (verifies single vs dual rail)\")\n",
    "print()\n",
    "print(\"Expected Results:\")\n",
    "print(\"  - Single-Rail: ~92 Gbps (limited by single 100G link)\")\n",
    "print(\"  - Dual-Rail: ~176 Gbps (aggregated across two 100G links)\")\n",
    "print(\"  - Link utilization: Single-rail uses one link; Dual-rail splits ~50/50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup between tests\n",
    "\n",
    "print(\"=== Cleanup ===\")\n",
    "print()\n",
    "print(\"Clear ETCD state (if nixlbench failed or timed out):\")\n",
    "clear_result = run_cmd('docker exec nixl-etcd etcdctl del \"xferbench\" --prefix')\n",
    "print(f\"  Cleared: {clear_result.strip()}\")\n",
    "print()\n",
    "print(\"Stop ETCD container (optional):\")\n",
    "print(\"  docker stop nixl-etcd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caefd26",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "**Single-Rail vs Dual-Rail:**\n",
    "- Single 100G link: ~96 Gbps maximum\n",
    "- Dual 100G links with NIXL: ~176 Gbps (1.8x improvement)\n",
    "- UCX handles multi-rail load balancing automatically\n",
    "\n",
    "**DRAM vs VRAM:**\n",
    "- DRAM transfers involve CPU memory allocation\n",
    "- VRAM transfers use GPUDirect RDMA (NIC accesses GPU memory directly)\n",
    "- Both achieve similar throughput, VRAM may have lower latency\n",
    "\n",
    "**Why NIXL outperforms bonding:**\n",
    "- Direct RDMA bypasses kernel networking stack\n",
    "- UCX multi-rail striping across both links\n",
    "- No TCP/IP protocol overhead\n",
    "- GPUDirect eliminates CPU copies for GPU workloads\n",
    "\n",
    "## References\n",
    "\n",
    "- [Multi-Rail Tutorial (02)](02_Multi_Rail_Tutorial.ipynb) - Network setup and bonding comparison\n",
    "- [InfiniBand Tutorial (01)](01_InfiniBand_Tutorial.ipynb) - RDMA basics and NCCL\n",
    "- [NIXL GitHub Repository](https://github.com/ai-dynamo/nixl)\n",
    "- [NIXLBench Documentation](https://github.com/ai-dynamo/nixl/tree/main/benchmark/nixlbench)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
