{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f166f6d5",
   "metadata": {},
   "source": [
    "# MicroK8s Cluster Setup: CPU Controller + DGX Spark Nodes\n",
    "\n",
    "This tutorial walks through setting up a MicroK8s Kubernetes cluster with:\n",
    "\n",
    "| Node | Role | IP Address | Description |\n",
    "|------|------|------------|-------------|\n",
    "| controller | Control Plane | 192.168.1.75 | CPU-only node running K8s control plane |\n",
    "| spark-01 | Worker | 192.168.1.76 | DGX Spark with GPU |\n",
    "| spark-02 | Worker | 192.168.1.77 | DGX Spark with GPU |\n",
    "\n",
    "All nodes are connected via WiFi and have the `nvidia` user configured.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Ubuntu 22.04 or later on all nodes\n",
    "- SSH access from your workstation to all nodes\n",
    "- `nvidia` user with sudo privileges on all nodes\n",
    "- Network connectivity between all nodes (WiFi in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaceaaa8",
   "metadata": {},
   "source": [
    "## Step 1: Define Cluster Variables\n",
    "\n",
    "Store node information in environment variables for use throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0c767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controller: nvidia@192.168.1.75\n",
      "Spark-01:   nvidia@192.168.1.76\n",
      "Spark-02:   nvidia@192.168.1.77\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Cluster configuration\n",
    "CONTROLLER_IP = \"192.168.1.75\"\n",
    "SPARK01_IP = \"192.168.1.76\"\n",
    "SPARK02_IP = \"192.168.1.77\"\n",
    "SSH_USER = \"nvidia\"\n",
    "\n",
    "# Store as environment variables for shell commands\n",
    "os.environ[\"CONTROLLER_IP\"] = CONTROLLER_IP\n",
    "os.environ[\"SPARK01_IP\"] = SPARK01_IP\n",
    "os.environ[\"SPARK02_IP\"] = SPARK02_IP\n",
    "os.environ[\"SSH_USER\"] = SSH_USER\n",
    "\n",
    "print(f\"Controller: {SSH_USER}@{CONTROLLER_IP}\")\n",
    "print(f\"Spark-01:   {SSH_USER}@{SPARK01_IP}\")\n",
    "print(f\"Spark-02:   {SSH_USER}@{SPARK02_IP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d88ab",
   "metadata": {},
   "source": [
    "## Step 2: Test SSH Connectivity\n",
    "\n",
    "Verify SSH access to all nodes. Each command should return the hostname without prompting for a password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31836783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SSH to Controller (192.168.1.75)...\n",
      "controller\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"Testing SSH to Controller (192.168.1.75)...\"\n",
    "ssh -o ConnectTimeout=5 -o BatchMode=yes ${SSH_USER}@${CONTROLLER_IP} \"hostname\" 2>&1 || echo \"FAILED: Cannot connect to controller\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Testing SSH to Spark-01 (192.168.1.76)...\"\n",
    "ssh -o ConnectTimeout=5 -o BatchMode=yes ${SSH_USER}@${SPARK01_IP} \"hostname\" 2>&1 || echo \"FAILED: Cannot connect to spark-01\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Testing SSH to Spark-02 (192.168.1.77)...\"\n",
    "ssh -o ConnectTimeout=5 -o BatchMode=yes ${SSH_USER}@${SPARK02_IP} \"hostname\" 2>&1 || echo \"FAILED: Cannot connect to spark-02\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47333179",
   "metadata": {},
   "source": [
    "### Diagnosing SSH Environment\n",
    "\n",
    "The notebook kernel may run in a different environment than your terminal. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94173c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SSH Environment Check ===\n",
      "\n",
      "Running as user: nvidia\n",
      "Home directory: /home/nvidia\n",
      "\n",
      "SSH keys available:\n",
      "-rw------- 1 nvidia nvidia 411 Jan 22 23:30 /home/nvidia/.ssh/id_ed25519\n",
      "-rw-r--r-- 1 nvidia nvidia 103 Jan 22 23:30 /home/nvidia/.ssh/id_ed25519.pub\n",
      "-rw------- 1 nvidia nvidia 411 Jan 22 00:40 /home/nvidia/.ssh/id_ed25519_shared\n",
      "-rw-r--r-- 1 nvidia nvidia 100 Jan 22 00:40 /home/nvidia/.ssh/id_ed25519_shared.pub\n",
      "\n",
      "SSH agent status:\n",
      "SSH_AUTH_SOCK: NOT SET\n",
      "Could not open a connection to your authentication agent.\n",
      "No agent running or no keys loaded\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"=== SSH Environment Check ===\"\n",
    "echo \"\"\n",
    "echo \"Running as user: $(whoami)\"\n",
    "echo \"Home directory: $HOME\"\n",
    "echo \"\"\n",
    "echo \"SSH keys available:\"\n",
    "ls -la ~/.ssh/id_* 2>/dev/null || echo \"No SSH keys found in ~/.ssh/\"\n",
    "echo \"\"\n",
    "echo \"SSH agent status:\"\n",
    "echo \"SSH_AUTH_SOCK: ${SSH_AUTH_SOCK:-NOT SET}\"\n",
    "ssh-add -l 2>&1 || echo \"No agent running or no keys loaded\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5e071",
   "metadata": {},
   "source": [
    "### Fix: Set Up SSH Key-Based Authentication\n",
    "\n",
    "If SSH fails, you need to set up passwordless SSH. First, check if you have an SSH key:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad71f8f",
   "metadata": {},
   "source": [
    "**If no key exists**, run this cell to generate one (skip if you already have a key):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f86491",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Generate SSH key (only run if you don't have one)\n",
    "ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 -N \"\" -C \"microk8s-cluster\"\n",
    "echo \"Key generated:\"\n",
    "cat ~/.ssh/id_ed25519.pub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c277b4e",
   "metadata": {},
   "source": [
    "### Copy SSH Key to All Nodes\n",
    "\n",
    "Run `ssh-copy-id` for each node. This will prompt for the password once per node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe8e3f",
   "metadata": {},
   "source": [
    "**Run these commands in a terminal** (they require interactive password input):\n",
    "\n",
    "```bash\n",
    "# Copy to controller\n",
    "ssh-copy-id nvidia@192.168.1.75\n",
    "\n",
    "# Copy to spark-01\n",
    "ssh-copy-id nvidia@192.168.1.76\n",
    "\n",
    "# Copy to spark-02\n",
    "ssh-copy-id nvidia@192.168.1.77\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62637278",
   "metadata": {},
   "source": [
    "### Verify SSH Access\n",
    "\n",
    "After copying keys, re-run this test. All nodes should return their hostname without password prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75444ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing SSH Connectivity ===\n",
      "\n",
      "Controller (192.168.1.75):\n",
      "controller\n",
      "✓ SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"=== Testing SSH Connectivity ===\"\n",
    "echo \"\"\n",
    "\n",
    "echo \"Controller (192.168.1.75):\"\n",
    "ssh -o ConnectTimeout=5 -o BatchMode=yes nvidia@192.168.1.75 \"hostname\" && echo \"✓ SUCCESS\" || echo \"✗ FAILED\"\n",
    "echo \"\"\n",
    "\n",
    "echo \"Spark-01 (192.168.1.76):\"\n",
    "ssh -o ConnectTimeout=5 -o BatchMode=yes nvidia@192.168.1.76 \"hostname\" && echo \"✓ SUCCESS\" || echo \"✗ FAILED\"\n",
    "echo \"\"\n",
    "\n",
    "echo \"Spark-02 (192.168.1.77):\"\n",
    "ssh -o ConnectTimeout=5 -o BatchMode=yes nvidia@192.168.1.77 \"hostname\" && echo \"✓ SUCCESS\" || echo \"✗ FAILED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74102ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Install MicroK8s on All Nodes\n",
    "\n",
    "MicroK8s is a lightweight Kubernetes distribution from Canonical. We'll install it on all three nodes, then join the Spark nodes to the controller.\n",
    "\n",
    "**Architecture:**\n",
    "- Controller (192.168.1.75): Runs the Kubernetes control plane only\n",
    "- Spark-01 (192.168.1.76): Worker node with GPU\n",
    "- Spark-02 (192.168.1.77): Worker node with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa73344",
   "metadata": {},
   "source": [
    "### 3.1 Install MicroK8s on the Controller\n",
    "\n",
    "The controller runs the control plane (API server, scheduler, etcd). No GPU needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743963b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== Installing MicroK8s on Controller (192.168.1.75) ===\"\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "    # Install MicroK8s\n",
    "    sudo snap install microk8s --classic --channel=1.31/stable\n",
    "    \n",
    "    # Add user to microk8s group (avoids sudo for kubectl)\n",
    "    sudo usermod -a -G microk8s $USER\n",
    "    sudo chown -R $USER ~/.kube 2>/dev/null || mkdir -p ~/.kube\n",
    "    \n",
    "    # Wait for MicroK8s to be ready\n",
    "    sudo microk8s status --wait-ready\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"MicroK8s version:\"\n",
    "    sudo microk8s kubectl version --short 2>/dev/null || sudo microk8s kubectl version\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92165e6d",
   "metadata": {},
   "source": [
    "### 3.2 Install MicroK8s on Spark-01\n",
    "\n",
    "Worker node with GPU. Same installation, will join the cluster later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== Installing MicroK8s on Spark-01 (192.168.1.76) ===\"\n",
    "ssh nvidia@192.168.1.76 << 'EOF'\n",
    "    # Install MicroK8s\n",
    "    sudo snap install microk8s --classic --channel=1.31/stable\n",
    "    \n",
    "    # Add user to microk8s group\n",
    "    sudo usermod -a -G microk8s $USER\n",
    "    sudo chown -R $USER ~/.kube 2>/dev/null || mkdir -p ~/.kube\n",
    "    \n",
    "    # Wait for MicroK8s to be ready\n",
    "    sudo microk8s status --wait-ready\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"MicroK8s version:\"\n",
    "    sudo microk8s kubectl version --short 2>/dev/null || sudo microk8s kubectl version\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2b210f",
   "metadata": {},
   "source": [
    "### 3.3 Install MicroK8s on Spark-02\n",
    "\n",
    "Second GPU worker node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b693d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== Installing MicroK8s on Spark-02 (192.168.1.77) ===\"\n",
    "ssh nvidia@192.168.1.77 << 'EOF'\n",
    "    # Install MicroK8s\n",
    "    sudo snap install microk8s --classic --channel=1.31/stable\n",
    "    \n",
    "    # Add user to microk8s group\n",
    "    sudo usermod -a -G microk8s $USER\n",
    "    sudo chown -R $USER ~/.kube 2>/dev/null || mkdir -p ~/.kube\n",
    "    \n",
    "    # Wait for MicroK8s to be ready\n",
    "    sudo microk8s status --wait-ready\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"MicroK8s version:\"\n",
    "    sudo microk8s kubectl version --short 2>/dev/null || sudo microk8s kubectl version\n",
    "EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
