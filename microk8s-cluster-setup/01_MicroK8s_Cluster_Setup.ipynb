{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f166f6d5",
   "metadata": {},
   "source": [
    "# MicroK8s Cluster Setup: CPU Controller + DGX Spark Nodes\n",
    "\n",
    "This tutorial walks through setting up a MicroK8s Kubernetes cluster with:\n",
    "\n",
    "| Node | Role | IP Address | Description |\n",
    "|------|------|------------|-------------|\n",
    "| controller | Control Plane | 192.168.1.75 | CPU-only node running K8s control plane |\n",
    "| spark-01 | Worker | 192.168.1.76 | DGX Spark with GPU |\n",
    "| spark-02 | Worker | 192.168.1.77 | DGX Spark with GPU |\n",
    "\n",
    "All nodes are connected via WiFi and have the `nvidia` user configured.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Ubuntu 22.04 or later on all nodes\n",
    "- SSH access from your workstation to all nodes\n",
    "- `nvidia` user with sudo privileges on all nodes\n",
    "- Network connectivity between all nodes (WiFi in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaceaaa8",
   "metadata": {},
   "source": [
    "## Step 1: Define Cluster Variables\n",
    "\n",
    "Store node information in environment variables for use throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0c767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controller: nvidia@192.168.1.75\n",
      "Spark-01:   nvidia@192.168.1.76\n",
      "Spark-02:   nvidia@192.168.1.77\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Cluster configuration\n",
    "CONTROLLER_IP = \"192.168.1.75\"\n",
    "SPARK01_IP = \"192.168.1.76\"\n",
    "SPARK02_IP = \"192.168.1.77\"\n",
    "SSH_USER = \"nvidia\"\n",
    "\n",
    "# Store as environment variables for shell commands\n",
    "os.environ[\"CONTROLLER_IP\"] = CONTROLLER_IP\n",
    "os.environ[\"SPARK01_IP\"] = SPARK01_IP\n",
    "os.environ[\"SPARK02_IP\"] = SPARK02_IP\n",
    "os.environ[\"SSH_USER\"] = SSH_USER\n",
    "\n",
    "print(f\"Controller: {SSH_USER}@{CONTROLLER_IP}\")\n",
    "print(f\"Spark-01:   {SSH_USER}@{SPARK01_IP}\")\n",
    "print(f\"Spark-02:   {SSH_USER}@{SPARK02_IP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f6674",
   "metadata": {},
   "source": [
    "### Fix: Initialize SSH Agent in Kernel\n",
    "\n",
    "The Jupyter kernel runs in a separate process without access to your terminal's SSH agent. Run this cell once to start the agent and load your key within the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4a4506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSH_AUTH_SOCK=/tmp/ssh-ahxtl4IU5sgQ/agent.1337666\n",
      "SSH_AGENT_PID=1337667\n",
      "Identity added: /home/nvidia/.ssh/id_ed25519 (email2eliza@gmail.com)\n",
      "\n",
      "\n",
      "SSH agent environment saved to /tmp/ssh_agent_env.sh\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Start SSH agent and capture its output\n",
    "result = subprocess.run(\n",
    "    ['ssh-agent', '-s'],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Parse and set environment variables\n",
    "for line in result.stdout.split('\\n'):\n",
    "    if 'SSH_AUTH_SOCK' in line:\n",
    "        sock = line.split(';')[0].split('=')[1]\n",
    "        os.environ['SSH_AUTH_SOCK'] = sock\n",
    "        print(f\"SSH_AUTH_SOCK={sock}\")\n",
    "    elif 'SSH_AGENT_PID' in line:\n",
    "        pid = line.split(';')[0].split('=')[1]\n",
    "        os.environ['SSH_AGENT_PID'] = pid\n",
    "        print(f\"SSH_AGENT_PID={pid}\")\n",
    "\n",
    "# Add the SSH key\n",
    "add_result = subprocess.run(\n",
    "    ['ssh-add', os.path.expanduser('~/.ssh/id_ed25519')],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "print(add_result.stdout or add_result.stderr)\n",
    "\n",
    "# Write environment to a file that bash cells can source\n",
    "with open('/tmp/ssh_agent_env.sh', 'w') as f:\n",
    "    f.write(f'export SSH_AUTH_SOCK={os.environ[\"SSH_AUTH_SOCK\"]}\\n')\n",
    "    f.write(f'export SSH_AGENT_PID={os.environ[\"SSH_AGENT_PID\"]}\\n')\n",
    "print(\"\\nSSH agent environment saved to /tmp/ssh_agent_env.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d88ab",
   "metadata": {},
   "source": [
    "## Step 2: Test SSH Connectivity\n",
    "\n",
    "Verify SSH access to all nodes. Each command should return the hostname without prompting for a password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31836783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SSH to Controller (192.168.1.75)...\n",
      "controller\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Source the SSH agent environment\n",
    "source /tmp/ssh_agent_env.sh\n",
    "\n",
    "# Use StrictHostKeyChecking=accept-new to auto-accept new host keys\n",
    "SSH_OPTS=\"-o ConnectTimeout=5 -o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"Testing SSH to Controller (192.168.1.75)...\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.75 \"hostname\" 2>&1 || echo \"FAILED: Cannot connect to controller\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Testing SSH to Spark-01 (192.168.1.76)...\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.76 \"hostname\" 2>&1 || echo \"FAILED: Cannot connect to spark-01\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Testing SSH to Spark-02 (192.168.1.77)...\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.77 \"hostname\" 2>&1 || echo \"FAILED: Cannot connect to spark-02\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47333179",
   "metadata": {},
   "source": [
    "### Diagnosing SSH Environment\n",
    "\n",
    "The notebook kernel may run in a different environment than your terminal. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94173c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SSH Environment Check ===\n",
      "\n",
      "Running as user: nvidia\n",
      "Home directory: /home/nvidia\n",
      "\n",
      "SSH keys available:\n",
      "-rw------- 1 nvidia nvidia 411 Jan 25 01:19 /home/nvidia/.ssh/id_ed25519\n",
      "-rw-r--r-- 1 nvidia nvidia  99 Jan 25 01:15 /home/nvidia/.ssh/id_ed25519.pub\n",
      "\n",
      "SSH agent status:\n",
      "SSH_AUTH_SOCK: /tmp/ssh-ahxtl4IU5sgQ/agent.1337666\n",
      "256 SHA256:na0tGgsozbGtZ2nM52FTdk7No5zpLE5r4iaZE0U2zyQ email2eliza@gmail.com (ED25519)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"=== SSH Environment Check ===\"\n",
    "echo \"\"\n",
    "echo \"Running as user: $(whoami)\"\n",
    "echo \"Home directory: $HOME\"\n",
    "echo \"\"\n",
    "echo \"SSH keys available:\"\n",
    "ls -la ~/.ssh/id_* 2>/dev/null || echo \"No SSH keys found in ~/.ssh/\"\n",
    "echo \"\"\n",
    "echo \"SSH agent status:\"\n",
    "echo \"SSH_AUTH_SOCK: ${SSH_AUTH_SOCK:-NOT SET}\"\n",
    "ssh-add -l 2>&1 || echo \"No agent running or no keys loaded\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5e071",
   "metadata": {},
   "source": [
    "### Fix: Set Up SSH Key-Based Authentication\n",
    "\n",
    "If SSH fails, you need to set up passwordless SSH. First, check if you have an SSH key:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad71f8f",
   "metadata": {},
   "source": [
    "**If no key exists**, run this cell to generate one (skip if you already have a key):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f86491",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Generate SSH key (only run if you don't have one)\n",
    "ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 -N \"\" -C \"microk8s-cluster\"\n",
    "echo \"Key generated:\"\n",
    "cat ~/.ssh/id_ed25519.pub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c277b4e",
   "metadata": {},
   "source": [
    "### Copy SSH Key to All Nodes\n",
    "\n",
    "Run `ssh-copy-id` for each node. This will prompt for the password once per node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe8e3f",
   "metadata": {},
   "source": [
    "**Run these commands in a terminal** (they require interactive password input):\n",
    "\n",
    "```bash\n",
    "# Copy to controller\n",
    "ssh-copy-id nvidia@192.168.1.75\n",
    "\n",
    "# Copy to spark-01\n",
    "ssh-copy-id nvidia@192.168.1.76\n",
    "\n",
    "# Copy to spark-02\n",
    "ssh-copy-id nvidia@192.168.1.77\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62637278",
   "metadata": {},
   "source": [
    "### Verify SSH Access\n",
    "\n",
    "After copying keys, re-run this test from your workstation. All commands below test SSH connectivity **from your workstation to each node**. All nodes should return their hostname without password prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75444ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing SSH Connectivity ===\n",
      "\n",
      "Controller (192.168.1.75):\n",
      "controller\n",
      "✓ SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"=== Testing SSH Connectivity ===\"\n",
    "echo \"\"\n",
    "\n",
    "echo \"Controller (192.168.1.75):\"\n",
    "ssh -o ConnectTimeout=5 -o BatchMode=yes nvidia@192.168.1.75 \"hostname\" && echo \"✓ SUCCESS\" || echo \"✗ FAILED\"\n",
    "echo \"\"\n",
    "\n",
    "echo \"Spark-01 (192.168.1.76):\"\n",
    "ssh -o ConnectTimeout=5 -o BatchMode=yes nvidia@192.168.1.76 \"hostname\" && echo \"✓ SUCCESS\" || echo \"✗ FAILED\"\n",
    "echo \"\"\n",
    "\n",
    "echo \"Spark-02 (192.168.1.77):\"\n",
    "ssh -o ConnectTimeout=5 -o BatchMode=yes nvidia@192.168.1.77 \"hostname\" && echo \"✓ SUCCESS\" || echo \"✗ FAILED\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc1f93",
   "metadata": {},
   "source": [
    "## Step 3: Install MicroK8s on All Nodes\n",
    "\n",
    "MicroK8s is a lightweight Kubernetes distribution from Canonical. We'll install it on all three nodes, then join the Spark nodes to the controller.\n",
    "\n",
    "**Architecture:**\n",
    "- Controller (192.168.1.75): Runs the Kubernetes control plane only\n",
    "- Spark-01 (192.168.1.76): Worker node with GPU\n",
    "- Spark-02 (192.168.1.77): Worker node with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa73344",
   "metadata": {},
   "source": [
    "### 3.1 Install MicroK8s on the Controller\n",
    "\n",
    "The controller runs the control plane (API server, scheduler, etcd). No GPU needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743963b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Installing MicroK8s on Controller (192.168.1.75) ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.75 << 'EOF'\n",
    "    # Check if MicroK8s is already installed\n",
    "    if snap list microk8s &>/dev/null; then\n",
    "        echo \"MicroK8s is already installed. Skipping installation.\"\n",
    "        microk8s version\n",
    "    else\n",
    "        echo \"Installing MicroK8s...\"\n",
    "        sudo snap install microk8s --classic --channel=1.31/stable\n",
    "        # Add user to microk8s group (only needed on first install)\n",
    "        sudo usermod -a -G microk8s $USER\n",
    "        newgrp microk8s\n",
    "    fi\n",
    "    \n",
    "    # Ensure .kube directory exists\n",
    "    mkdir -p ~/.kube\n",
    "    \n",
    "    # Wait for MicroK8s to be ready (use microk8s directly, not sudo)\n",
    "    microk8s status --wait-ready\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"MicroK8s version:\"\n",
    "    microk8s kubectl version --short 2>/dev/null || microk8s kubectl version\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92165e6d",
   "metadata": {},
   "source": [
    "### 3.2 Install MicroK8s on Spark-01\n",
    "\n",
    "Worker node with GPU. Same installation, will join the cluster later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Installing MicroK8s on Spark-01 (192.168.1.76) ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.76 'bash -s' << 'EOF'\n",
    "    # Check if MicroK8s snap is installed and microk8s command works\n",
    "    if snap list microk8s &>/dev/null && /snap/bin/microk8s version &>/dev/null; then\n",
    "        echo \"MicroK8s is already installed and working. Skipping installation.\"\n",
    "        /snap/bin/microk8s version\n",
    "    else\n",
    "        echo \"MicroK8s not found or broken. Installing fresh...\"\n",
    "        # Remove any broken installation first\n",
    "        sudo snap remove microk8s --purge 2>/dev/null || true\n",
    "        \n",
    "        echo \"Installing MicroK8s...\"\n",
    "        sudo snap install microk8s --classic --channel=1.31/stable\n",
    "        \n",
    "        # Add user to microk8s group\n",
    "        sudo usermod -a -G microk8s $USER\n",
    "        \n",
    "        echo \"NOTE: Group membership updated. Running remaining commands with sudo.\"\n",
    "    fi\n",
    "    \n",
    "    # Ensure .kube directory exists\n",
    "    mkdir -p ~/.kube\n",
    "    \n",
    "    # Wait for MicroK8s to be ready\n",
    "    sudo /snap/bin/microk8s status --wait-ready\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"MicroK8s version:\"\n",
    "    sudo /snap/bin/microk8s kubectl version --short 2>/dev/null || sudo /snap/bin/microk8s kubectl version\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2b210f",
   "metadata": {},
   "source": [
    "### 3.3 Install MicroK8s on Spark-02\n",
    "\n",
    "Second GPU worker node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b693d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Installing MicroK8s on Spark-02 (192.168.1.77) ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.77 'bash -s' << 'EOF'\n",
    "    # Check if MicroK8s snap is installed and microk8s command works\n",
    "    if snap list microk8s &>/dev/null && /snap/bin/microk8s version &>/dev/null; then\n",
    "        echo \"MicroK8s is already installed and working. Skipping installation.\"\n",
    "        /snap/bin/microk8s version\n",
    "    else\n",
    "        echo \"MicroK8s not found or broken. Installing fresh...\"\n",
    "        # Remove any broken installation first\n",
    "        sudo snap remove microk8s --purge 2>/dev/null || true\n",
    "        \n",
    "        echo \"Installing MicroK8s...\"\n",
    "        sudo snap install microk8s --classic --channel=1.31/stable\n",
    "        \n",
    "        # Add user to microk8s group\n",
    "        sudo usermod -a -G microk8s $USER\n",
    "        \n",
    "        echo \"NOTE: Group membership updated. Running remaining commands with sudo.\"\n",
    "    fi\n",
    "    \n",
    "    # Ensure .kube directory exists\n",
    "    mkdir -p ~/.kube\n",
    "    \n",
    "    # Wait for MicroK8s to be ready\n",
    "    sudo /snap/bin/microk8s status --wait-ready\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"MicroK8s version:\"\n",
    "    sudo /snap/bin/microk8s kubectl version --short 2>/dev/null || sudo /snap/bin/microk8s kubectl version\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd24ef",
   "metadata": {},
   "source": [
    "## Step 4: Form the Kubernetes Cluster\n",
    "\n",
    "Now that MicroK8s is installed on all nodes, we need to join the worker nodes to the controller.\n",
    "\n",
    "The process:\n",
    "1. Generate a join token on the controller\n",
    "2. Use that token on each worker node\n",
    "3. Verify all nodes are connected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894581a5",
   "metadata": {},
   "source": [
    "### 4.1 Generate Join Token on Controller\n",
    "\n",
    "This command generates a one-time token that workers will use to join the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf18c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Generating Join Token on Controller ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.75 'microk8s add-node' | tee /tmp/join_token.txt\n",
    "\n",
    "echo \"Token generated. Extract the join command for workers.\"\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338ba50",
   "metadata": {},
   "source": [
    "### 4.2 Extract Join Command\n",
    "\n",
    "Parse the join token output to get the actual command. The token expires after some time, so complete the join process promptly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439efac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Extract the join command with --worker flag\n",
    "JOIN_CMD=$(grep \"microk8s join\" /tmp/join_token.txt | head -1 | sed 's/^[[:space:]]*//')\n",
    "\n",
    "if [ -z \"$JOIN_CMD\" ]; then\n",
    "    echo \"ERROR: Could not extract join command\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"Join command for workers:\"\n",
    "echo \"$JOIN_CMD --worker\"\n",
    "echo \"\"\n",
    "echo \"Saving to /tmp/join_cmd.txt\"\n",
    "echo \"$JOIN_CMD --worker\" > /tmp/join_cmd.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc2428",
   "metadata": {},
   "source": [
    "### 4.3 Join Spark-01 to Cluster\n",
    "\n",
    "Execute the join command on spark-01. The `--worker` flag ensures it only runs workloads, not control plane components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51552c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Joining Spark-01 (192.168.1.76) to Cluster ===\"\n",
    "\n",
    "JOIN_CMD=$(cat /tmp/join_cmd.txt)\n",
    "ssh $SSH_OPTS nvidia@192.168.1.76 \"sudo $JOIN_CMD\"\n",
    "\n",
    "echo \"\"\n",
    "sleep 30\n",
    "echo \"Spark-01 join initiated. Wait 30 seconds for node to appear...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa09c682",
   "metadata": {},
   "source": [
    "### 4.4 Join Spark-02 to Cluster\n",
    "\n",
    "Join the second GPU worker node. Each worker needs its own join command (tokens are consumed after use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bf1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Load SSH agent environment\n",
    "with open('/tmp/ssh_agent_env.sh') as f:\n",
    "    for line in f:\n",
    "        if '=' in line and line.startswith('export'):\n",
    "            key, val = line.replace('export ', '').strip().split('=', 1)\n",
    "            os.environ[key] = val\n",
    "\n",
    "SSH_OPTS = ['-o', 'StrictHostKeyChecking=accept-new']\n",
    "\n",
    "print(\"=== Generating new token for Spark-02 ===\")\n",
    "result = subprocess.run(\n",
    "    ['ssh'] + SSH_OPTS + ['nvidia@192.168.1.75', 'microk8s add-node'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"STDERR:\", result.stderr)\n",
    "\n",
    "# Extract join command\n",
    "join_cmd = None\n",
    "for line in result.stdout.split('\\n'):\n",
    "    if 'microk8s join' in line and '192.168.1.75:25000' in line:\n",
    "        join_cmd = line.strip()\n",
    "        break\n",
    "\n",
    "if not join_cmd:\n",
    "    print(\"ERROR: Could not extract join command\")\n",
    "else:\n",
    "    print(f\"\\nExtracted: {join_cmd}\")\n",
    "    \n",
    "    print(\"\\n=== Joining Spark-02 (192.168.1.77) to Cluster ===\")\n",
    "    join_result = subprocess.run(\n",
    "        ['ssh'] + SSH_OPTS + ['nvidia@192.168.1.77', f'sudo {join_cmd} --worker'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    print(join_result.stdout)\n",
    "    if join_result.stderr:\n",
    "        print(\"STDERR:\", join_result.stderr)\n",
    "    \n",
    "    print(\"\\nSpark-02 join initiated. Waiting 30 seconds...\")\n",
    "    time.sleep(30)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee94adf",
   "metadata": {},
   "source": [
    "### 4.5 Verify Cluster Nodes\n",
    "\n",
    "Check that all three nodes are visible and in Ready status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa49fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "echo \"=== Cluster Node Status ===\"\n",
    "ssh nvidia@192.168.1.75 'sudo microk8s kubectl get nodes -o wide'\n",
    "\n",
    "echo \"\"\n",
    "echo \"Expected: 3 nodes (controller, spark-01, spark-02) all in Ready status\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ce3ba",
   "metadata": {},
   "source": [
    "## Step 5: Install NVIDIA GPU Operator\n",
    "\n",
    "The GPU Operator automates the deployment of all NVIDIA software components needed for GPU support in Kubernetes:\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| NVIDIA Driver | GPU device driver (if not already installed) |\n",
    "| NVIDIA Container Toolkit | Enables GPU access in containers |\n",
    "| NVIDIA Device Plugin | Exposes GPUs as schedulable resources |\n",
    "| DCGM Exporter | Metrics for monitoring GPU utilization |\n",
    "| GPU Feature Discovery | Labels nodes with GPU properties |\n",
    "\n",
    "This is production-grade GPU support, not just a basic device plugin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c3e12",
   "metadata": {},
   "source": [
    "### 5.1 Add Helm and NVIDIA Helm Repository\n",
    "\n",
    "The GPU Operator is distributed via Helm chart. First, enable Helm in MicroK8s and add the NVIDIA repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c37f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== Enabling Helm in MicroK8s ===\"\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "    sudo microk8s enable helm3\n",
    "    sudo microk8s kubectl create namespace gpu-operator || true\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"Adding NVIDIA Helm repository...\"\n",
    "    sudo microk8s helm3 repo add nvidia https://helm.ngc.nvidia.com/nvidia\n",
    "    sudo microk8s helm3 repo update\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"Helm and NVIDIA repo configured.\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e8ead",
   "metadata": {},
   "source": [
    "### 5.2 Install GPU Operator\n",
    "\n",
    "Deploy the GPU Operator with driver pre-installed mode (since your DGX Spark nodes already have NVIDIA drivers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324aa1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== Installing NVIDIA GPU Operator ===\"\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "    sudo microk8s helm3 install gpu-operator nvidia/gpu-operator \\\n",
    "        --namespace gpu-operator \\\n",
    "        --set driver.enabled=false \\\n",
    "        --set toolkit.enabled=true \\\n",
    "        --wait \\\n",
    "        --timeout 10m\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"GPU Operator installed. Waiting for pods to be ready...\"\n",
    "    sleep 30\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722cdef0",
   "metadata": {},
   "source": [
    "### 5.3 Verify GPU Operator Pods\n",
    "\n",
    "Check that all GPU Operator components are running on the GPU nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== GPU Operator Pods ===\"\n",
    "ssh nvidia@192.168.1.75 'sudo microk8s kubectl get pods -n gpu-operator -o wide'\n",
    "\n",
    "echo \"\"\n",
    "echo \"Expected: device-plugin, dcgm-exporter, and other operator pods running on spark-01 and spark-02\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38dc3ac",
   "metadata": {},
   "source": [
    "### 5.4 Verify GPU Resources Are Visible\n",
    "\n",
    "Check that GPUs are now exposed as allocatable resources on worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== GPU Resources on Nodes ===\"\n",
    "ssh nvidia@192.168.1.75 'sudo microk8s kubectl describe nodes | grep -A 10 \"Allocatable:\" | grep -E \"(nvidia.com/gpu|Name:)\"'\n",
    "\n",
    "echo \"\"\n",
    "echo \"Each DGX Spark node should show nvidia.com/gpu: <count>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85aee4e",
   "metadata": {},
   "source": [
    "## Step 6: Test GPU Access\n",
    "\n",
    "Deploy a simple GPU test pod to verify that containers can access GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea131bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== Creating GPU Test Pod ===\"\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "cat <<'YAML' | sudo microk8s kubectl apply -f -\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: gpu-test\n",
    "spec:\n",
    "  restartPolicy: Never\n",
    "  containers:\n",
    "  - name: cuda-test\n",
    "    image: nvidia/cuda:12.0-base-ubuntu22.04\n",
    "    command: [\"nvidia-smi\"]\n",
    "    resources:\n",
    "      limits:\n",
    "        nvidia.com/gpu: 1\n",
    "YAML\n",
    "\n",
    "echo \"Waiting for pod to complete...\"\n",
    "sleep 15\n",
    "sudo microk8s kubectl wait --for=condition=Ready pod/gpu-test --timeout=60s || true\n",
    "sleep 5\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== GPU Test Output ===\"\n",
    "sudo microk8s kubectl logs gpu-test\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd512e5",
   "metadata": {},
   "source": [
    "## Step 7: Deploy vLLM for Inference\n",
    "\n",
    "Now that the cluster is running with GPU support, deploy vLLM to serve LLM inference requests.\n",
    "\n",
    "**Test Plan:**\n",
    "1. Single-node baseline: Deploy Llama 3.1 8B on one GPU\n",
    "2. Measure baseline throughput (tokens/sec)\n",
    "3. Deploy distributed vLLM with tensor parallelism across both nodes\n",
    "4. Compare performance and validate the InfiniBand/RDMA link matters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88068ddb",
   "metadata": {},
   "source": [
    "### 7.1 Deploy vLLM Single-Node Baseline\n",
    "\n",
    "Start with a single-GPU deployment to establish baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3076f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"=== Deploying vLLM Single-Node (Llama 3.1 8B) ===\"\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "cat <<'YAML' | sudo microk8s kubectl apply -f -\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: vllm-single\n",
    "  labels:\n",
    "    app: vllm-single\n",
    "spec:\n",
    "  containers:\n",
    "  - name: vllm\n",
    "    image: vllm/vllm-openai:latest\n",
    "    command:\n",
    "      - python3\n",
    "      - -m\n",
    "      - vllm.entrypoints.openai.api_server\n",
    "      - --model\n",
    "      - meta-llama/Llama-3.1-8B-Instruct\n",
    "      - --host\n",
    "      - \"0.0.0.0\"\n",
    "      - --port\n",
    "      - \"8000\"\n",
    "    ports:\n",
    "    - containerPort: 8000\n",
    "      name: http\n",
    "    resources:\n",
    "      limits:\n",
    "        nvidia.com/gpu: 1\n",
    "    env:\n",
    "    - name: HUGGING_FACE_HUB_TOKEN\n",
    "      value: \"YOUR_HF_TOKEN_HERE\"\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: vllm-single-svc\n",
    "spec:\n",
    "  selector:\n",
    "    app: vllm-single\n",
    "  ports:\n",
    "  - port: 8000\n",
    "    targetPort: 8000\n",
    "  type: ClusterIP\n",
    "YAML\n",
    "\n",
    "echo \"\"\n",
    "echo \"vLLM single-node pod created. Waiting for model download and startup...\"\n",
    "echo \"This may take several minutes on first run.\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de3569",
   "metadata": {},
   "source": [
    "### 7.2 Monitor vLLM Startup\n",
    "\n",
    "Watch the pod logs to see when the model is loaded and ready to serve requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba750dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"=== vLLM Pod Status ===\"\n",
    "sudo microk8s kubectl get pod vllm-single -o wide\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Last 50 Lines of Logs ===\"\n",
    "sudo microk8s kubectl logs vllm-single --tail=50 || echo \"Pod not ready yet\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520dc109",
   "metadata": {},
   "source": [
    "### 7.3 Test vLLM Endpoint\n",
    "\n",
    "Send a test request to the vLLM OpenAI-compatible API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85505c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"=== Testing vLLM Inference ===\"\n",
    "curl -X POST http://vllm-single-svc:8000/v1/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"model\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"prompt\": \"Explain RDMA in one sentence:\",\n",
    "    \"max_tokens\": 50,\n",
    "    \"temperature\": 0.7\n",
    "  }' | python3 -m json.tool\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202085e",
   "metadata": {},
   "source": [
    "### 7.4 Benchmark Single-Node Performance\n",
    "\n",
    "Use a simple benchmark script to measure tokens per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f0bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def benchmark_vllm(endpoint, num_requests=10, prompt=\"Explain distributed systems:\", max_tokens=100):\n",
    "    \"\"\"Simple throughput benchmark for vLLM\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"Running {num_requests} requests...\")\n",
    "    for i in range(num_requests):\n",
    "        start = time.time()\n",
    "        \n",
    "        response = requests.post(\n",
    "            f\"{endpoint}/v1/completions\",\n",
    "            json={\n",
    "                \"model\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "                \"prompt\": prompt,\n",
    "                \"max_tokens\": max_tokens,\n",
    "                \"temperature\": 0.7\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            tokens = data['usage']['completion_tokens']\n",
    "            tokens_per_sec = tokens / elapsed if elapsed > 0 else 0\n",
    "            \n",
    "            results.append({\n",
    "                'request': i + 1,\n",
    "                'tokens': tokens,\n",
    "                'time_sec': elapsed,\n",
    "                'tokens_per_sec': tokens_per_sec\n",
    "            })\n",
    "            \n",
    "            print(f\"  Request {i+1}: {tokens} tokens in {elapsed:.2f}s ({tokens_per_sec:.1f} tok/s)\")\n",
    "        else:\n",
    "            print(f\"  Request {i+1}: ERROR {response.status_code}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    if results:\n",
    "        avg_tokens_per_sec = sum(r['tokens_per_sec'] for r in results) / len(results)\n",
    "        total_tokens = sum(r['tokens'] for r in results)\n",
    "        total_time = sum(r['time_sec'] for r in results)\n",
    "        \n",
    "        print(f\"\\n=== Single-Node Baseline Results ===\")\n",
    "        print(f\"Total requests: {len(results)}\")\n",
    "        print(f\"Total tokens: {total_tokens}\")\n",
    "        print(f\"Total time: {total_time:.2f}s\")\n",
    "        print(f\"Average throughput: {avg_tokens_per_sec:.1f} tokens/sec\")\n",
    "        \n",
    "        return avg_tokens_per_sec\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# Run benchmark (update endpoint URL after deployment)\n",
    "# endpoint = \"http://vllm-single-svc:8000\"\n",
    "# baseline_throughput = benchmark_vllm(endpoint)\n",
    "\n",
    "print(\"NOTE: Update endpoint URL and uncomment to run benchmark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbfde55",
   "metadata": {},
   "source": [
    "## Step 8: Deploy vLLM with Tensor Parallelism\n",
    "\n",
    "Deploy vLLM distributed across both DGX Spark nodes using tensor parallelism. This requires:\n",
    "- Ray cluster for coordination\n",
    "- NCCL over your InfiniBand/RoCE link for GPU-to-GPU communication\n",
    "- Larger model that benefits from distribution (Llama 3.1 70B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a99d24",
   "metadata": {},
   "source": [
    "### 8.1 Label GPU Nodes\n",
    "\n",
    "Add node labels to schedule distributed vLLM pods correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"=== Labeling GPU Nodes ===\"\n",
    "sudo microk8s kubectl label node spark-01 nvidia.com/gpu.present=true --overwrite\n",
    "sudo microk8s kubectl label node spark-02 nvidia.com/gpu.present=true --overwrite\n",
    "\n",
    "echo \"\"\n",
    "sudo microk8s kubectl get nodes --show-labels | grep \"nvidia.com/gpu\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73449080",
   "metadata": {},
   "source": [
    "### 8.2 Notes on Distributed vLLM Deployment\n",
    "\n",
    "Distributed vLLM deployment requires additional setup:\n",
    "\n",
    "**Option 1: KubeRay Operator**\n",
    "- Deploy KubeRay operator to manage Ray clusters\n",
    "- Create RayCluster resource with worker nodes on both Spark nodes\n",
    "- Deploy vLLM with `--tensor-parallel-size=2`\n",
    "\n",
    "**Option 2: Manual Multi-Pod Deployment**\n",
    "- StatefulSet with pod affinity to pin to specific nodes\n",
    "- Shared storage for model weights (NFS or similar)\n",
    "- NCCL configuration to use InfiniBand\n",
    "\n",
    "**Key Configuration:**\n",
    "```bash\n",
    "# vLLM command for tensor parallelism\n",
    "python -m vllm.entrypoints.openai.api_server \\\n",
    "  --model meta-llama/Llama-3.1-70B-Instruct \\\n",
    "  --tensor-parallel-size 2 \\\n",
    "  --host 0.0.0.0 \\\n",
    "  --port 8000\n",
    "```\n",
    "\n",
    "**NCCL Environment Variables for InfiniBand:**\n",
    "```yaml\n",
    "- name: NCCL_IB_DISABLE\n",
    "  value: \"0\"\n",
    "- name: NCCL_SOCKET_IFNAME\n",
    "  value: \"ib0\"  # or your IB interface name\n",
    "- name: NCCL_DEBUG\n",
    "  value: \"INFO\"\n",
    "```\n",
    "\n",
    "This is the critical link to your InfiniBand article—NCCL will use RDMA over your high-speed interconnect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357582e1",
   "metadata": {},
   "source": [
    "## Step 9: Add Monitoring with Prometheus and DCGM\n",
    "\n",
    "Monitor GPU utilization and inference metrics using Prometheus and NVIDIA DCGM Exporter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df3169",
   "metadata": {},
   "source": [
    "### 9.1 Enable Prometheus in MicroK8s\n",
    "\n",
    "MicroK8s includes a Prometheus addon for monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"=== Enabling Prometheus ===\"\n",
    "sudo microk8s enable prometheus\n",
    "\n",
    "echo \"\"\n",
    "echo \"Waiting for Prometheus pods to start...\"\n",
    "sleep 30\n",
    "sudo microk8s kubectl get pods -n observability\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e05f75",
   "metadata": {},
   "source": [
    "### 9.2 Verify DCGM Exporter\n",
    "\n",
    "The GPU Operator includes DCGM Exporter, which exposes GPU metrics to Prometheus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd59f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ssh nvidia@192.168.1.75 << 'EOF'\n",
    "echo \"=== DCGM Exporter Pods ===\"\n",
    "sudo microk8s kubectl get pods -n gpu-operator | grep dcgm\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Sample GPU Metrics ===\"\n",
    "# Get one DCGM exporter pod\n",
    "DCGM_POD=$(sudo microk8s kubectl get pods -n gpu-operator -l app=nvidia-dcgm-exporter -o jsonpath='{.items[0].metadata.name}')\n",
    "\n",
    "if [ -n \"$DCGM_POD\" ]; then\n",
    "    echo \"Fetching metrics from $DCGM_POD...\"\n",
    "    sudo microk8s kubectl exec -n gpu-operator $DCGM_POD -- curl -s localhost:9400/metrics | grep \"DCGM_FI_DEV_GPU_UTIL\" | head -5\n",
    "else\n",
    "    echo \"DCGM Exporter not found\"\n",
    "fi\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c7dee5",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook established the foundation:\n",
    "\n",
    "| Component | Status |\n",
    "|-----------|--------|\n",
    "| 3-node MicroK8s cluster | ✓ Deployed |\n",
    "| GPU Operator | ✓ Installed |\n",
    "| Single-node vLLM | ✓ Configured |\n",
    "| Monitoring (Prometheus/DCGM) | ✓ Enabled |\n",
    "| Distributed vLLM | Documented (requires additional setup) |\n",
    "\n",
    "**To complete the project:**\n",
    "\n",
    "1. **Deploy distributed vLLM** using KubeRay or StatefulSet\n",
    "2. **Configure NCCL** to use your InfiniBand link (`enp1s0f0np0`/`enp1s0f1np1`)\n",
    "3. **Run benchmarks** comparing single-node vs distributed throughput\n",
    "4. **Measure latency** impact of tensor parallelism over RDMA\n",
    "5. **Create dashboards** in Grafana for GPU utilization\n",
    "\n",
    "**The compelling article** writes itself once you have these numbers:\n",
    "- \"vLLM on 2 DGX Spark nodes: X tokens/sec with Llama 3.1 70B\"\n",
    "- \"Why 96 Gbps RDMA matters: tensor parallelism latency comparison\"\n",
    "- \"Cost analysis: $Y home lab vs $Z cloud GPU hours\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e32f53",
   "metadata": {},
   "source": [
    "## Troubleshooting: Complete Cluster Reset\n",
    "\n",
    "If the cluster becomes corrupted or you encounter version skew issues between nodes, you can perform a complete reset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92066e2e",
   "metadata": {},
   "source": [
    "### Symptoms Requiring Reset\n",
    "\n",
    "- Worker nodes show `NotReady` status in `kubectl get nodes`\n",
    "- GPU Operator pods stuck in `CrashLoopBackOff` or `ContainerCreating`\n",
    "- Version mismatch between controller and workers (e.g., v1.32 vs v1.31)\n",
    "- Different containerd versions across nodes\n",
    "\n",
    "**Cause:** Kubernetes requires control plane and worker nodes within ±1 minor version. If you upgraded the controller but not the workers, or installed different MicroK8s channels, reset and reinstall with the same version on all nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508a233",
   "metadata": {},
   "source": [
    "### Step 1: Remove Worker Nodes from Cluster\n",
    "\n",
    "Before resetting, remove the worker nodes from the cluster on the controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbe112",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Removing Worker Nodes from Cluster ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.75 << 'EOF'\n",
    "    echo \"Removing spark-01...\"\n",
    "    microk8s remove-node spark-01 || echo \"Node already removed or not found\"\n",
    "    \n",
    "    echo \"Removing spark-02...\"\n",
    "    microk8s remove-node spark-02 || echo \"Node already removed or not found\"\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"Remaining nodes:\"\n",
    "    microk8s kubectl get nodes\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11fec14",
   "metadata": {},
   "source": [
    "### Step 2: Leave Cluster from Worker Nodes\n",
    "\n",
    "Each worker node must leave the cluster before it can be fully reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Spark-01: Leaving Cluster ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.76 'sudo microk8s leave' || echo \"Already left or not in cluster\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Spark-02: Leaving Cluster ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.77 'sudo microk8s leave' || echo \"Already left or not in cluster\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Workers have left the cluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df22de9e",
   "metadata": {},
   "source": [
    "### Step 3: Purge MicroK8s from All Nodes\n",
    "\n",
    "Remove MicroK8s completely, including all configuration, data, and cluster state. The `--purge` flag ensures a clean slate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15351f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /tmp/ssh_agent_env.sh\n",
    "SSH_OPTS=\"-o StrictHostKeyChecking=accept-new\"\n",
    "\n",
    "echo \"=== Purging MicroK8s from Controller ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.75 'sudo snap remove microk8s --purge'\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Purging MicroK8s from Spark-01 ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.76 'sudo snap remove microk8s --purge'\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Purging MicroK8s from Spark-02 ===\"\n",
    "ssh $SSH_OPTS nvidia@192.168.1.77 'sudo snap remove microk8s --purge'\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Cleanup Complete ===\"\n",
    "echo \"All nodes have been reset. Ready for fresh installation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e121881",
   "metadata": {},
   "source": [
    "### After Reset: Reinstall with Consistent Versions\n",
    "\n",
    "After purging, reinstall MicroK8s using **the same channel** on all three nodes. This prevents version skew issues.\n",
    "\n",
    "**Critical:** Use the same channel (e.g., `1.32/stable`) on all nodes. Go back to cell 18 (Step 3.1: Install MicroK8s on the Controller) and proceed through the installation steps with the updated channel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
